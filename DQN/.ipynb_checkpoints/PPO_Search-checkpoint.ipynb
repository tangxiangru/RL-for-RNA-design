{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os \n",
    "from collections import deque, Counter\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import editdistance\n",
    "import sys\n",
    "import RNA\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# import path \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.sequence_utils import translate_one_hot_to_string,generate_random_mutant\n",
    "from models.Theoretical_models import *\n",
    "from models.Noise_wrapper import *\n",
    "from exploration_strategies.CE import *\n",
    "from utils.landscape_utils import *\n",
    "from models.RNA_landscapes import *\n",
    "from models.Multi_dimensional_model import *\n",
    "\n",
    "from segment_tree import MinSegmentTree, SumSegmentTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAA=\"UGCA\" #alphabet\n",
    "length=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCUAAGGAAUGGCAAAUACCUCGAUCGAAAAAUCCCGGCU'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt=generate_random_sequences(length,1,alphabet=RAA)[0]\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a simple folding landscape starting at wt\n",
    "landscape1=RNA_landscape(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_alpha=1\n",
    "experiment_batch_size=10\n",
    "virtual_per_measure_ratio=15\n",
    "temperature=0.1\n",
    "generations=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are multiple abstract \"noise models\" you can use, or you can try to train your own model, using skM\n",
    "noisy_landscape=Noise_wrapper(landscape1,\n",
    "                              noise_alpha=noise_alpha,\n",
    "                              always_costly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_genotypes=list(set([wt]+[generate_random_mutant(wt,0.05,RAA) for i in range(experiment_batch_size*10)]))[:experiment_batch_size]\n",
    "len(initial_genotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_landscape.reset()\n",
    "noisy_landscape.measure_true_landscape(initial_genotypes)\n",
    "noisy_landscape.natural_mode=False\n",
    "noisy_landscape.local_mode=False\n",
    "noisy_landscape.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import bisect\n",
    "from utils.sequence_utils import translate_string_to_one_hot, translate_one_hot_to_string\n",
    "\n",
    "def renormalize_moves(one_hot_input, rewards_output):\n",
    "    \"\"\"ensures that staying in place gives no reward\"\"\"\n",
    "    zero_current_state = (one_hot_input - 1) * (-1)\n",
    "    return np.multiply(rewards_output, zero_current_state)\n",
    "\n",
    "def walk_away_renormalize_moves(one_hot_input, one_hot_wt, rewards_output):\n",
    "    \"\"\"ensures that moving toward wt is also not useful\"\"\"\n",
    "    zero_current_state=(one_hot_input-1)*-1\n",
    "    zero_wt=((one_hot_wt-1)*-1)\n",
    "    zero_conservative_moves=np.multiply(zero_wt,zero_current_state)\n",
    "    return np.multiply(rewards_output,zero_conservative_moves)\n",
    "\n",
    "def get_all_singles_fitness(model,sequence,alphabet):\n",
    "    prob_singles=np.zeros((len(alphabet),len(sequence)))\n",
    "    for i in range(len(sequence)):\n",
    "        for j in range(len(alphabet)):\n",
    "            putative_seq=sequence[:i]+alphabet[j]+sequence[i+1:]\n",
    "           # print (putative_seq)\n",
    "            prob_singles[j][i]=model.get_fitness(putative_seq)\n",
    "    return prob_singles\n",
    "\n",
    "def get_all_mutants(sequence):\n",
    "    mutants = []\n",
    "    for i in range(sequence.shape[0]):\n",
    "        for j in range(sequence.shape[1]):\n",
    "            putative_seq = sequence.copy()\n",
    "            putative_seq[:, j] = 0\n",
    "            putative_seq[i, j] = 1\n",
    "            mutants.append(putative_seq)\n",
    "    return np.array(mutants)\n",
    "\n",
    "def sample_greedy(matrix):\n",
    "    i,j=matrix.shape\n",
    "    max_arg=np.argmax(matrix)\n",
    "    y=max_arg%j\n",
    "    x=int(max_arg/j)\n",
    "    output=np.zeros((i,j))\n",
    "    output[x][y]=matrix[x][y]\n",
    "    return output\n",
    "\n",
    "def sample_multi_greedy(matrix):\n",
    "    n = 5 # the number of base positions to greedily change\n",
    "    max_args = np.argpartition(matrix.flatten(), -n)[-n:]\n",
    "    i,j=matrix.shape\n",
    "    output=np.zeros((i,j))\n",
    "    for max_arg in max_args:\n",
    "        y=max_arg%j\n",
    "        x=int(max_arg/j)\n",
    "        output[x][y]=matrix[x][y]\n",
    "    return output\n",
    "\n",
    "def sample_random(matrix):\n",
    "    i,j=matrix.shape\n",
    "    non_zero_moves=np.nonzero(matrix)\n",
    "   # print (non_zero_moves)\n",
    "    k=len(non_zero_moves)\n",
    "    l=len(non_zero_moves[0])\n",
    "    if k!=0 and l!=0:\n",
    "        rand_arg=random.choice([[non_zero_moves[alph][pos] for alph in range(k)] for pos in range(l)])\n",
    "    else:\n",
    "        rand_arg=[random.randint(0,i-1),random.randint(0,j-1)]\n",
    "    #print (rand_arg)\n",
    "    y=rand_arg[1]\n",
    "    x=rand_arg[0]\n",
    "    output=np.zeros((i,j))\n",
    "    output[x][y] = 1\n",
    "    return output   \n",
    "\n",
    "def action_to_scalar(matrix):\n",
    "    matrix = matrix.ravel()\n",
    "    for i in range(len(matrix)):\n",
    "        if matrix[i] != 0:\n",
    "            return i\n",
    "    \n",
    "def construct_mutant_from_sample(pwm_sample, one_hot_base):\n",
    "    one_hot = np.zeros(one_hot_base.shape)\n",
    "    one_hot += one_hot_base\n",
    "    nonzero = np.nonzero(pwm_sample)\n",
    "    nonzero = list(zip(nonzero[0], nonzero[1]))\n",
    "    for nz in nonzero: # this can be problematic for non-positive fitnesses\n",
    "        i, j = nz\n",
    "        one_hot[:,j]=0\n",
    "        one_hot[i,j]=1\n",
    "    return one_hot\n",
    "\n",
    "def best_predicted_new_gen(actor, genotypes, alphabet, pop_size):\n",
    "    mutants = get_all_mutants(genotypes)\n",
    "    one_hot_mutants = np.array([translate_string_to_one_hot(mutant, alphabet) for mutant in mutants])\n",
    "    torch_one_hot_mutants = torch.from_numpy(np.expand_dims(one_hot_mutants, axis=0)).float()\n",
    "    predictions = actor(torch_one_hot_mutants)\n",
    "    predictions = predictions.detach().numpy()\n",
    "    best_pred_ind = predictions.argsort()[-pop_size:]\n",
    "    return mutants[best_pred_ind]\n",
    "\n",
    "def make_one_hot_train_test(genotypes, model, alphabet):\n",
    "    genotypes_one_hot = np.array([translate_string_to_one_hot(genotype, alphabet) for genotype in genotypes])\n",
    "    genotype_fitnesses = []\n",
    "    for genotype in genotypes:\n",
    "        genotype_fitnesses.append(model.get_fitness(genotype))\n",
    "    genotype_fitnesses = np.array(genotype_fitnesses)\n",
    "\n",
    "    return genotypes_one_hot, genotype_fitnesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 128):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        obs: np.ndarray,\n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray\n",
    "    ):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \n",
    "    Attributes:\n",
    "        max_priority (float): max priority\n",
    "        tree_ptr (int): next index of tree\n",
    "        alpha (float): alpha parameter for prioritized replay buffer\n",
    "        sum_tree (SumSegmentTree): sum tree for prior\n",
    "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int,\n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        alpha: float = 0.6\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        assert alpha >= 0\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(obs_dim, size, batch_size)\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: int, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray\n",
    "    ):\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        super().store(obs, act, rew, next_obs)\n",
    "        \n",
    "        self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "        self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "        self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        assert len(self) >= self.batch_size\n",
    "        assert beta > 0\n",
    "        \n",
    "        indices = self._sample_proportional()\n",
    "        \n",
    "        obs = self.obs_buf[indices]\n",
    "        next_obs = self.next_obs_buf[indices]\n",
    "        acts = self.acts_buf[indices]\n",
    "        rews = self.rews_buf[indices]\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        \n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "        \n",
    "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        assert len(indices) == len(priorities)\n",
    "\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self)\n",
    "\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "    def _sample_proportional(self) -> List[int]:\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        indices = []\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        segment = p_total / self.batch_size\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            upperbound = random.uniform(a, b)\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            indices.append(idx)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, sequence_len, alphabet_len):\n",
    "        super(Q_Network, self).__init__()\n",
    "        self.sequence_len = sequence_len\n",
    "        self.alphabet_len = alphabet_len\n",
    "        self.linear1 = nn.Linear(2 * alphabet_len * sequence_len, alphabet_len * sequence_len)\n",
    "        self.bn1 = nn.BatchNorm1d(alphabet_len * sequence_len)\n",
    "        self.linear2 = nn.Linear(alphabet_len * sequence_len, sequence_len)\n",
    "        self.bn2 = nn.BatchNorm1d(sequence_len)\n",
    "        self.linear3 = nn.Linear(sequence_len, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(F.relu(self.linear1(x)))\n",
    "        x = self.bn2(F.relu(self.linear2(x)))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        return x\n",
    "    \n",
    "def build_model(sequence_len, alphabet_len, device):\n",
    "    model = Model(sequence_len, alphabet_len).to(device)\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "class RL_agent_PPO():\n",
    "    '''\n",
    "    Based off https://colab.research.google.com/drive/1NsbSPn6jOcaJB_mp9TmkgQX7UrRIrTi0\n",
    "    '''\n",
    "    def __init__(self, landscape, start_sequence, alphabet, gamma=0.9, \n",
    "                 memory_size=100000, batch_size=10, experiment_batch_size=1000,\n",
    "                 device = \"cpu\", noise_alpha=1, train_epochs=10):\n",
    "        '''\n",
    "        Unintuitive variables:\n",
    "        memory_size: size of agent memory\n",
    "        batch_size: batch size to train the PER buffer with\n",
    "        experiment_batch_size: the batch size of the experiment.\n",
    "            that is, if this were a lab, this would be the number of sequences\n",
    "            evaluated in a lab trial\n",
    "        '''\n",
    "        \n",
    "        self.alphabet = alphabet\n",
    "        self.alphabet_size = len(alphabet)\n",
    "        self.state = translate_string_to_one_hot(start_sequence, self.alphabet)\n",
    "        self.seq_size = len(start_sequence)\n",
    "        self.model = build_model(self.seq_size, len(self.alphabet), device)\n",
    "        self.model.eval()\n",
    "        self.start_sequence = translate_string_to_one_hot(start_sequence,self.alphabet)\n",
    "        self.memory_size = memory_size\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.experiment_batch_size = experiment_batch_size\n",
    "        self.memory = PrioritizedReplayBuffer(len(self.alphabet) * self.seq_size, \n",
    "                                              memory_size, batch_size, 0.6)\n",
    "        self.seen_sequences = []\n",
    "        self.landscape = landscape\n",
    "        self.best_fitness = 0\n",
    "        \n",
    "        self.train_epochs = 10\n",
    "        self.epsilon_min = 0.1\n",
    "        \n",
    "        self.top_sequence = []\n",
    "\n",
    "        self.times_seen = Counter()\n",
    "        \n",
    "    def reset_position(self,sequence):\n",
    "        self.state=translate_string_to_one_hot(sequence,self.alphabet)\n",
    "\n",
    "    def get_position(self):\n",
    "        return translate_one_hot_to_string(self.state,self.alphabet)\n",
    "\n",
    "    def translate_pwm_to_sequence(self,input_seq_one_hot,output_pwm):\n",
    "        diff=output_pwm-input_seq_one_hot\n",
    "        most_likely=np.argmax(diff,axis=0)\n",
    "        out_seq=\"\"\n",
    "        for m in most_likely:\n",
    "            out_seq+=self.alphabet[m]\n",
    "        return out_seq\n",
    "    \n",
    "    def sample(self):\n",
    "        indices = np.random.choice(len(self.memory), self.batch_size)\n",
    "        rewards, actions, states, next_states = zip(*[self.memory[ind] for ind in indices])\n",
    "        return np.array(rewards), np.array(actions), np.array(states), np.array(next_states) \n",
    "    \n",
    "    def calculate_next_q_values(self, state_v):\n",
    "        dim = self.alphabet_size * self.seq_size\n",
    "        states_repeated = state_v.repeat(1, dim).reshape(-1, dim)\n",
    "        actions_repeated = torch.FloatTensor(np.identity(dim)).repeat(len(state_v), 1)\n",
    "        next_states_actions = torch.cat((states_repeated, actions_repeated), 1)\n",
    "        next_states_values = self.q_network(next_states_actions)\n",
    "        next_states_values = next_states_values.reshape(len(state_v), -1)\n",
    "        \n",
    "        return next_states_values\n",
    "    \n",
    "    def q_network_loss(self, batch, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Calculate MSE between actual state action values,\n",
    "        and expected state action values from DQN\n",
    "        \"\"\"\n",
    "        rewards, actions, states, next_states = \\\n",
    "        batch['rews'], batch['acts'], batch['obs'], batch['next_obs']\n",
    "        \n",
    "        state_action_v = torch.FloatTensor(np.hstack((states, actions)))\n",
    "        rewards_v = torch.FloatTensor(rewards)\n",
    "        next_states_v = torch.FloatTensor(next_states)\n",
    "    \n",
    "        state_action_values = self.q_network(state_action_v).view(-1)\n",
    "        next_state_values = self.calculate_next_q_values(next_states_v)\n",
    "        next_state_values = next_state_values.max(1)[0].detach()\n",
    "        expected_state_action_values = next_state_values * self.gamma + rewards_v\n",
    "        \n",
    "        return nn.MSELoss()(state_action_values, expected_state_action_values)\n",
    "\n",
    "    def train_actor(self, train_epochs=10):\n",
    "        total_loss = 0.\n",
    "        # train Q network on new samples \n",
    "        optimizer = optim.Adam(self.q_network.parameters())\n",
    "        for epoch in range(train_epochs):\n",
    "            batch = self.memory.sample_batch()\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.q_network_loss(batch)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(self.q_network.parameters(), 1.0, norm_type=1)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        return (total_loss / train_epochs)\n",
    "\n",
    "    def get_action_and_mutant(self, epsilon):\n",
    "        state_tensor = torch.FloatTensor([self.state.ravel()])\n",
    "        prediction = self.calculate_next_q_values(state_tensor).detach().numpy()\n",
    "        prediction = prediction.reshape((len(self.alphabet), self.seq_size))\n",
    "        # make action\n",
    "        moves = renormalize_moves(self.state, prediction)\n",
    "        p = random.random()\n",
    "        action = sample_random(moves) if p < epsilon else sample_greedy(moves)\n",
    "        # get next state (mutant)\n",
    "        mutant = construct_mutant_from_sample(action, self.state)\n",
    "        mutant_string = translate_one_hot_to_string(mutant, self.alphabet)\n",
    "        self.state = mutant\n",
    "\n",
    "        return action, mutant\n",
    "    \n",
    "    def pick_action(self):\n",
    "        b = 0\n",
    "        eps = max(self.epsilon_min, (0.5 - self.landscape.cost / (self.experiment_batch_size * generations)))\n",
    "        while (b < self.experiment_batch_size):\n",
    "            state = self.state.copy()\n",
    "            action, new_state = self.get_action_and_mutant(eps)\n",
    "            new_state_string = translate_one_hot_to_string(new_state, self.alphabet)\n",
    "            reward = self.landscape.get_fitness(new_state_string)\n",
    "            if not new_state_string in self.landscape.measured_sequences:\n",
    "                if reward > self.best_fitness:\n",
    "                    state_tensor = torch.FloatTensor([self.state.ravel()])\n",
    "                    prediction = self.calculate_next_q_values(state_tensor).detach().numpy()\n",
    "                    prediction = prediction.reshape((len(self.alphabet), self.seq_size))\n",
    "#                     print(prediction)\n",
    "                    self.top_sequence.append((reward, new_state, self.landscape.cost))\n",
    "                self.best_fitness = max(self.best_fitness, reward)\n",
    "                self.memory.store(state.ravel(), action.ravel(), reward, new_state.ravel())\n",
    "                b += 1\n",
    "        avg_loss = self.train_actor(self.train_epochs)\n",
    "        return\n",
    "    \n",
    "    def pick_action_reward_freq(self):\n",
    "        b = 0\n",
    "        eps = max(self.epsilon_min, (0.5 - self.landscape.cost / (self.experiment_batch_size * generations)))\n",
    "        while (b < self.experiment_batch_size):\n",
    "            state = self.state.copy() \n",
    "            action, new_state = self.get_action_and_mutant(eps)\n",
    "            new_state_string = translate_one_hot_to_string(new_state, self.alphabet)\n",
    "            fitness = self.landscape.get_fitness(new_state_string)\n",
    "            reward = fitness - 0.1 * self.times_seen[new_state_string]\n",
    "            self.times_seen[new_state_string] += 1\n",
    "            if fitness > self.best_fitness:\n",
    "                state_tensor = torch.FloatTensor([self.state.ravel()])\n",
    "                prediction = self.calculate_next_q_values(state_tensor).detach().numpy()\n",
    "                prediction = prediction.reshape((len(self.alphabet), self.seq_size))\n",
    "#                 print(prediction)\n",
    "                self.top_sequence.append((reward, new_state, self.landscape.cost))\n",
    "            self.best_fitness = max(self.best_fitness, fitness)\n",
    "            self.memory.store(state.ravel(), action.ravel(), reward, new_state.ravel())\n",
    "            b += 1\n",
    "        avg_loss = self.train_actor(self.train_epochs)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Network(\n",
      "  (linear1): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (bn1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear2): Linear(in_features=160, out_features=40, bias=True)\n",
      "  (bn2): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear3): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n",
      "Cost: 14, Top fitness: 0.023529411764705882\n",
      "Cost: 18, Top fitness: 0.058823529411764705\n",
      "Cost: 19, Top fitness: 0.09058823305017807\n",
      "Cost: 22, Top fitness: 0.0917647081262925\n",
      "Cost: 23, Top fitness: 0.0917647081262925\n",
      "Cost: 25, Top fitness: 0.0917647081262925\n",
      "Cost: 26, Top fitness: 0.0917647081262925\n",
      "Cost: 28, Top fitness: 0.0917647081262925\n",
      "Cost: 30, Top fitness: 0.0917647081262925\n",
      "Cost: 31, Top fitness: 0.0917647081262925\n",
      "Cost: 33, Top fitness: 0.0917647081262925\n",
      "Cost: 35, Top fitness: 0.0917647081262925\n",
      "Cost: 36, Top fitness: 0.0917647081262925\n",
      "Cost: 37, Top fitness: 0.0917647081262925\n",
      "Cost: 37, Top fitness: 0.0917647081262925\n",
      "Cost: 38, Top fitness: 0.0917647081262925\n",
      "Cost: 39, Top fitness: 0.0917647081262925\n",
      "Cost: 40, Top fitness: 0.0917647081262925\n",
      "Cost: 40, Top fitness: 0.0917647081262925\n",
      "Cost: 40, Top fitness: 0.0917647081262925\n",
      "Cost: 42, Top fitness: 0.0917647081262925\n",
      "Cost: 42, Top fitness: 0.0917647081262925\n",
      "Cost: 42, Top fitness: 0.0917647081262925\n",
      "Cost: 42, Top fitness: 0.0917647081262925\n",
      "Cost: 44, Top fitness: 0.0917647081262925\n",
      "Cost: 44, Top fitness: 0.0917647081262925\n",
      "Cost: 45, Top fitness: 0.0917647081262925\n",
      "Cost: 46, Top fitness: 0.0917647081262925\n",
      "Cost: 46, Top fitness: 0.0917647081262925\n",
      "Cost: 46, Top fitness: 0.0917647081262925\n",
      "Cost: 46, Top fitness: 0.0917647081262925\n",
      "Cost: 47, Top fitness: 0.0917647081262925\n",
      "Cost: 47, Top fitness: 0.0917647081262925\n",
      "Cost: 47, Top fitness: 0.0917647081262925\n",
      "Cost: 47, Top fitness: 0.0917647081262925\n",
      "Cost: 49, Top fitness: 0.0917647081262925\n",
      "Cost: 51, Top fitness: 0.11058823080623852\n",
      "Cost: 51, Top fitness: 0.11058823080623852\n",
      "Cost: 53, Top fitness: 0.11058823080623852\n",
      "Cost: 54, Top fitness: 0.11058823080623852\n",
      "Cost: 54, Top fitness: 0.11058823080623852\n",
      "Cost: 54, Top fitness: 0.11058823080623852\n",
      "Cost: 56, Top fitness: 0.11058823080623852\n",
      "Cost: 56, Top fitness: 0.11058823080623852\n",
      "Cost: 56, Top fitness: 0.11058823080623852\n",
      "Cost: 56, Top fitness: 0.11058823080623852\n",
      "Cost: 56, Top fitness: 0.11058823080623852\n",
      "Cost: 57, Top fitness: 0.11058823080623852\n",
      "Cost: 59, Top fitness: 0.11058823080623852\n",
      "Cost: 60, Top fitness: 0.11058823080623852\n",
      "Cost: 61, Top fitness: 0.11058823080623852\n",
      "Cost: 61, Top fitness: 0.11058823080623852\n",
      "Cost: 62, Top fitness: 0.11058823080623852\n",
      "Cost: 63, Top fitness: 0.11058823080623852\n",
      "Cost: 65, Top fitness: 0.11058823080623852\n",
      "Cost: 65, Top fitness: 0.11058823080623852\n",
      "Cost: 65, Top fitness: 0.11058823080623852\n",
      "Cost: 66, Top fitness: 0.11058823080623852\n",
      "Cost: 66, Top fitness: 0.11058823080623852\n",
      "Cost: 66, Top fitness: 0.11058823080623852\n",
      "Cost: 67, Top fitness: 0.11058823080623852\n",
      "Cost: 67, Top fitness: 0.11058823080623852\n",
      "Cost: 69, Top fitness: 0.11058823080623852\n",
      "Cost: 69, Top fitness: 0.11058823080623852\n",
      "Cost: 70, Top fitness: 0.11058823080623852\n",
      "Cost: 71, Top fitness: 0.11058823080623852\n",
      "Cost: 72, Top fitness: 0.11058823080623852\n",
      "Cost: 72, Top fitness: 0.11058823080623852\n",
      "Cost: 74, Top fitness: 0.11058823080623852\n",
      "Cost: 74, Top fitness: 0.11058823080623852\n",
      "Cost: 74, Top fitness: 0.11058823080623852\n",
      "Cost: 74, Top fitness: 0.11058823080623852\n",
      "Cost: 74, Top fitness: 0.11058823080623852\n",
      "Cost: 75, Top fitness: 0.11058823080623852\n",
      "Cost: 76, Top fitness: 0.11058823080623852\n",
      "Cost: 77, Top fitness: 0.11058823080623852\n",
      "Cost: 77, Top fitness: 0.11058823080623852\n",
      "Cost: 78, Top fitness: 0.11058823080623852\n",
      "Cost: 78, Top fitness: 0.11058823080623852\n",
      "Cost: 78, Top fitness: 0.11058823080623852\n",
      "Cost: 78, Top fitness: 0.11058823080623852\n",
      "Cost: 79, Top fitness: 0.11058823080623852\n",
      "Cost: 81, Top fitness: 0.11058823080623852\n",
      "Cost: 82, Top fitness: 0.11058823080623852\n",
      "Cost: 82, Top fitness: 0.11058823080623852\n",
      "Cost: 83, Top fitness: 0.11058823080623852\n",
      "Cost: 85, Top fitness: 0.12352941176470589\n",
      "Cost: 85, Top fitness: 0.12352941176470589\n",
      "Cost: 86, Top fitness: 0.12352941176470589\n",
      "Cost: 86, Top fitness: 0.12352941176470589\n",
      "Cost: 86, Top fitness: 0.12352941176470589\n",
      "Cost: 87, Top fitness: 0.12352941176470589\n",
      "Cost: 87, Top fitness: 0.12352941176470589\n",
      "Cost: 87, Top fitness: 0.12352941176470589\n",
      "Cost: 88, Top fitness: 0.12352941176470589\n",
      "Cost: 89, Top fitness: 0.12352941176470589\n",
      "Cost: 89, Top fitness: 0.12352941176470589\n",
      "Cost: 91, Top fitness: 0.12352941176470589\n",
      "Cost: 91, Top fitness: 0.12352941176470589\n",
      "Cost: 91, Top fitness: 0.12352941176470589\n",
      "Cost: 92, Top fitness: 0.12352941176470589\n",
      "Cost: 95, Top fitness: 0.12352941176470589\n",
      "Cost: 95, Top fitness: 0.12352941176470589\n",
      "Cost: 96, Top fitness: 0.12352941176470589\n",
      "Cost: 97, Top fitness: 0.12352941176470589\n",
      "Cost: 97, Top fitness: 0.12352941176470589\n",
      "Cost: 97, Top fitness: 0.12352941176470589\n",
      "Cost: 97, Top fitness: 0.12352941176470589\n",
      "Cost: 98, Top fitness: 0.12352941176470589\n",
      "Cost: 98, Top fitness: 0.12352941176470589\n",
      "Cost: 98, Top fitness: 0.12352941176470589\n",
      "Cost: 99, Top fitness: 0.12352941176470589\n",
      "Cost: 101, Top fitness: 0.12352941176470589\n"
     ]
    }
   ],
   "source": [
    "agent = RL_agent_DQN(landscape=noisy_landscape, start_sequence=wt,\n",
    "                     alphabet=RAA, gamma=0.8, memory_size=10000,\n",
    "                     device=device, experiment_batch_size=experiment_batch_size)\n",
    "\n",
    "noisy_landscape.reset()\n",
    "noisy_landscape.measure_true_landscape(initial_genotypes)\n",
    "noisy_landscape.natural_mode=False\n",
    "noisy_landscape.local_mode=False\n",
    "noisy_landscape.cost\n",
    "\n",
    "while noisy_landscape.cost < generations*experiment_batch_size:\n",
    "    agent.pick_action()\n",
    "    print(f\"Cost: {noisy_landscape.cost}, Top fitness: {agent.top_sequence[-1][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Network(\n",
      "  (linear1): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (bn1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear2): Linear(in_features=160, out_features=40, bias=True)\n",
      "  (bn2): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear3): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n",
      "Cost: 20, Top fitness: 0.08235294117647059\n",
      "Cost: 29, Top fitness: 0.08235294117647059\n",
      "Cost: 33, Top fitness: 0.08235294117647059\n",
      "Cost: 38, Top fitness: 0.1\n",
      "Cost: 44, Top fitness: 0.10235293893253102\n",
      "Cost: 48, Top fitness: 0.10588235294117647\n",
      "Cost: 52, Top fitness: 0.10588235294117647\n",
      "Cost: 55, Top fitness: 0.10588235294117647\n",
      "Cost: 57, Top fitness: 0.10588235294117647\n",
      "Cost: 60, Top fitness: 0.10588235294117647\n",
      "Cost: 61, Top fitness: 0.10588235294117647\n",
      "Cost: 62, Top fitness: 0.10588235294117647\n",
      "Cost: 63, Top fitness: 0.10588235294117647\n",
      "Cost: 63, Top fitness: 0.10588235294117647\n",
      "Cost: 65, Top fitness: 0.10588235294117647\n",
      "Cost: 66, Top fitness: 0.10588235294117647\n",
      "Cost: 67, Top fitness: 0.10588235294117647\n",
      "Cost: 67, Top fitness: 0.10588235294117647\n",
      "Cost: 67, Top fitness: 0.10588235294117647\n",
      "Cost: 67, Top fitness: 0.10588235294117647\n",
      "Cost: 67, Top fitness: 0.10588235294117647\n",
      "Cost: 69, Top fitness: 0.10588235294117647\n",
      "Cost: 70, Top fitness: 0.10588235294117647\n",
      "Cost: 70, Top fitness: 0.10588235294117647\n",
      "Cost: 73, Top fitness: 0.10588235294117647\n",
      "Cost: 75, Top fitness: 0.10588235294117647\n",
      "Cost: 76, Top fitness: 0.10588235294117647\n",
      "Cost: 76, Top fitness: 0.10588235294117647\n",
      "Cost: 79, Top fitness: 0.10588235294117647\n",
      "Cost: 80, Top fitness: 0.10588235294117647\n",
      "Cost: 80, Top fitness: 0.10588235294117647\n",
      "Cost: 80, Top fitness: 0.10588235294117647\n",
      "Cost: 81, Top fitness: 0.10588235294117647\n",
      "Cost: 82, Top fitness: 0.10588235294117647\n",
      "Cost: 83, Top fitness: 0.10588235294117647\n",
      "Cost: 84, Top fitness: 0.10588235294117647\n",
      "Cost: 84, Top fitness: 0.10588235294117647\n",
      "Cost: 86, Top fitness: 0.10588235294117647\n",
      "Cost: 87, Top fitness: 0.10588235294117647\n",
      "Cost: 89, Top fitness: 0.10588235294117647\n",
      "Cost: 90, Top fitness: 0.10588235294117647\n",
      "Cost: 90, Top fitness: 0.10588235294117647\n",
      "Cost: 90, Top fitness: 0.10588235294117647\n",
      "Cost: 90, Top fitness: 0.10588235294117647\n",
      "Cost: 91, Top fitness: 0.10588235294117647\n",
      "Cost: 91, Top fitness: 0.10588235294117647\n",
      "Cost: 91, Top fitness: 0.10588235294117647\n",
      "Cost: 91, Top fitness: 0.10588235294117647\n",
      "Cost: 91, Top fitness: 0.10588235294117647\n",
      "Cost: 91, Top fitness: 0.10588235294117647\n",
      "Cost: 92, Top fitness: 0.10588235294117647\n",
      "Cost: 93, Top fitness: 0.10588235294117647\n",
      "Cost: 93, Top fitness: 0.10588235294117647\n",
      "Cost: 93, Top fitness: 0.10588235294117647\n",
      "Cost: 94, Top fitness: 0.10588235294117647\n",
      "Cost: 94, Top fitness: 0.10588235294117647\n",
      "Cost: 95, Top fitness: 0.10588235294117647\n",
      "Cost: 95, Top fitness: 0.10588235294117647\n",
      "Cost: 95, Top fitness: 0.10588235294117647\n",
      "Cost: 97, Top fitness: 0.10588235294117647\n",
      "Cost: 98, Top fitness: 0.11294118095846738\n",
      "Cost: 99, Top fitness: 0.11411764481488396\n",
      "Cost: 101, Top fitness: 0.11411764481488396\n"
     ]
    }
   ],
   "source": [
    "agent_reward_freq = RL_agent_DQN(landscape=noisy_landscape, start_sequence=wt,\n",
    "                     alphabet=RAA, gamma=0.8, memory_size=10000,\n",
    "                     device=device, experiment_batch_size=experiment_batch_size)\n",
    "\n",
    "noisy_landscape.reset()\n",
    "noisy_landscape.measure_true_landscape(initial_genotypes)\n",
    "noisy_landscape.natural_mode=False\n",
    "noisy_landscape.local_mode=False\n",
    "noisy_landscape.cost\n",
    "\n",
    "while noisy_landscape.cost < generations*experiment_batch_size:\n",
    "    agent_reward_freq.pick_action_reward_freq()\n",
    "    print(f\"Cost: {noisy_landscape.cost}, Top fitness: {agent_reward_freq.top_sequence[-1][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "#plt.xscale(\"log\")\n",
    "plt.title(f\"Batch size: {experiment_batch_size}; Generations: {generations}; Noise: {noise_alpha}\")\n",
    "plt.xlabel(\"number of batches tested\")\n",
    "plt.ylabel(\"maximum fitness observed\")\n",
    "plt.plot([t[2]/experiment_batch_size for t in agent.top_sequence[1:]],[t[0] for t in agent.top_sequence[1:]],label=\"RL DQN PER\")\n",
    "plt.plot([t[2]/experiment_batch_size for t in agent_reward_freq.top_sequence[1:]],[t[0] for t in agent_reward_freq.top_sequence[1:]],label=\"RL DQN PER reward freq\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(range(generations));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
