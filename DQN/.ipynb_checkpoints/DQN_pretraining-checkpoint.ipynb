{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import editdistance\n",
    "from collections import deque\n",
    "import sys\n",
    "import RNA\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "from utils.sequence_utils import translate_one_hot_to_string,generate_random_mutant\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from utils.sequence_utils import *\n",
    "from models.Theoretical_models import *\n",
    "from models.Noise_wrapper import *\n",
    "from exploration_strategies.CE import *\n",
    "from utils.landscape_utils import *\n",
    "from models.RNA_landscapes import *\n",
    "from models.Multi_dimensional_model import *\n",
    "from exploration_strategies.BGE import *\n",
    "from exploration_strategies.CE2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAA=\"UGCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_alpha=1\n",
    "batch_size=100\n",
    "virtual_per_measure_ratio=100\n",
    "temperature=0.01\n",
    "generations=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GCGUCGGGAAAAUCCAGCCCAACACCCUGUUGUCUUCAGGCGCCCGUGAUUGGAUCCCCGCCAUGAGGUGCUAGAUGUCCGUGGAGUAGAUGACAUCUCG',\n",
       " ['..((.((......)).)).(((((...)))))......((((((((((..(((....))).)))).))))))(((((((.((.......)))))))))..',\n",
       "  -26.100000381469727])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wts=generate_random_sequences(100,1000,alphabet=RAA)\n",
    "for wt in wts:\n",
    "    if RNA.fold(wt)[1]<0:\n",
    "        break\n",
    "wt,RNA.fold(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 0.3070588280172909)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_landscape = RNA_landscape(wt)\n",
    "len(wt), base_landscape.get_fitness(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_genotypes = list(set([wt]+[generate_random_mutant(wt,0.05,RAA) for i in range(batch_size*10)]))[:batch_size]\n",
    "len(initial_genotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import bisect\n",
    "from utils.sequence_utils import translate_string_to_one_hot, translate_one_hot_to_string\n",
    "\n",
    "def renormalize_moves(one_hot_input, rewards_output):\n",
    "    \"\"\"ensures that staying in place gives no reward\"\"\"\n",
    "    zero_current_state = (one_hot_input - 1) * (-1)\n",
    "    return np.multiply(rewards_output, zero_current_state)\n",
    "\n",
    "def walk_away_renormalize_moves(one_hot_input, one_hot_wt, rewards_output):\n",
    "    \"\"\"ensures that moving toward wt is also not useful\"\"\"\n",
    "    zero_current_state=(one_hot_input-1)*-1\n",
    "    zero_wt=((one_hot_wt-1)*-1)\n",
    "    zero_conservative_moves=np.multiply(zero_wt,zero_current_state)\n",
    "    return np.multiply(rewards_output,zero_conservative_moves)\n",
    "\n",
    "def get_all_singles_fitness(model,sequence,alphabet):\n",
    "    prob_singles=np.zeros((len(alphabet),len(sequence)))\n",
    "    for i in range(len(sequence)):\n",
    "        for j in range(len(alphabet)):\n",
    "            putative_seq=sequence[:i]+alphabet[j]+sequence[i+1:]\n",
    "           # print (putative_seq)\n",
    "            prob_singles[j][i]=model.get_fitness(putative_seq)\n",
    "    return prob_singles\n",
    "\n",
    "def get_all_mutants(sequence):\n",
    "    mutants = []\n",
    "    for i in range(sequence.shape[0]):\n",
    "        for j in range(sequence.shape[1]):\n",
    "            putative_seq = sequence.copy()\n",
    "            putative_seq[:, j] = 0\n",
    "            putative_seq[i, j] = 1\n",
    "            mutants.append(putative_seq)\n",
    "    return np.array(mutants)\n",
    "\n",
    "def sample_greedy(matrix):\n",
    "    i,j=matrix.shape\n",
    "    max_arg=np.argmax(matrix)\n",
    "    y=max_arg%j\n",
    "    x=int(max_arg/j)\n",
    "    output=np.zeros((i,j))\n",
    "    output[x][y]=matrix[x][y]\n",
    "    return output\n",
    "\n",
    "def sample_multi_greedy(matrix):\n",
    "    n = 5 # the number of base positions to greedily change\n",
    "    max_args = np.argpartition(matrix.flatten(), -n)[-n:]\n",
    "    i,j=matrix.shape\n",
    "    output=np.zeros((i,j))\n",
    "    for max_arg in max_args:\n",
    "        y=max_arg%j\n",
    "        x=int(max_arg/j)\n",
    "        output[x][y]=matrix[x][y]\n",
    "    return output\n",
    "\n",
    "def sample_random(matrix):\n",
    "    i,j=matrix.shape\n",
    "    non_zero_moves=np.nonzero(matrix)\n",
    "   # print (non_zero_moves)\n",
    "    k=len(non_zero_moves)\n",
    "    l=len(non_zero_moves[0])\n",
    "    if k!=0 and l!=0:\n",
    "        rand_arg=random.choice([[non_zero_moves[alph][pos] for alph in range(k)] for pos in range(l)])\n",
    "    else:\n",
    "        rand_arg=[random.randint(0,i-1),random.randint(0,j-1)]\n",
    "    #print (rand_arg)\n",
    "    y=rand_arg[1]\n",
    "    x=rand_arg[0]\n",
    "    output=np.zeros((i,j))\n",
    "    output[x][y] = 1\n",
    "    return output   \n",
    "\n",
    "def action_to_scalar(matrix):\n",
    "    matrix = matrix.ravel()\n",
    "    for i in range(len(matrix)):\n",
    "        if matrix[i] != 0:\n",
    "            return i\n",
    "    \n",
    "def construct_mutant_from_sample(pwm_sample, one_hot_base):\n",
    "    one_hot = np.zeros(one_hot_base.shape)\n",
    "    one_hot += one_hot_base\n",
    "    nonzero = np.nonzero(pwm_sample)\n",
    "    nonzero = list(zip(nonzero[0], nonzero[1]))\n",
    "    for nz in nonzero: # this can be problematic for non-positive fitnesses\n",
    "        i, j = nz\n",
    "        one_hot[:,j]=0\n",
    "        one_hot[i,j]=1\n",
    "    return one_hot\n",
    "\n",
    "def best_predicted_new_gen(actor, genotypes, alphabet, pop_size):\n",
    "    mutants = get_all_mutants(genotypes)\n",
    "    one_hot_mutants = np.array([translate_string_to_one_hot(mutant, alphabet) for mutant in mutants])\n",
    "    torch_one_hot_mutants = torch.from_numpy(np.expand_dims(one_hot_mutants, axis=0)).float()\n",
    "    predictions = actor(torch_one_hot_mutants)\n",
    "    predictions = predictions.detach().numpy()\n",
    "    best_pred_ind = predictions.argsort()[-pop_size:]\n",
    "    return mutants[best_pred_ind]\n",
    "\n",
    "def make_one_hot_train_test(genotypes, model, alphabet):\n",
    "    genotypes_one_hot = np.array([translate_string_to_one_hot(genotype, alphabet) for genotype in genotypes])\n",
    "    genotype_fitnesses = []\n",
    "    for genotype in genotypes:\n",
    "        genotype_fitnesses.append(model.get_fitness(genotype))\n",
    "    genotype_fitnesses = np.array(genotype_fitnesses)\n",
    "\n",
    "    return genotypes_one_hot, genotype_fitnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from utils.sequence_utils import translate_one_hot_to_string,generate_random_mutant\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Q_Network(nn.Module):\n",
    "    def __init__(self, sequence_len, alphabet_len):\n",
    "        super(Q_Network, self).__init__()\n",
    "        self.sequence_len = sequence_len\n",
    "        self.alphabet_len = alphabet_len\n",
    "        self.linear1 = nn.Linear(alphabet_len * sequence_len, alphabet_len * sequence_len)\n",
    "        self.bn1 = nn.BatchNorm1d(alphabet_len * sequence_len)\n",
    "        self.linear2 = nn.Linear(alphabet_len * sequence_len, sequence_len)\n",
    "        self.bn2 = nn.BatchNorm1d(sequence_len)\n",
    "        self.linear3 = nn.Linear(sequence_len, sequence_len)\n",
    "        self.bn3 = nn.BatchNorm1d(sequence_len)\n",
    "        self.linear4 = nn.Linear(sequence_len, alphabet_len * sequence_len)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.alphabet_len * self.sequence_len)\n",
    "        x = self.bn1(F.relu(self.linear1(x)))\n",
    "        x = self.bn2(F.relu(self.linear2(x)))\n",
    "        x = self.bn3(F.relu(self.linear3(x)))\n",
    "        x = F.relu(self.linear4(x))\n",
    "        return x\n",
    "    \n",
    "def build_q_network(sequence_len, alphabet_len, device):\n",
    "    model = Q_Network(sequence_len, alphabet_len).to(device)\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "class RL_agent_DQN():\n",
    "    '''\n",
    "    Based off https://colab.research.google.com/drive/1NsbSPn6jOcaJB_mp9TmkgQX7UrRIrTi0\n",
    "    '''\n",
    "    def __init__(self, start_sequence, alphabet, gamma=0.9, \n",
    "                 memory_size=1000, batch_size=1000, experiment_batch_size=1000,\n",
    "                 device=\"cpu\", noise_alpha=1, noisy_landscape=None, q_network=None):\n",
    "        self.alphabet = alphabet\n",
    "        self.state = translate_string_to_one_hot(start_sequence, self.alphabet)\n",
    "        self.seq_size = len(start_sequence)\n",
    "        if q_network:\n",
    "            self.q_network = q_network\n",
    "        else:\n",
    "            self.q_network = build_q_network(self.seq_size, len(self.alphabet), device)\n",
    "        self.start_sequence = translate_string_to_one_hot(start_sequence,self.alphabet)\n",
    "        self.memory_size = memory_size\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.experiment_batch_size = experiment_batch_size\n",
    "        self.memory = deque(maxlen=self.memory_size)\n",
    "        self.seen_sequences = []\n",
    "        if noisy_landscape:\n",
    "            self.landscape = noisy_landscape\n",
    "        else:\n",
    "            self.landscape = Noise_wrapper(RNA_landscape(start_sequence), \n",
    "                                       noise_alpha=noise_alpha, always_costly=True)\n",
    "        self.best_fitness = 0\n",
    "        self.eps = 1.\n",
    "        self.eps_decay = 0.995\n",
    "\n",
    "    def reset_position(self,sequence):\n",
    "        self.state=translate_string_to_one_hot(sequence,self.alphabet)\n",
    "\n",
    "    def get_position(self):\n",
    "        return translate_one_hot_to_string(self.state,self.alphabet)\n",
    "\n",
    "    def translate_pwm_to_sequence(self,input_seq_one_hot,output_pwm):\n",
    "        diff=output_pwm-input_seq_one_hot\n",
    "        most_likely=np.argmax(diff,axis=0)\n",
    "        out_seq=\"\"\n",
    "        for m in most_likely:\n",
    "            out_seq+=self.alphabet[m]\n",
    "        return out_seq\n",
    "    \n",
    "    def sample(self):\n",
    "        indices = np.random.choice(len(self.memory), self.batch_size)\n",
    "        rewards, actions, states, next_states = zip(*[self.memory[ind] for ind in indices])\n",
    "        return np.array(rewards), np.array(actions), np.array(states), np.array(next_states) \n",
    "    \n",
    "    def q_network_loss(self, batch, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Calculate MSE between actual state action values,\n",
    "        and expected state action values from DQN\n",
    "        \"\"\"\n",
    "        rewards, actions, states, next_states = batch\n",
    "\n",
    "        rewards_v = torch.tensor(rewards).float()\n",
    "        actions_v = torch.tensor(actions).float()\n",
    "        states_v = torch.tensor(states).float()\n",
    "        next_states_v = torch.tensor(next_states).float()\n",
    "\n",
    "        state_action_values = self.q_network(states_v).gather(1, actions_v.long().unsqueeze(-1)).squeeze(-1)\n",
    "        next_state_values = self.q_network(next_states_v).max(1)[0]\n",
    "        next_state_values = next_state_values.detach()\n",
    "        expected_state_action_values = next_state_values * self.gamma + rewards_v\n",
    "        \n",
    "        return nn.MSELoss()(state_action_values, expected_state_action_values)\n",
    "\n",
    "    def train_actor(self, train_epochs=10):\n",
    "        total_loss = 0.\n",
    "        # train Q network on new samples \n",
    "        optimizer = optim.Adam(self.q_network.parameters(), lr=0.0001)\n",
    "        for epoch in range(train_epochs):\n",
    "            batch = self.sample()\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.q_network_loss(batch)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(self.q_network.parameters(), 1.0, norm_type=1)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        return (total_loss / train_epochs)\n",
    "\n",
    "    def pick_action(self, epsilon):\n",
    "        prediction = self.q_network(torch.tensor(self.state).float()).detach().numpy()[0]\n",
    "        prediction = prediction.reshape((len(self.alphabet), self.seq_size))\n",
    "        # make action\n",
    "        moves = renormalize_moves(self.state, prediction)\n",
    "        p = random.random()\n",
    "        action = sample_random(moves) if p < epsilon else sample_greedy(moves)\n",
    "        # get next state (mutant)\n",
    "        mutant = construct_mutant_from_sample(action, self.state)\n",
    "        mutant_string = translate_one_hot_to_string(mutant, self.alphabet)\n",
    "        self.state = mutant\n",
    "\n",
    "        return action_to_scalar(action), mutant\n",
    "    \n",
    "    def run_RL(self, generations=10, train_epochs=10, epsilon_min=0.1):\n",
    "        self.q_network.eval()\n",
    "        while self.landscape.cost < self.experiment_batch_size*generations:\n",
    "            eps = max(epsilon_min, (1.0 - self.landscape.cost / (self.experiment_batch_size * generations)))\n",
    "#             eps = max(epsilon_min, self.eps)\n",
    "            b = 0\n",
    "            new = []\n",
    "            while (b < self.experiment_batch_size):\n",
    "                state = self.state.copy() \n",
    "                \n",
    "                action, new_state = agent.pick_action(eps)\n",
    "                old_state_string = translate_one_hot_to_string(state, self.alphabet)\n",
    "                new_state_string = translate_one_hot_to_string(new_state, self.alphabet)\n",
    "                reward = self.landscape.get_fitness(new_state_string)\n",
    "                                \n",
    "                # remember seen sequences\n",
    "                self.seen_sequences.append(new_state_string)\n",
    "                \n",
    "                if not new_state_string in self.landscape.measured_sequences:\n",
    "                    if reward > self.best_fitness:\n",
    "                        prediction = self.q_network(torch.tensor(self.state).float()).detach().numpy()[0]\n",
    "                        # print(prediction)\n",
    "                    self.best_fitness = max(self.best_fitness, reward)\n",
    "                    self.memory.append((reward, action, state, new_state))\n",
    "                    b += 1\n",
    "            \n",
    "#             self.memory = sorted(self.memory, key = lambda x: x[0])\n",
    "            self.eps = eps * self.eps_decay\n",
    "            avg_loss = agent.train_actor(train_epochs)\n",
    "            print(f\"Cost: {self.landscape.cost}, Score: {self.best_fitness}, Loss: {avg_loss}\")\n",
    "            \n",
    "        return (translate_one_hot_to_string(self.memory[-1][2], self.alphabet), self.memory[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_landscape = Noise_wrapper(base_landscape, noise_alpha=1, always_costly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_landscape.reset()\n",
    "noisy_landscape.measure_true_landscape(initial_genotypes)\n",
    "noisy_landscape.natural_mode=True\n",
    "noisy_landscape.local_mode=False\n",
    "noisy_landscape.cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with the wild type at every iteration, and let the agent explore over many batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Network(\n",
      "  (linear1): Linear(in_features=400, out_features=400, bias=True)\n",
      "  (bn1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear2): Linear(in_features=400, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear3): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (bn3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear4): Linear(in_features=100, out_features=400, bias=True)\n",
      ")\n",
      "Cost: 101, Score: 0.4200000089757583, Loss: 0.14298971891403198\n",
      "Cost: 201, Score: 0.4200000089757583, Loss: 0.11174212843179702\n",
      "Cost: 292, Score: 0.4200000089757583, Loss: 0.09199151247739792\n",
      "Cost: 359, Score: 0.4200000089757583, Loss: 0.08725345581769943\n",
      "Cost: 410, Score: 0.4200000089757583, Loss: 0.09633873850107193\n",
      "Cost: 435, Score: 0.4200000089757583, Loss: 0.08127163499593734\n",
      "Cost: 458, Score: 0.4200000089757583, Loss: 0.05882741585373878\n",
      "Cost: 485, Score: 0.4200000089757583, Loss: 0.03625807240605354\n",
      "Cost: 498, Score: 0.4200000089757583, Loss: 0.020883533358573913\n",
      "Cost: 521, Score: 0.4200000089757583, Loss: 0.03803674504160881\n",
      "Cost: 101, Score: 0.38352939381318935, Loss: 0.1602119594812393\n",
      "Cost: 193, Score: 0.38352939381318935, Loss: 0.11381571888923644\n",
      "Cost: 283, Score: 0.38352939381318935, Loss: 0.13308868408203126\n",
      "Cost: 357, Score: 0.38823529411764707, Loss: 0.13713591694831848\n",
      "Cost: 409, Score: 0.38823529411764707, Loss: 0.07648543119430543\n",
      "Cost: 447, Score: 0.38823529411764707, Loss: 0.049145332723855975\n",
      "Cost: 473, Score: 0.38823529411764707, Loss: 0.038146693632006644\n",
      "Cost: 502, Score: 0.38823529411764707, Loss: 0.03130786865949631\n",
      "Cost: 97, Score: 0.39058824426987593, Loss: 0.30858447551727297\n",
      "Cost: 189, Score: 0.39058824426987593, Loss: 0.25721033215522765\n",
      "Cost: 275, Score: 0.39058824426987593, Loss: 0.2431479275226593\n",
      "Cost: 353, Score: 0.39058824426987593, Loss: 0.196492937207222\n",
      "Cost: 406, Score: 0.39058824426987593, Loss: 0.11726704388856887\n",
      "Cost: 422, Score: 0.39058824426987593, Loss: 0.09555621296167374\n",
      "Cost: 465, Score: 0.4023529501522289, Loss: 0.19187081903219222\n",
      "Cost: 479, Score: 0.4023529501522289, Loss: 0.0478909008204937\n",
      "Cost: 502, Score: 0.4023529501522289, Loss: 0.10073446109890938\n",
      "Cost: 101, Score: 0.38823529411764707, Loss: 0.571293044090271\n",
      "Cost: 198, Score: 0.38823529411764707, Loss: 0.6301337480545044\n",
      "Cost: 286, Score: 0.38823529411764707, Loss: 0.5681272864341735\n",
      "Cost: 357, Score: 0.4, Loss: 0.39853633642196656\n",
      "Cost: 417, Score: 0.41647060618681064, Loss: 0.38466871678829195\n",
      "Cost: 448, Score: 0.4282353120691636, Loss: 0.21162684559822081\n",
      "Cost: 476, Score: 0.4282353120691636, Loss: 0.17197214365005492\n",
      "Cost: 493, Score: 0.4282353120691636, Loss: 0.13547462224960327\n",
      "Cost: 514, Score: 0.4282353120691636, Loss: 0.1304166566580534\n",
      "Cost: 101, Score: 0.36117647956399357, Loss: 1.111624264717102\n",
      "Cost: 195, Score: 0.36117647956399357, Loss: 1.0644317746162415\n",
      "Cost: 281, Score: 0.40823530309340533, Loss: 0.9455805540084838\n",
      "Cost: 343, Score: 0.40823530309340533, Loss: 0.6290986061096191\n",
      "Cost: 403, Score: 0.40823530309340533, Loss: 0.7764099359512329\n",
      "Cost: 428, Score: 0.40823530309340533, Loss: 0.15730900168418885\n",
      "Cost: 461, Score: 0.40823530309340533, Loss: 0.36010665595531466\n",
      "Cost: 476, Score: 0.40823530309340533, Loss: 0.1252944495412521\n",
      "Cost: 491, Score: 0.40823530309340533, Loss: 0.057314789132215084\n",
      "Cost: 521, Score: 0.4141176560345818, Loss: 0.31615275144577026\n",
      "Cost: 100, Score: 0.4117647058823529, Loss: 1.4677685499191284\n",
      "Cost: 195, Score: 0.41529410867130057, Loss: 1.3623364210128783\n",
      "Cost: 289, Score: 0.41529410867130057, Loss: 1.2195056915283202\n",
      "Cost: 356, Score: 0.4776470408720129, Loss: 1.0988016247749328\n",
      "Cost: 412, Score: 0.4776470408720129, Loss: 0.9684933662414551\n",
      "Cost: 450, Score: 0.4776470408720129, Loss: 0.3466894328594208\n",
      "Cost: 471, Score: 0.4776470408720129, Loss: 0.25904744463041424\n",
      "Cost: 496, Score: 0.4776470408720129, Loss: 0.19466840773820876\n",
      "Cost: 521, Score: 0.4776470408720129, Loss: 0.2011364296078682\n",
      "Cost: 100, Score: 0.43294116749482997, Loss: 1.4414088249206543\n",
      "Cost: 192, Score: 0.43294116749482997, Loss: 1.6631099462509156\n",
      "Cost: 275, Score: 0.4717646879308364, Loss: 1.295055890083313\n",
      "Cost: 335, Score: 0.4717646879308364, Loss: 1.0145233273506165\n",
      "Cost: 399, Score: 0.4717646879308364, Loss: 0.6384788155555725\n",
      "Cost: 420, Score: 0.4717646879308364, Loss: 0.3729552537202835\n",
      "Cost: 450, Score: 0.4717646879308364, Loss: 0.4508584201335907\n",
      "Cost: 467, Score: 0.4717646879308364, Loss: 0.21934508522972465\n",
      "Cost: 489, Score: 0.4717646879308364, Loss: 0.14520670138299466\n",
      "Cost: 510, Score: 0.4717646879308364, Loss: 0.09056630367413163\n",
      "Cost: 101, Score: 0.4764705882352941, Loss: 1.4907101392745972\n",
      "Cost: 194, Score: 0.4764705882352941, Loss: 1.1136037707328796\n",
      "Cost: 280, Score: 0.4764705882352941, Loss: 0.6775386810302735\n",
      "Cost: 342, Score: 0.4764705882352941, Loss: 0.6111618459224701\n",
      "Cost: 400, Score: 0.4764705882352941, Loss: 0.49588547050952914\n",
      "Cost: 443, Score: 0.4764705882352941, Loss: 0.742302417755127\n",
      "Cost: 462, Score: 0.4764705882352941, Loss: 0.22758059948682785\n",
      "Cost: 487, Score: 0.4764705882352941, Loss: 0.3338549226522446\n",
      "Cost: 508, Score: 0.4764705882352941, Loss: 0.22830460965633392\n",
      "Cost: 101, Score: 0.4282353120691636, Loss: 2.1691885471343992\n",
      "Cost: 199, Score: 0.4282353120691636, Loss: 2.762099266052246\n",
      "Cost: 275, Score: 0.4282353120691636, Loss: 1.7214614272117614\n",
      "Cost: 349, Score: 0.4282353120691636, Loss: 1.4888669967651367\n",
      "Cost: 398, Score: 0.4282353120691636, Loss: 1.3041898548603057\n",
      "Cost: 441, Score: 0.4282353120691636, Loss: 1.203765070438385\n",
      "Cost: 467, Score: 0.4282353120691636, Loss: 0.6522542059421539\n",
      "Cost: 486, Score: 0.4282353120691636, Loss: 0.3614744579419494\n",
      "Cost: 511, Score: 0.4282353120691636, Loss: 0.43679843527497725\n",
      "Cost: 101, Score: 0.38823529411764707, Loss: 3.374851703643799\n",
      "Cost: 197, Score: 0.38823529411764707, Loss: 3.27657151222229\n",
      "Cost: 284, Score: 0.38823529411764707, Loss: 3.2945626020431518\n",
      "Cost: 353, Score: 0.38823529411764707, Loss: 2.230986309051514\n",
      "Cost: 402, Score: 0.3941176470588235, Loss: 1.7401313781738281\n",
      "Cost: 430, Score: 0.44000001795151655, Loss: 1.6629585146903991\n",
      "Cost: 450, Score: 0.44941177368164065, Loss: 0.4151464939117432\n",
      "Cost: 477, Score: 0.44941177368164065, Loss: 0.7533749639987946\n",
      "Cost: 494, Score: 0.44941177368164065, Loss: 0.6511560529470444\n",
      "Cost: 507, Score: 0.44941177368164065, Loss: 0.16030954306479545\n"
     ]
    }
   ],
   "source": [
    "initial_genotypes = list([wt])\n",
    "generations = 5\n",
    "experiment_batch_size = 100\n",
    "# for sampling for training\n",
    "batch_size = 20\n",
    "\n",
    "noisy_landscape = Noise_wrapper(base_landscape, noise_alpha=1, always_costly=True)\n",
    "noisy_landscape.reset()\n",
    "noisy_landscape.measure_true_landscape(initial_genotypes)\n",
    "noisy_landscape.natural_mode=True\n",
    "noisy_landscape.local_mode=False\n",
    "noisy_landscape.cost\n",
    "\n",
    "# initialize fresh agent\n",
    "agent = RL_agent_DQN(wt, alphabet=RAA, gamma=0.8,\n",
    "                     memory_size=100, device=device,\n",
    "                     experiment_batch_size=experiment_batch_size,\n",
    "                     noisy_landscape=noisy_landscape)\n",
    "q_network = agent.q_network\n",
    "\n",
    "for i in range(10):\n",
    "    # reset landscape\n",
    "    noisy_landscape = Noise_wrapper(base_landscape, noise_alpha=1, always_costly=True)\n",
    "    noisy_landscape.reset()\n",
    "    noisy_landscape.measure_true_landscape(initial_genotypes)\n",
    "    noisy_landscape.natural_mode=True\n",
    "    noisy_landscape.local_mode=False\n",
    "    noisy_landscape.cost\n",
    "    \n",
    "    # initialize agent with old q_network\n",
    "    agent = RL_agent_DQN(wt, alphabet=RAA, gamma=0.8,\n",
    "                     memory_size=100, device=device,\n",
    "                     experiment_batch_size=experiment_batch_size,\n",
    "                     noisy_landscape=noisy_landscape,\n",
    "                     q_network=q_network,\n",
    "                     batch_size=batch_size)\n",
    "    \n",
    "    # run agent\n",
    "    agent.run_RL(generations=generations, train_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_fitnesses_DQN = get_distance_fitness(wt, noisy_landscape)\n",
    "plt.scatter([x[0] for x in seq_fitnesses_DQN],[x[1] for x in seq_fitnesses_DQN])\n",
    "plt.xlabel(\"Sequence edit distance\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
