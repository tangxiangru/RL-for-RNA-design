{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os \n",
    "from collections import deque, Counter\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import editdistance\n",
    "import sys\n",
    "import RNA\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# import path \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.sequence_utils import translate_one_hot_to_string,generate_random_mutant\n",
    "from models.Theoretical_models import *\n",
    "from models.Noise_wrapper import *\n",
    "# from exploration_strategies.CE import *\n",
    "from utils.landscape_utils import *\n",
    "from models.RNA_landscapes import *\n",
    "from models.Multi_dimensional_model import *\n",
    "\n",
    "from segment_tree import MinSegmentTree, SumSegmentTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAA=\"UGCA\" #alphabet\n",
    "length=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GGUCCCAUAGAUUGCGUCUGAGGCGUAUAUGCGGCAUCCC'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt=generate_random_sequences(length,1,alphabet=RAA)[0]\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a simple folding landscape starting at wt\n",
    "landscape1=RNA_landscape(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_alpha=1\n",
    "experiment_batch_size=100\n",
    "virtual_per_measure_ratio=15\n",
    "temperature=0.1\n",
    "generations=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are multiple abstract \"noise models\" you can use, or you can try to train your own model, using skM\n",
    "noisy_landscape=Noise_wrapper(landscape1,\n",
    "                              noise_alpha=noise_alpha,\n",
    "                              always_costly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_genotypes=list(set([wt]+[generate_random_mutant(wt,0.05,RAA) for i in range(experiment_batch_size*10)]))[:experiment_batch_size]\n",
    "len(initial_genotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_landscape.reset()\n",
    "noisy_landscape.measure_true_landscape(initial_genotypes)\n",
    "noisy_landscape.natural_mode=False\n",
    "noisy_landscape.local_mode=False\n",
    "noisy_landscape.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import bisect\n",
    "from utils.sequence_utils import translate_string_to_one_hot, translate_one_hot_to_string\n",
    "\n",
    "def renormalize_moves(one_hot_input, rewards_output):\n",
    "    \"\"\"ensures that staying in place gives no reward\"\"\"\n",
    "    zero_current_state = (one_hot_input - 1) * (-1)\n",
    "    return np.multiply(rewards_output, zero_current_state)\n",
    "\n",
    "def walk_away_renormalize_moves(one_hot_input, one_hot_wt, rewards_output):\n",
    "    \"\"\"ensures that moving toward wt is also not useful\"\"\"\n",
    "    zero_current_state=(one_hot_input-1)*-1\n",
    "    zero_wt=((one_hot_wt-1)*-1)\n",
    "    zero_conservative_moves=np.multiply(zero_wt,zero_current_state)\n",
    "    return np.multiply(rewards_output,zero_conservative_moves)\n",
    "\n",
    "def get_all_singles_fitness(model,sequence,alphabet):\n",
    "    prob_singles=np.zeros((len(alphabet),len(sequence)))\n",
    "    for i in range(len(sequence)):\n",
    "        for j in range(len(alphabet)):\n",
    "            putative_seq=sequence[:i]+alphabet[j]+sequence[i+1:]\n",
    "           # print (putative_seq)\n",
    "            prob_singles[j][i]=model.get_fitness(putative_seq)\n",
    "    return prob_singles\n",
    "\n",
    "def get_all_mutants(sequence):\n",
    "    mutants = []\n",
    "    for i in range(sequence.shape[0]):\n",
    "        for j in range(sequence.shape[1]):\n",
    "            putative_seq = sequence.copy()\n",
    "            putative_seq[:, j] = 0\n",
    "            putative_seq[i, j] = 1\n",
    "            mutants.append(putative_seq)\n",
    "    return np.array(mutants)\n",
    "\n",
    "def sample_greedy(matrix):\n",
    "    i,j=matrix.shape\n",
    "    max_arg=np.argmax(matrix)\n",
    "    y=max_arg%j\n",
    "    x=int(max_arg/j)\n",
    "    output=np.zeros((i,j))\n",
    "    output[x][y]=matrix[x][y]\n",
    "    return output\n",
    "\n",
    "def sample_multi_greedy(matrix):\n",
    "    n = 5 # the number of base positions to greedily change\n",
    "    max_args = np.argpartition(matrix.flatten(), -n)[-n:]\n",
    "    i,j=matrix.shape\n",
    "    output=np.zeros((i,j))\n",
    "    for max_arg in max_args:\n",
    "        y=max_arg%j\n",
    "        x=int(max_arg/j)\n",
    "        output[x][y]=matrix[x][y]\n",
    "    return output\n",
    "\n",
    "def sample_random(matrix):\n",
    "    i,j=matrix.shape\n",
    "    non_zero_moves=np.nonzero(matrix)\n",
    "   # print (non_zero_moves)\n",
    "    k=len(non_zero_moves)\n",
    "    l=len(non_zero_moves[0])\n",
    "    if k!=0 and l!=0:\n",
    "        rand_arg=random.choice([[non_zero_moves[alph][pos] for alph in range(k)] for pos in range(l)])\n",
    "    else:\n",
    "        rand_arg=[random.randint(0,i-1),random.randint(0,j-1)]\n",
    "    #print (rand_arg)\n",
    "    y=rand_arg[1]\n",
    "    x=rand_arg[0]\n",
    "    output=np.zeros((i,j))\n",
    "    output[x][y] = 1\n",
    "    return output   \n",
    "\n",
    "def action_to_scalar(matrix):\n",
    "    matrix = matrix.ravel()\n",
    "    for i in range(len(matrix)):\n",
    "        if matrix[i] != 0:\n",
    "            return i\n",
    "    \n",
    "def construct_mutant_from_sample(pwm_sample, one_hot_base):\n",
    "    one_hot = np.zeros(one_hot_base.shape)\n",
    "    one_hot += one_hot_base\n",
    "    nonzero = np.nonzero(pwm_sample)\n",
    "    nonzero = list(zip(nonzero[0], nonzero[1]))\n",
    "    for nz in nonzero: # this can be problematic for non-positive fitnesses\n",
    "        i, j = nz\n",
    "        one_hot[:,j]=0\n",
    "        one_hot[i,j]=1\n",
    "    return one_hot\n",
    "\n",
    "def best_predicted_new_gen(actor, genotypes, alphabet, pop_size):\n",
    "    mutants = get_all_mutants(genotypes)\n",
    "    one_hot_mutants = np.array([translate_string_to_one_hot(mutant, alphabet) for mutant in mutants])\n",
    "    torch_one_hot_mutants = torch.from_numpy(np.expand_dims(one_hot_mutants, axis=0)).float()\n",
    "    predictions = actor(torch_one_hot_mutants)\n",
    "    predictions = predictions.detach().numpy()\n",
    "    best_pred_ind = predictions.argsort()[-pop_size:]\n",
    "    return mutants[best_pred_ind]\n",
    "\n",
    "def make_one_hot_train_test(genotypes, model, alphabet):\n",
    "    genotypes_one_hot = np.array([translate_string_to_one_hot(genotype, alphabet) for genotype in genotypes])\n",
    "    genotype_fitnesses = []\n",
    "    for genotype in genotypes:\n",
    "        genotype_fitnesses.append(model.get_fitness(genotype))\n",
    "    genotype_fitnesses = np.array(genotype_fitnesses)\n",
    "\n",
    "    return genotypes_one_hot, genotype_fitnesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 128):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        obs: np.ndarray,\n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray\n",
    "    ):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \n",
    "    Attributes:\n",
    "        max_priority (float): max priority\n",
    "        tree_ptr (int): next index of tree\n",
    "        alpha (float): alpha parameter for prioritized replay buffer\n",
    "        sum_tree (SumSegmentTree): sum tree for prior\n",
    "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int,\n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        alpha: float = 0.6\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        assert alpha >= 0\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(obs_dim, size, batch_size)\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: int, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray\n",
    "    ):\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        super().store(obs, act, rew, next_obs)\n",
    "        \n",
    "        self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "        self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "        self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        assert len(self) >= self.batch_size\n",
    "        assert beta > 0\n",
    "        \n",
    "        indices = self._sample_proportional()\n",
    "        \n",
    "        obs = self.obs_buf[indices]\n",
    "        next_obs = self.next_obs_buf[indices]\n",
    "        acts = self.acts_buf[indices]\n",
    "        rews = self.rews_buf[indices]\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        \n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "        \n",
    "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        assert len(indices) == len(priorities)\n",
    "\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self)\n",
    "\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "    def _sample_proportional(self) -> List[int]:\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        indices = []\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        segment = p_total / self.batch_size\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            upperbound = random.uniform(a, b)\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            indices.append(idx)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_Network(nn.Module):\n",
    "    def __init__(self, sequence_len, alphabet_len):\n",
    "        super(Q_Network, self).__init__()\n",
    "        self.sequence_len = sequence_len\n",
    "        self.alphabet_len = alphabet_len\n",
    "        self.linear1 = nn.Linear(2 * alphabet_len * sequence_len, alphabet_len * sequence_len)\n",
    "        self.bn1 = nn.BatchNorm1d(alphabet_len * sequence_len)\n",
    "        self.linear2 = nn.Linear(alphabet_len * sequence_len, sequence_len)\n",
    "        self.bn2 = nn.BatchNorm1d(sequence_len)\n",
    "        self.linear3 = nn.Linear(sequence_len, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(F.relu(self.linear1(x)))\n",
    "        x = self.bn2(F.relu(self.linear2(x)))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        return x\n",
    "    \n",
    "def build_q_network(sequence_len, alphabet_len, device):\n",
    "    model = Q_Network(sequence_len, alphabet_len).to(device)\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "class RL_agent_DQN():\n",
    "    '''\n",
    "    Based off https://colab.research.google.com/drive/1NsbSPn6jOcaJB_mp9TmkgQX7UrRIrTi0\n",
    "    '''\n",
    "    def __init__(self, landscape, start_sequence, alphabet, gamma=0.9, \n",
    "                 memory_size=100000, batch_size=10, experiment_batch_size=1000,\n",
    "                 device = \"cpu\", noise_alpha=1, train_epochs=10):\n",
    "        '''\n",
    "        Unintuitive variables:\n",
    "        memory_size: size of agent memory\n",
    "        batch_size: batch size to train the PER buffer with\n",
    "        experiment_batch_size: the batch size of the experiment.\n",
    "            that is, if this were a lab, this would be the number of sequences\n",
    "            evaluated in a lab trial\n",
    "        '''\n",
    "        \n",
    "        self.alphabet = alphabet\n",
    "        self.alphabet_size = len(alphabet)\n",
    "        self.state = translate_string_to_one_hot(start_sequence, self.alphabet)\n",
    "        self.seq_size = len(start_sequence)\n",
    "        self.q_network = build_q_network(self.seq_size, len(self.alphabet), device)\n",
    "        self.q_network.eval()\n",
    "        self.start_sequence = translate_string_to_one_hot(start_sequence,self.alphabet)\n",
    "        self.memory_size = memory_size\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.experiment_batch_size = experiment_batch_size\n",
    "        self.memory = PrioritizedReplayBuffer(len(self.alphabet) * self.seq_size, \n",
    "                                              memory_size, batch_size, 0.6)\n",
    "        self.seen_sequences = []\n",
    "        self.landscape = landscape\n",
    "        self.best_fitness = 0\n",
    "        \n",
    "        self.train_epochs = 10\n",
    "        self.epsilon_min = 0.1\n",
    "        \n",
    "        self.top_sequence = []\n",
    "\n",
    "        self.times_seen = Counter()\n",
    "        \n",
    "    def reset_position(self,sequence):\n",
    "        self.state=translate_string_to_one_hot(sequence,self.alphabet)\n",
    "\n",
    "    def get_position(self):\n",
    "        return translate_one_hot_to_string(self.state,self.alphabet)\n",
    "\n",
    "    def translate_pwm_to_sequence(self,input_seq_one_hot,output_pwm):\n",
    "        diff=output_pwm-input_seq_one_hot\n",
    "        most_likely=np.argmax(diff,axis=0)\n",
    "        out_seq=\"\"\n",
    "        for m in most_likely:\n",
    "            out_seq+=self.alphabet[m]\n",
    "        return out_seq\n",
    "    \n",
    "    def sample(self):\n",
    "        indices = np.random.choice(len(self.memory), self.batch_size)\n",
    "        rewards, actions, states, next_states = zip(*[self.memory[ind] for ind in indices])\n",
    "        return np.array(rewards), np.array(actions), np.array(states), np.array(next_states) \n",
    "    \n",
    "    def calculate_next_q_values(self, state_v):\n",
    "        dim = self.alphabet_size * self.seq_size\n",
    "        states_repeated = state_v.repeat(1, dim).reshape(-1, dim)\n",
    "        actions_repeated = torch.FloatTensor(np.identity(dim)).repeat(len(state_v), 1)\n",
    "        next_states_actions = torch.cat((states_repeated, actions_repeated), 1)\n",
    "        next_states_values = self.q_network(next_states_actions)\n",
    "        next_states_values = next_states_values.reshape(len(state_v), -1)\n",
    "        \n",
    "        return next_states_values\n",
    "    \n",
    "    def q_network_loss(self, batch, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Calculate MSE between actual state action values,\n",
    "        and expected state action values from DQN\n",
    "        \"\"\"\n",
    "        rewards, actions, states, next_states = \\\n",
    "        batch['rews'], batch['acts'], batch['obs'], batch['next_obs']\n",
    "        \n",
    "        state_action_v = torch.FloatTensor(np.hstack((states, actions)))\n",
    "        rewards_v = torch.FloatTensor(rewards)\n",
    "        next_states_v = torch.FloatTensor(next_states)\n",
    "    \n",
    "        state_action_values = self.q_network(state_action_v).view(-1)\n",
    "        next_state_values = self.calculate_next_q_values(next_states_v)\n",
    "        next_state_values = next_state_values.max(1)[0].detach()\n",
    "        expected_state_action_values = next_state_values * self.gamma + rewards_v\n",
    "        \n",
    "        return nn.MSELoss()(state_action_values, expected_state_action_values)\n",
    "\n",
    "    def train_actor(self, train_epochs=10):\n",
    "        total_loss = 0.\n",
    "        # train Q network on new samples \n",
    "        optimizer = optim.Adam(self.q_network.parameters())\n",
    "        for epoch in range(train_epochs):\n",
    "            batch = self.memory.sample_batch()\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.q_network_loss(batch)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(self.q_network.parameters(), 1.0, norm_type=1)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        return (total_loss / train_epochs)\n",
    "\n",
    "    def get_action_and_mutant(self, epsilon):\n",
    "        state_tensor = torch.FloatTensor([self.state.ravel()])\n",
    "        prediction = self.calculate_next_q_values(state_tensor).detach().numpy()\n",
    "        prediction = prediction.reshape((len(self.alphabet), self.seq_size))\n",
    "        # make action\n",
    "        moves = renormalize_moves(self.state, prediction)\n",
    "        p = random.random()\n",
    "        action = sample_random(moves) if p < epsilon else sample_greedy(moves)\n",
    "        # get next state (mutant)\n",
    "        mutant = construct_mutant_from_sample(action, self.state)\n",
    "        mutant_string = translate_one_hot_to_string(mutant, self.alphabet)\n",
    "        self.state = mutant\n",
    "\n",
    "        return action, mutant\n",
    "    \n",
    "    def pick_action(self):\n",
    "        b = 0\n",
    "        eps = max(self.epsilon_min, (0.5 - self.landscape.cost / (self.experiment_batch_size * generations)))\n",
    "        while (b < self.experiment_batch_size):\n",
    "            state = self.state.copy()\n",
    "            action, new_state = self.get_action_and_mutant(eps)\n",
    "            new_state_string = translate_one_hot_to_string(new_state, self.alphabet)\n",
    "            reward = self.landscape.get_fitness(new_state_string)\n",
    "            if not new_state_string in self.landscape.measured_sequences:\n",
    "                if reward > self.best_fitness:\n",
    "                    state_tensor = torch.FloatTensor([self.state.ravel()])\n",
    "                    prediction = self.calculate_next_q_values(state_tensor).detach().numpy()\n",
    "                    prediction = prediction.reshape((len(self.alphabet), self.seq_size))\n",
    "#                     print(prediction)\n",
    "                    self.top_sequence.append((reward, new_state, self.landscape.cost))\n",
    "                self.best_fitness = max(self.best_fitness, reward)\n",
    "                self.memory.store(state.ravel(), action.ravel(), reward ** 0.9, new_state.ravel())\n",
    "                b += 1\n",
    "        avg_loss = self.train_actor(self.train_epochs)\n",
    "        return\n",
    "    \n",
    "    def pick_action_reward_freq(self):\n",
    "        b = 0\n",
    "        eps = max(self.epsilon_min, (0.5 - self.landscape.cost / (self.experiment_batch_size * generations)))\n",
    "        while (b < self.experiment_batch_size):\n",
    "            state = self.state.copy() \n",
    "            action, new_state = self.get_action_and_mutant(eps)\n",
    "            new_state_string = translate_one_hot_to_string(new_state, self.alphabet)\n",
    "            fitness = self.landscape.get_fitness(new_state_string)\n",
    "            reward = fitness - 0.1 * self.times_seen[new_state_string]\n",
    "            self.times_seen[new_state_string] += 1\n",
    "            if fitness > self.best_fitness:\n",
    "                state_tensor = torch.FloatTensor([self.state.ravel()])\n",
    "                prediction = self.calculate_next_q_values(state_tensor).detach().numpy()\n",
    "                prediction = prediction.reshape((len(self.alphabet), self.seq_size))\n",
    "#                 print(prediction)\n",
    "                self.top_sequence.append((reward, new_state, self.landscape.cost))\n",
    "            self.best_fitness = max(self.best_fitness, fitness)\n",
    "            self.memory.store(state.ravel(), action.ravel(), reward, new_state.ravel())\n",
    "            b += 1\n",
    "        avg_loss = self.train_actor(self.train_epochs)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Network(\n",
      "  (linear1): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (bn1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear2): Linear(in_features=160, out_features=40, bias=True)\n",
      "  (bn2): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear3): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n",
      "Cost: 131, Top fitness: 0.13411764257094438\n",
      "Cost: 155, Top fitness: 0.13411764257094438\n",
      "Cost: 179, Top fitness: 0.15529411540311924\n",
      "Cost: 202, Top fitness: 0.1588235294117647\n",
      "Cost: 226, Top fitness: 0.1588235294117647\n",
      "Cost: 250, Top fitness: 0.1588235294117647\n",
      "Cost: 274, Top fitness: 0.1588235294117647\n",
      "Cost: 287, Top fitness: 0.1588235294117647\n",
      "Cost: 305, Top fitness: 0.1658823574290556\n",
      "Cost: 318, Top fitness: 0.1658823574290556\n",
      "Cost: 339, Top fitness: 0.1658823574290556\n",
      "Cost: 351, Top fitness: 0.1658823574290556\n",
      "Cost: 359, Top fitness: 0.1658823574290556\n",
      "Cost: 366, Top fitness: 0.1658823574290556\n",
      "Cost: 379, Top fitness: 0.1658823574290556\n",
      "Cost: 384, Top fitness: 0.1658823574290556\n",
      "Cost: 391, Top fitness: 0.1658823574290556\n",
      "Cost: 401, Top fitness: 0.1658823574290556\n",
      "Cost: 406, Top fitness: 0.1658823574290556\n",
      "Cost: 413, Top fitness: 0.1658823574290556\n",
      "Cost: 418, Top fitness: 0.1658823574290556\n",
      "Cost: 429, Top fitness: 0.1658823574290556\n",
      "Cost: 445, Top fitness: 0.1658823574290556\n",
      "Cost: 454, Top fitness: 0.1658823574290556\n",
      "Cost: 461, Top fitness: 0.1658823574290556\n",
      "Cost: 464, Top fitness: 0.1658823574290556\n",
      "Cost: 469, Top fitness: 0.1658823574290556\n",
      "Cost: 479, Top fitness: 0.1658823574290556\n",
      "Cost: 489, Top fitness: 0.1658823574290556\n",
      "Cost: 497, Top fitness: 0.1658823574290556\n",
      "Cost: 502, Top fitness: 0.1658823574290556\n",
      "Cost: 510, Top fitness: 0.1658823574290556\n",
      "Cost: 518, Top fitness: 0.1658823574290556\n",
      "Cost: 524, Top fitness: 0.1658823574290556\n",
      "Cost: 530, Top fitness: 0.1658823574290556\n",
      "Cost: 534, Top fitness: 0.1658823574290556\n",
      "Cost: 543, Top fitness: 0.1658823574290556\n",
      "Cost: 547, Top fitness: 0.1658823574290556\n",
      "Cost: 556, Top fitness: 0.1658823574290556\n",
      "Cost: 561, Top fitness: 0.1658823574290556\n",
      "Cost: 566, Top fitness: 0.1658823574290556\n",
      "Cost: 575, Top fitness: 0.1658823574290556\n",
      "Cost: 584, Top fitness: 0.1658823574290556\n",
      "Cost: 588, Top fitness: 0.1658823574290556\n",
      "Cost: 591, Top fitness: 0.1658823574290556\n",
      "Cost: 602, Top fitness: 0.1658823574290556\n",
      "Cost: 619, Top fitness: 0.1658823574290556\n",
      "Cost: 628, Top fitness: 0.1658823574290556\n",
      "Cost: 635, Top fitness: 0.1658823574290556\n",
      "Cost: 644, Top fitness: 0.1658823574290556\n",
      "Cost: 654, Top fitness: 0.1658823574290556\n",
      "Cost: 663, Top fitness: 0.1658823574290556\n",
      "Cost: 670, Top fitness: 0.1658823574290556\n",
      "Cost: 680, Top fitness: 0.1658823574290556\n",
      "Cost: 690, Top fitness: 0.1658823574290556\n",
      "Cost: 700, Top fitness: 0.1658823574290556\n",
      "Cost: 708, Top fitness: 0.1658823574290556\n",
      "Cost: 714, Top fitness: 0.1658823574290556\n",
      "Cost: 727, Top fitness: 0.1658823574290556\n",
      "Cost: 735, Top fitness: 0.1658823574290556\n",
      "Cost: 738, Top fitness: 0.1658823574290556\n",
      "Cost: 744, Top fitness: 0.1658823574290556\n",
      "Cost: 754, Top fitness: 0.1658823574290556\n",
      "Cost: 761, Top fitness: 0.1658823574290556\n",
      "Cost: 772, Top fitness: 0.1658823574290556\n",
      "Cost: 779, Top fitness: 0.1658823574290556\n",
      "Cost: 784, Top fitness: 0.1658823574290556\n",
      "Cost: 790, Top fitness: 0.1658823574290556\n",
      "Cost: 798, Top fitness: 0.1658823574290556\n",
      "Cost: 805, Top fitness: 0.1658823574290556\n",
      "Cost: 815, Top fitness: 0.1658823574290556\n",
      "Cost: 825, Top fitness: 0.1658823574290556\n",
      "Cost: 828, Top fitness: 0.1658823574290556\n",
      "Cost: 839, Top fitness: 0.1658823574290556\n",
      "Cost: 852, Top fitness: 0.1658823574290556\n",
      "Cost: 858, Top fitness: 0.1658823574290556\n",
      "Cost: 869, Top fitness: 0.1658823574290556\n",
      "Cost: 874, Top fitness: 0.1658823574290556\n",
      "Cost: 880, Top fitness: 0.1658823574290556\n",
      "Cost: 891, Top fitness: 0.1658823574290556\n",
      "Cost: 898, Top fitness: 0.1658823574290556\n",
      "Cost: 904, Top fitness: 0.1658823574290556\n",
      "Cost: 911, Top fitness: 0.1658823574290556\n",
      "Cost: 911, Top fitness: 0.1658823574290556\n",
      "Cost: 922, Top fitness: 0.1658823574290556\n",
      "Cost: 928, Top fitness: 0.1658823574290556\n",
      "Cost: 936, Top fitness: 0.1658823574290556\n",
      "Cost: 944, Top fitness: 0.1658823574290556\n",
      "Cost: 949, Top fitness: 0.1658823574290556\n",
      "Cost: 959, Top fitness: 0.1658823574290556\n",
      "Cost: 966, Top fitness: 0.1658823574290556\n",
      "Cost: 971, Top fitness: 0.1658823574290556\n",
      "Cost: 977, Top fitness: 0.1658823574290556\n",
      "Cost: 985, Top fitness: 0.1658823574290556\n",
      "Cost: 989, Top fitness: 0.1658823574290556\n",
      "Cost: 991, Top fitness: 0.1658823574290556\n",
      "Cost: 1002, Top fitness: 0.1658823574290556\n"
     ]
    }
   ],
   "source": [
    "agent = RL_agent_DQN(landscape=noisy_landscape, start_sequence=wt,\n",
    "                     alphabet=RAA, gamma=0.8, memory_size=10000,\n",
    "                     device=device, experiment_batch_size=experiment_batch_size)\n",
    "\n",
    "noisy_landscape.reset()\n",
    "noisy_landscape.measure_true_landscape(initial_genotypes)\n",
    "noisy_landscape.natural_mode=False\n",
    "noisy_landscape.local_mode=False\n",
    "noisy_landscape.cost\n",
    "\n",
    "while noisy_landscape.cost < generations*experiment_batch_size:\n",
    "    agent.pick_action()\n",
    "    print(f\"Cost: {noisy_landscape.cost}, Top fitness: {agent.top_sequence[-1][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Network(\n",
      "  (linear1): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (bn1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear2): Linear(in_features=160, out_features=40, bias=True)\n",
      "  (bn2): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear3): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n",
      "Cost: 151, Top fitness: 0.18235294117647058\n",
      "Cost: 197, Top fitness: 0.18235294117647058\n",
      "Cost: 245, Top fitness: 0.18235294117647058\n",
      "Cost: 311, Top fitness: 0.18235294117647058\n",
      "Cost: 354, Top fitness: 0.18235294117647058\n",
      "Cost: 395, Top fitness: 0.18235294117647058\n",
      "Cost: 404, Top fitness: 0.18235294117647058\n",
      "Cost: 415, Top fitness: 0.18235294117647058\n",
      "Cost: 423, Top fitness: 0.18235294117647058\n",
      "Cost: 433, Top fitness: 0.18235294117647058\n",
      "Cost: 455, Top fitness: 0.18235294117647058\n",
      "Cost: 469, Top fitness: 0.18235294117647058\n",
      "Cost: 478, Top fitness: 0.18235294117647058\n",
      "Cost: 485, Top fitness: 0.18235294117647058\n",
      "Cost: 508, Top fitness: 0.18235294117647058\n",
      "Cost: 516, Top fitness: 0.18235294117647058\n",
      "Cost: 541, Top fitness: 0.18235294117647058\n",
      "Cost: 550, Top fitness: 0.18235294117647058\n",
      "Cost: 556, Top fitness: 0.18235294117647058\n",
      "Cost: 561, Top fitness: 0.18235294117647058\n",
      "Cost: 570, Top fitness: 0.18235294117647058\n",
      "Cost: 579, Top fitness: 0.18235294117647058\n",
      "Cost: 584, Top fitness: 0.18235294117647058\n",
      "Cost: 596, Top fitness: 0.18235294117647058\n",
      "Cost: 611, Top fitness: 0.18235294117647058\n",
      "Cost: 626, Top fitness: 0.18235294117647058\n",
      "Cost: 628, Top fitness: 0.18235294117647058\n",
      "Cost: 633, Top fitness: 0.18235294117647058\n",
      "Cost: 635, Top fitness: 0.18235294117647058\n",
      "Cost: 642, Top fitness: 0.18235294117647058\n",
      "Cost: 654, Top fitness: 0.18235294117647058\n",
      "Cost: 691, Top fitness: 0.18235294117647058\n",
      "Cost: 698, Top fitness: 0.18235294117647058\n",
      "Cost: 704, Top fitness: 0.18235294117647058\n",
      "Cost: 707, Top fitness: 0.18235294117647058\n",
      "Cost: 715, Top fitness: 0.18235294117647058\n",
      "Cost: 722, Top fitness: 0.18235294117647058\n",
      "Cost: 725, Top fitness: 0.18235294117647058\n",
      "Cost: 733, Top fitness: 0.18235294117647058\n",
      "Cost: 743, Top fitness: 0.18235294117647058\n",
      "Cost: 744, Top fitness: 0.18235294117647058\n",
      "Cost: 751, Top fitness: 0.18235294117647058\n",
      "Cost: 761, Top fitness: 0.18235294117647058\n",
      "Cost: 767, Top fitness: 0.18235294117647058\n",
      "Cost: 774, Top fitness: 0.18235294117647058\n",
      "Cost: 801, Top fitness: 0.18235294117647058\n",
      "Cost: 811, Top fitness: 0.18235294117647058\n",
      "Cost: 820, Top fitness: 0.20117647507611444\n",
      "Cost: 831, Top fitness: 0.20117647507611444\n",
      "Cost: 843, Top fitness: 0.20117647507611444\n",
      "Cost: 850, Top fitness: 0.20117647507611444\n",
      "Cost: 856, Top fitness: 0.20117647507611444\n",
      "Cost: 864, Top fitness: 0.20117647507611444\n",
      "Cost: 883, Top fitness: 0.20117647507611444\n",
      "Cost: 890, Top fitness: 0.20117647507611444\n",
      "Cost: 897, Top fitness: 0.20117647507611444\n",
      "Cost: 903, Top fitness: 0.20117647507611444\n",
      "Cost: 910, Top fitness: 0.20117647507611444\n",
      "Cost: 915, Top fitness: 0.20117647507611444\n",
      "Cost: 926, Top fitness: 0.20117647507611444\n",
      "Cost: 949, Top fitness: 0.20117647507611444\n",
      "Cost: 960, Top fitness: 0.20117647507611444\n",
      "Cost: 976, Top fitness: 0.20117647507611444\n",
      "Cost: 983, Top fitness: 0.20117647507611444\n",
      "Cost: 989, Top fitness: 0.20117647507611444\n",
      "Cost: 994, Top fitness: 0.20117647507611444\n",
      "Cost: 1002, Top fitness: 0.20117647507611444\n"
     ]
    }
   ],
   "source": [
    "agent_reward_freq = RL_agent_DQN(landscape=noisy_landscape, start_sequence=wt,\n",
    "                     alphabet=RAA, gamma=0.8, memory_size=10000,\n",
    "                     device=device, experiment_batch_size=experiment_batch_size)\n",
    "\n",
    "noisy_landscape.reset()\n",
    "noisy_landscape.measure_true_landscape(initial_genotypes)\n",
    "noisy_landscape.natural_mode=False\n",
    "noisy_landscape.local_mode=False\n",
    "noisy_landscape.cost\n",
    "\n",
    "while noisy_landscape.cost < generations*experiment_batch_size:\n",
    "    agent_reward_freq.pick_action_reward_freq()\n",
    "    print(f\"Cost: {noisy_landscape.cost}, Top fitness: {agent_reward_freq.top_sequence[-1][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "#plt.xscale(\"log\")\n",
    "plt.title(f\"Batch size: {experiment_batch_size}; Generations: {generations}; Noise: {noise_alpha}\")\n",
    "plt.xlabel(\"number of batches tested\")\n",
    "plt.ylabel(\"maximum fitness observed\")\n",
    "plt.plot([t[2]/experiment_batch_size for t in agent.top_sequence[1:]],[t[0] for t in agent.top_sequence[1:]],label=\"RL DQN PER\")\n",
    "plt.plot([t[2]/experiment_batch_size for t in agent_reward_freq.top_sequence[1:]],[t[0] for t in agent_reward_freq.top_sequence[1:]],label=\"RL DQN PER reward freq\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(range(generations));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python RNA_3.6",
   "language": "python",
   "name": "rna_3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
