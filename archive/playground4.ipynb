{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wow, very many playgrounds\n",
    "# this one is to just strictly work on optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import editdistance\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
    "sys.path.append('/usr/local/ViennaRNA/lib/python3.7/site-packages/')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# from utils.sequence_utils import *\n",
    "from models.Theoretical_models import *\n",
    "from models.Noise_wrapper import *\n",
    "from exploration_strategies.CE import *\n",
    "# from exploration_strategies.RL_explorers_modify import *\n",
    "from utils.landscape_utils import *\n",
    "from models.RNA_landscapes import *\n",
    "from models.Multi_dimensional_model import *\n",
    "import RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CACGCCCGCUAAUAGGUACCACUAAUUUGAUUGUUCGUGG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "RAA=\"UGCA\" #alphabet\n",
    "length=40\n",
    "np.random.seed(0)\n",
    "wt='CACGCCCGCUAAUAGGUACCACUAAUUUGAUUGUUCGUGG' #generate_random_sequences(length,1,alphabet=RAA)[0]\n",
    "print(wt)\n",
    "#make a simple folding landscape starting at wt\n",
    "landscape1=RNA_landscape(wt)\n",
    "noise_alpha=1\n",
    "virtual_per_measure_ratio=15\n",
    "temperature=0.1\n",
    "# there are multiple abstract \"noise models\" you can use, or you can try to train your own model, using skM\n",
    "noisy_landscape_CE=Noise_wrapper(landscape1,noise_alpha=noise_alpha)\n",
    "noisy_landscape_RL=Noise_wrapper(landscape1,noise_alpha=noise_alpha)\n",
    "noisy_landscape_RL_multiple=Noise_wrapper(landscape1,noise_alpha=noise_alpha)\n",
    "#noisy_landscape=Gaussian_noise_landscape(base_landscape,noise_alpha=0.15)\n",
    "#noisy_landscape=DF_noise_landscape(base_landscape,noise_alpha=0.5)\n",
    "batch_size = 10\n",
    "initial_genotypes=list(set([wt]+[generate_random_mutant(wt,0.05,RAA) for i in range(batch_size*10)]))[:batch_size]\n",
    "len(initial_genotypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_CE(initial_genotypes, batch_size, generations):\n",
    "    noisy_landscape_CE.reset()\n",
    "    noisy_landscape_CE.measure_true_landscape(initial_genotypes)\n",
    "    noisy_landscape_CE.natural_mode=False\n",
    "    noisy_landscape_CE.local_mode=False\n",
    "    noisy_landscape_CE.cost\n",
    "\n",
    "    eCE=CE(noisy_landscape_CE,initial_genotypes,wt,\\\n",
    "           alphabet=RAA,batch_size=batch_size,recomb_rate=0.0, \\\n",
    "           temperature=temperature,virtual_screen=virtual_per_measure_ratio)\n",
    "\n",
    "    news=[]\n",
    "    CE_top_seqs = []\n",
    "    \n",
    "    print(noisy_landscape_CE.cost,eCE.top_sequence[-1][0])\n",
    "    while noisy_landscape_CE.cost<generations*batch_size:\n",
    "        news.append(eCE.pick_action())\n",
    "\n",
    "        print(noisy_landscape_CE.cost,eCE.top_sequence[-1][0])\n",
    "        CE_top_seqs += [(noisy_landscape_CE.cost, eCE.top_sequence[-1][0])]\n",
    "        news=[]\n",
    "        \n",
    "    return CE_top_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.11882353389964384\n",
      "20 0.13529411764705881\n",
      "30 0.183529416252585\n",
      "40 0.19176469690659467\n",
      "50 0.19176469690659467\n",
      "60 0.2035294027889476\n",
      "70 0.2482352986055262\n",
      "80 0.2482352986055262\n",
      "90 0.2517647013944738\n",
      "100 0.25647057925953587\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "generations = 10\n",
    "CE_top_seqs = run_CE(initial_genotypes, batch_size, generations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE AGENT RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import bisect\n",
    "from utils.sequence_utils import translate_string_to_one_hot\n",
    "\n",
    "\n",
    "def renormalize_moves(one_hot_input,rewards_output):\n",
    "    \"\"\"ensures that staying in place gives no reward\"\"\"\n",
    "    zero_current_state=(one_hot_input-1)*-1\n",
    "    return np.multiply(rewards_output,zero_current_state)\n",
    "\n",
    "def walk_away_renormalize_moves(one_hot_input, one_hot_wt, rewards_output):\n",
    "    \"\"\"ensures that moving toward wt is also not useful\"\"\"\n",
    "    zero_current_state=(one_hot_input-1)*-1\n",
    "    zero_wt=((one_hot_wt-1)*-1)\n",
    "    zero_conservative_moves=np.multiply(zero_wt,zero_current_state)\n",
    "    return np.multiply(rewards_output,zero_conservative_moves)\n",
    "\n",
    "def get_all_singles_fitness(model,sequence,alphabet):\n",
    "    prob_singles=np.zeros((len(alphabet),len(sequence)))\n",
    "    for i in range(len(sequence)):\n",
    "        for j in range(len(alphabet)):\n",
    "            putative_seq=sequence[:i]+alphabet[j]+sequence[i+1:]\n",
    "           # print (putative_seq)\n",
    "            prob_singles[j][i]=model.get_fitness(putative_seq)\n",
    "    return prob_singles\n",
    "\n",
    "def sample_greedy(matrix, output=None):\n",
    "    i,j=matrix.shape\n",
    "    max_arg=np.argmax(matrix)\n",
    "    y=max_arg%j\n",
    "    x=int(max_arg/j)\n",
    "    if not(type(output)==np.array):\n",
    "        output=np.zeros((i,j))\n",
    "    output[x][y]=matrix[x][y]\n",
    "    return output\n",
    "\n",
    "def sample_greedy_k(matrix, k, output=None):\n",
    "    i,j = matrix.shape\n",
    "    max_args = np.argsort(matrix.flatten())[-k:]\n",
    "    if not(type(output)==np.array):\n",
    "        outputs = [np.zeros((i,j)) for _ in range(k)]\n",
    "    else:\n",
    "        outputs = [output for _ in range(k)]\n",
    "    for ixk in range(k):\n",
    "        y = max_args[ixk]%j\n",
    "        x = int(max_args[ixk]/j)\n",
    "        outputs[ixk][x][y] = matrix[x][y]\n",
    "    return outputs\n",
    "\n",
    "def sample_multi_greedy(matrix):\n",
    "    n = 5 # the number of base positions to greedily change\n",
    "    max_args = np.argpartition(matrix.flatten(), -n)[-n:]\n",
    "    i,j=matrix.shape\n",
    "    output=np.zeros((i,j))\n",
    "    for max_arg in max_args:\n",
    "        y=max_arg%j\n",
    "        x=int(max_arg/j)\n",
    "        output[x][y]=matrix[x][y]\n",
    "    return output\n",
    "\n",
    "def sample_random(matrix, output = None):\n",
    "    i,j=matrix.shape\n",
    "    non_zero_moves=np.nonzero(matrix)\n",
    "   # print (non_zero_moves)\n",
    "    k=len(non_zero_moves)\n",
    "    l=len(non_zero_moves[0])\n",
    "    if k!=0 and l!=0:\n",
    "        rand_arg=random.choice([[non_zero_moves[alph][pos] for alph in range(k)] for pos in range(l)])\n",
    "    else:\n",
    "        rand_arg=[random.randint(0,i-1),random.randint(0,j-1)]\n",
    "    #print (rand_arg)\n",
    "    y=rand_arg[1]\n",
    "    x=rand_arg[0]\n",
    "    if not(type(output)==np.array):\n",
    "        output=np.zeros((i,j))\n",
    "    output[x][y]=matrix[x][y]\n",
    "    return output   \n",
    "    \n",
    "def construct_mutant_from_sample(pwm_sample, one_hot_base):\n",
    "    one_hot=np.zeros(one_hot_base.shape)\n",
    "    one_hot+=one_hot_base\n",
    "    nonzero = np.nonzero(pwm_sample)\n",
    "    nonzero = list(zip(nonzero[0], nonzero[1]))\n",
    "    for nz in nonzero: # this can be problematic for non-positive fitnesses\n",
    "        i, j = nz\n",
    "        one_hot[:,j]=0\n",
    "        one_hot[i,j]=1\n",
    "    return one_hot\n",
    "\n",
    "def make_one_hot_train_test(genotypes,model,alphabet,split=0.0):\n",
    "    genotypes_one_hot=[translate_string_to_one_hot(genotype,alphabet) for genotype in genotypes]\n",
    "    genotype_fitnesses=[get_all_singles_fitness(model,genotype,alphabet) for genotype in genotypes]\n",
    "    train_x=[]\n",
    "    test_x=[]\n",
    "    train_y=[]\n",
    "    test_y=[]\n",
    "    if split>0: #check this to avoid calling the randomizer if not required\n",
    "        for x,y in zip(genotypes_one_hot,genotype_fitnesses):\n",
    "                if random.random()<split:\n",
    "                    test_x.append(x)\n",
    "                    test_y.append(y)\n",
    "                else:\n",
    "                    train_x.append(x)\n",
    "                    train_y.append(y)\n",
    "        train_x=np.stack(train_x)\n",
    "        train_y=np.stack(train_y)\n",
    "        test_y=np.stack(test_y)\n",
    "        test_x=np.stack(test_x)\n",
    "        return train_x,train_y,test_x,test_y\n",
    "    else:\n",
    "        train_x=np.stack(genotypes_one_hot)\n",
    "        train_y=np.stack(genotype_fitnesses)\n",
    "\n",
    "        return train_x,train_y,test_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "# from utils.RL_utils import *\n",
    "from utils.sequence_utils import translate_one_hot_to_string,generate_random_mutant\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class RL_agent_QN():\n",
    "\n",
    "    def __init__(self,model, start_sequence,alphabet,gamma=0.9,memory_size=1000, device = \"cpu\"):\n",
    "        self.model=model\n",
    "        self.alphabet=alphabet\n",
    "        self.state=translate_string_to_one_hot(start_sequence,self.alphabet)\n",
    "        self.seq_size=len(start_sequence)\n",
    "        self.actor=build_model(self.seq_size,len(self.alphabet), device)\n",
    "        self.start_sequence=translate_string_to_one_hot(start_sequence,self.alphabet)\n",
    "        self.gamma=gamma\n",
    "        self.memory=[]\n",
    "        self.memory_size=memory_size\n",
    "\n",
    "    def reset_position(self,sequence):\n",
    "        self.state=translate_string_to_one_hot(sequence,self.alphabet)\n",
    "\n",
    "    def get_position(self):\n",
    "        return translate_one_hot_to_string(self.state,self.alphabet)\n",
    "\n",
    "    def translate_pwm_to_sequence(self,input_seq_one_hot,output_pwm):\n",
    "        diff=output_pwm-input_seq_one_hot\n",
    "        most_likely=np.argmax(diff,axis=0)\n",
    "        out_seq=\"\"\n",
    "        for m in most_likely:\n",
    "            out_seq+=self.alphabet[m]\n",
    "        return out_seq\n",
    "\n",
    "    def observe(self,landscape,genotypes,costly=False,num_observations=50,epsilon=0.2,depth=10):\n",
    "        if genotypes:\n",
    "            new_sequences=make_one_hot_genotypes(genotypes,self.alphabet)\n",
    "        elif self.memory:\n",
    "            new_sequences=make_one_hot_genotypes(self.memory[-num_observations:],self.alphabet)\n",
    "        else:\n",
    "            return \"Nothing to observe\"\n",
    "        new_moves=[]\n",
    "        all_moves=[]\n",
    "        \n",
    "        #all_fitnesses=[]\n",
    "        for i in range(depth):\n",
    "            for genotype in new_sequences:\n",
    "                if random.random()<epsilon:\n",
    "                    genotype_tensor = torch.from_numpy(np.expand_dims(genotype,axis=0)).float()\n",
    "                    prediction = self.actor(genotype_tensor)\n",
    "                    prediction = prediction.detach().numpy()[0]\n",
    "                    #moves=walk_away_renormalize_moves(genotype,self.start_sequence,prediction)\n",
    "                    moves=renormalize_moves(genotype,prediction)\n",
    "\n",
    "                    sample=sample_random(moves)\n",
    "                    mutant=construct_mutant_from_sample(sample,genotype)\n",
    "                    new_moves.append(translate_one_hot_to_string(mutant,self.alphabet))\n",
    "                else:\n",
    "                    genotype_tensor = torch.from_numpy(np.expand_dims(genotype,axis=0)).float()\n",
    "                    prediction = self.actor(genotype_tensor)\n",
    "                    prediction = prediction.detach().numpy()[0]\n",
    "                    #moves=walk_away_renormalize_moves(genotype,self.start_sequence,prediction)\n",
    "                    moves=renormalize_moves(genotype,prediction)\n",
    "                    \n",
    "                    sample=sample_boltzman(moves)\n",
    "                    mutant=construct_mutant_from_sample(sample,genotype)\n",
    "                    new_moves.append(translate_one_hot_to_string(mutant,self.alphabet))\n",
    "            if costly:\n",
    "                landscape.measure_true_landscape(new_moves)\n",
    "#             else:\n",
    "#                 landscape.genotype_fitnesses(new_moves)\n",
    "\n",
    "            new_sequences=np.stack([translate_string_to_one_hot(move,self.alphabet) for move in new_moves])\n",
    "            all_moves.extend(new_moves)\n",
    "            #all_fitnesses.append(new_fitnesses)\n",
    "            new_moves=[]\n",
    "        self.memory=all_moves[-self.memory_size:] #store at most 1000 memories\n",
    "        return all_moves\n",
    "\n",
    "    def train_actor(self, landscape, observations, train_epochs=10):\n",
    "        loss_fxn = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.actor.parameters(), lr=0.001)\n",
    "        total_loss = 0.\n",
    "        for epoch in range(train_epochs):     \n",
    "            moves = observations #random.sample(observations, train_size)\n",
    "            genotypes_one_hot, genotype_fitnesses, t_1, t_2 = make_one_hot_train_test(moves, landscape, self.alphabet)\n",
    "            optimizer.zero_grad()\n",
    "            genotypes_one_hot_tensor = torch.from_numpy(genotypes_one_hot).float()\n",
    "            outputs = self.actor(genotypes_one_hot_tensor)\n",
    "            genotype_fitnesses = torch.tensor(genotype_fitnesses, requires_grad=True).float()\n",
    "            loss = loss_fxn(outputs, genotype_fitnesses)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "#         print('[%d] Avg loss: %.3f' % (epoch+1, total_loss / (epoch + 1)))\n",
    "        return (total_loss / (epoch+1))\n",
    "\n",
    "    def xtrain_actor(self,landscape,observations,train_size=1000,train_epochs=1):\n",
    "        loss_fxn = nn.MSELoss()\n",
    "        optimizer = optim.Adam(net.parameters, lr=0.001)\n",
    "        for epoch in range(train_epochs):  # loop over the dataset multiple times\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            moves = random.sample(observations,train_size)+random.sample(self.memory,train_size)\n",
    "            genotypes_one_hot, genotype_fitnesses, t_1, t_2 = make_one_hot_train_test(moves, landscape, self.alphabet)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = self.actor(genotypes_one_hot)\n",
    "            loss = loss_fxn(outputs, genotype_fitnesses)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 2000))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "\n",
    "    def pick_action(self,method):\n",
    "            state_tensor = torch.from_numpy(np.expand_dims(self.state,axis=0)).float()\n",
    "            prediction = self.actor(state_tensor)\n",
    "            prediction = prediction.detach().numpy()[0]\n",
    "            moves=renormalize_moves(self.state,prediction)\n",
    "            if(method[0] == 'eps'):\n",
    "                epsilon = method[1]\n",
    "                p = random.random()\n",
    "                sample = sample_random(moves) if p < epsilon else sample_greedy(moves)\n",
    "            elif(method[0] == 'multi_eps'):\n",
    "                epsilon = method[1]\n",
    "                p = random.random()\n",
    "                sample = sample_random(moves) if p < epsilon else sample_multi_greedy(moves)\n",
    "                \n",
    "            elif(method[0] == 'rollout'):\n",
    "                epsilon = method[1]\n",
    "                k = method[2] # number of samples\n",
    "                d = method[3] # depth of rollout\n",
    "                samples = {}\n",
    "                all_samples = []\n",
    "                # start with depth 0\n",
    "                samples[0] = sample_greedy_k(moves, k)\n",
    "                # with eps probability use random action otherwise use kth best mutation\n",
    "                for ixk in range(k):\n",
    "                    r = sample_random(moves)\n",
    "                    samples[0][ixk] = (r,max(r.flatten())) if random.random() < epsilon else (samples[0][ixk], max(samples[0][ixk].flatten()))\n",
    "                for ixd in range(d):\n",
    "                    samples[ixd+1] = []\n",
    "                    for ixk in range(len(samples[ixd])):\n",
    "                        sample = samples[ixd][ixk][0] #sample_greedy(moves)\n",
    "                        mutant = construct_mutant_from_sample(sample,self.state)\n",
    "                        state_tensor = torch.from_numpy(np.expand_dims(mutant,axis=0)).float()\n",
    "                        prediction = self.actor(state_tensor)\n",
    "                        prediction = prediction.detach().numpy()[0]\n",
    "                        all_samples.append((sample, max(sample.flatten())))\n",
    "                        moves = renormalize_moves(mutant,prediction)\n",
    "                        temp_samples = sample_greedy_k(moves, k, mutant)\n",
    "                        for ixk2 in range(k):\n",
    "                            r = sample_random(moves, mutant)\n",
    "                            samples[ixd+1].append((r,sum(r.flatten())) if random.random() < epsilon else (temp_samples[ixk2], max(temp_samples[ixk2].flatten())))\n",
    "                r = random.randint(0,len(all_samples)-1)\n",
    "                sample = all_samples[r][0] if random.random() < epsilon else sorted(all_samples, key=lambda x: x[1], reverse=True)[0][0]\n",
    "                \n",
    "            mutant=construct_mutant_from_sample(sample,self.state)\n",
    "            mutant_string=translate_one_hot_to_string(mutant,self.alphabet)\n",
    "\n",
    "            self.state=mutant\n",
    "            self.memory.append(mutant_string)\n",
    "\n",
    "            return mutant_string\n",
    "        \n",
    "    def pick_action_batch(self, method, batch_size):\n",
    "        state_tensor = torch.from_numpy(np.expand_dims(self.state,axis=0)).float()\n",
    "        prediction = self.actor(state_tensor)\n",
    "        prediction = prediction.detach().numpy()[0]\n",
    "        moves=renormalize_moves(self.state,prediction)\n",
    "        mutant = construct_mutant_from_sample(moves,self.state)\n",
    "        mutant_string=translate_one_hot_to_string(mutant,self.alphabet)\n",
    "        if(method[0] == 'rollout'):\n",
    "            epsilon = method[1]\n",
    "            k = method[2] # number of samples\n",
    "            d = method[3] # depth of rollout\n",
    "            samples = {}\n",
    "            all_samples = []\n",
    "            strings_seen = []\n",
    "            # start with depth 0\n",
    "            samples[0] = [moves]\n",
    "            all_samples.append((moves, max(moves.flatten()), mutant_string))\n",
    "            strings_seen.append(mutant_string)\n",
    "            ixd=0\n",
    "            while(ixd < d or len(all_samples) < batch_size):\n",
    "                for ixk in range(k):\n",
    "                    sample = all_samples[ixk][0]\n",
    "                    mutant = construct_mutant_from_sample(sample,self.state)\n",
    "                    state_tensor = torch.from_numpy(np.expand_dims(mutant,axis=0)).float()\n",
    "                    prediction = self.actor(state_tensor)\n",
    "                    prediction = prediction.detach().numpy()[0]\n",
    "#                     moves = renormalize_moves(mutant,prediction)\n",
    "                    temp_samples = sample_greedy_k(moves, k, mutant)\n",
    "                    for ixk2 in range(k):\n",
    "                        r = sample_random(moves, mutant) if random.random() < epsilon else temp_samples[ixk2]\n",
    "                        temp_mutant = construct_mutant_from_sample(r,sample)\n",
    "                        temp_mutant_string=translate_one_hot_to_string(temp_mutant,self.alphabet)\n",
    "                        if(temp_mutant_string in strings_seen):\n",
    "                            continue\n",
    "                        strings_seen.append(mutant_string)\n",
    "                        all_samples.append((r, sum(r.flatten()),temp_mutant_string))\n",
    "                all_samples = sorted(all_samples,key=lambda x: x[1], reverse=True)\n",
    "                ixd += 1\n",
    "#                 print([all_samples[ixk][1] for ixk in range(k)])\n",
    "#             for ixd in range(d):\n",
    "#                 samples[ixd+1] = []\n",
    "#                 for ixk in range(k):\n",
    "#                     sample = all_samples[ixk][0] #sample_greedy(moves)\n",
    "#                     mutant = construct_mutant_from_sample(sample,self.state)\n",
    "#                     mutant_string=translate_one_hot_to_string(mutant,self.alphabet)\n",
    "#                     strings_seen.append(mutant_string)\n",
    "#                     state_tensor = torch.from_numpy(np.expand_dims(mutant,axis=0)).float()\n",
    "#                     prediction = self.actor(state_tensor)\n",
    "#                     prediction = prediction.detach().numpy()[0]\n",
    "#                     moves = renormalize_moves(mutant,prediction)\n",
    "#                     temp_samples = sample_greedy_k(moves, k, mutant)\n",
    "#                     for ixk2 in range(k):\n",
    "#                         r = temp_samples[ixk2] #sample_random(moves, mutant) if random.random() < epsilon else temp_samples[ixk2]\n",
    "#                         temp_mutant = construct_mutant_from_sample(r,sample)\n",
    "#                         temp_mutant_string=translate_one_hot_to_string(temp_mutant,self.alphabet)\n",
    "# #                         if(temp_mutant_string in strings_seen):\n",
    "# #                             continue\n",
    "#                         strings_seen.append(mutant_string)\n",
    "#                         samples[ixd+1].append((r,sum(r.flatten())))\n",
    "#                         all_samples.append((r, sum(r.flatten()),temp_mutant_string))\n",
    "#                     # sort so that always mutating from highest value mutations\n",
    "#                     all_samples = sorted(all_samples,key=lambda x: x[1], reverse=True)\n",
    "# #                 print([all_samples[ixk][1] for ixk in range(k)])\n",
    "\n",
    "        mutant_strings=[(mutant_string,v) for (s,v,mutant_string) in all_samples]\n",
    "        self.state=all_samples[0][0]\n",
    "        self.memory.append(mutant_strings)\n",
    "#         self.memory = sorted(self.memory,key=lambda x:x[1], reverse=True)\n",
    "\n",
    "        return mutant_strings\n",
    "        \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, sequence_len, alphabet_len):\n",
    "        super(Model,self).__init__()\n",
    "        self.sequence_len = sequence_len\n",
    "        self.alphabet_len = alphabet_len\n",
    "        self.linear1 = nn.Linear(alphabet_len * sequence_len, alphabet_len * sequence_len)\n",
    "        self.linear2 = nn.Linear(alphabet_len * sequence_len, sequence_len)\n",
    "        self.linear3 = nn.Linear(sequence_len, sequence_len)\n",
    "        self.linear4 = nn.Linear(sequence_len, 18)\n",
    "        self.linear5 = nn.Linear(18, alphabet_len * sequence_len)\n",
    "        self.linear6 = nn.Linear(alphabet_len * sequence_len, alphabet_len * sequence_len)\n",
    "        self.linear_final = nn.Linear(sequence_len, sequence_len)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.alphabet_len*self.sequence_len)\n",
    "        x = F.sigmoid(self.linear1(x))\n",
    "        x = F.sigmoid(self.linear2(x))\n",
    "        x = F.sigmoid(self.linear3(x))\n",
    "        x = F.sigmoid(self.linear4(x))\n",
    "        x = F.sigmoid(self.linear5(x))\n",
    "        x = F.sigmoid(self.linear6(x))\n",
    "        x = x.view([-1]+list((self.alphabet_len, self.sequence_len)))\n",
    "        x = self.linear_final(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def build_model(sequence_len, alphabet_len, device):\n",
    "    model = Model(sequence_len, alphabet_len).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pick_action_batch(self, method):\n",
    "#         state_tensor = torch.from_numpy(np.expand_dims(self.state,axis=0)).float()\n",
    "#         prediction = self.actor(state_tensor)\n",
    "#         prediction = prediction.detach().numpy()[0]\n",
    "#         moves=renormalize_moves(self.state,prediction)\n",
    "#         if(method[0] == 'rollout'):\n",
    "#             epsilon = method[1]\n",
    "#             k = method[2] # number of samples\n",
    "#             d = method[3] # depth of rollout\n",
    "#             samples = {}\n",
    "#             all_samples = []\n",
    "#             # start with depth 0\n",
    "#             samples[0] = sample_greedy_k(moves, k)\n",
    "#             # with eps probability use random action otherwise use kth best mutation\n",
    "#             for ixk in range(k):\n",
    "#                 r = sample_random(moves)\n",
    "#                 samples[0][ixk] = (r,max(r.flatten())) if random.random() < epsilon else (samples[0][ixk], max(samples[0][ixk].flatten()))\n",
    "#             all_samples += samples[0]\n",
    "#             all_samples = sorted(all_samples, key=lambda x:x[1], reverse=True)\n",
    "\n",
    "#             for ixd in range(d):\n",
    "#                 samples[ixd+1] = []\n",
    "#                 for ixk in range(k):\n",
    "#                     sample = all_samples[ixk][0] #sample_greedy(moves)\n",
    "#                     mutant = construct_mutant_from_sample(sample,self.state)\n",
    "#                     state_tensor = torch.from_numpy(np.expand_dims(mutant,axis=0)).float()\n",
    "#                     prediction = self.actor(state_tensor)\n",
    "#                     prediction = prediction.detach().numpy()[0]\n",
    "#                     moves = renormalize_moves(mutant,prediction)\n",
    "#                     temp_samples = sample_greedy_k(moves, k, mutant)\n",
    "#                     for ixk2 in range(k):\n",
    "#                         r = temp_samples[ixk2] #sample_random(moves, mutant) if random.random() < epsilon else temp_samples[ixk2]\n",
    "#                         samples[ixd+1].append((r,sum(r.flatten())))\n",
    "#                     all_samples += samples[ixd+1]\n",
    "#                     # sort so that always mutating from highest value mutations\n",
    "#                     all_samples = sorted(all_samples,key=lambda x: x[1], reverse=True)    \n",
    "                    \n",
    "# #             batch_samples = []\n",
    "# #             for b in batch_size:\n",
    "# #                 r = random.randint(0,len(all_samples)-1)\n",
    "# #                 batch_samples.append(all_samples[r][0] if random.random() < epsilon \n",
    "# #                                      else sorted(all_samples, key=lambda x: x[1], reverse=True)[b][0])\n",
    "\n",
    "#         mutants=[(construct_mutant_from_sample(sample,self.state),v) for (sample,v) in all_samples]\n",
    "#         mutant_strings=[(translate_one_hot_to_string(mutant,self.alphabet),v) for (mutant,v) in mutants]\n",
    "\n",
    "#         self.state=mutants[0][0]\n",
    "#         self.memory.append(mutant_strings)\n",
    "# #         self.memory = sorted(self.memory,key=lambda x:x[1], reverse=True)\n",
    "\n",
    "#         return mutant_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_RL(initial_genotypes, batch_size, generations, sampling_method):\n",
    "#     noisy_landscape_RL.reset()\n",
    "#     noisy_landscape_RL.measure_true_landscape(initial_genotypes)\n",
    "#     noisy_landscape_RL.natural_mode=False\n",
    "#     noisy_landscape_RL.local_mode=False\n",
    "#     noisy_landscape_RL.cost\n",
    "\n",
    "#     agent = RL_agent_QN(noisy_landscape_RL, wt,alphabet=RAA,memory_size=10000, device=device)\n",
    "#     observations=[x for x in initial_genotypes]#agent.observe(noisy_landscape_RL,initial_genotypes,costly=True,num_observations=100,depth=5)\n",
    "#     agent.train_actor(noisy_landscape_RL,observations, train_epochs=10)\n",
    "#     new_sequences = sorted([(noisy_landscape_RL.get_fitness(observations[i]),[observations[i]])\n",
    "#                             for i in range(len(observations))])\n",
    "\n",
    "#     RL_top_seqs = []\n",
    "#     while noisy_landscape_RL.cost<batch_size*generations:\n",
    "#         if (sampling_method == 'eps'):\n",
    "#             eps = max(0.2,(0.5 - noisy_landscape_RL.cost / (batch_size * generations)))\n",
    "#             method = (sampling_method, eps)\n",
    "#         elif (sampling_method == 'multi_eps'):\n",
    "#             eps = max(0.2,(0.5 - noisy_landscape_RL.cost / (batch_size * generations)))\n",
    "#             method = (sampling_method, eps)\n",
    "#         elif (sampling_method.split('.')[0] == 'rollout'):\n",
    "#             eps = max(0.1,(0.5 - noisy_landscape_RL.cost / (batch_size * generations)))\n",
    "#             k = int(sampling_method.split('.')[1])\n",
    "#             d = int(sampling_method.split('.')[2])\n",
    "#             method = ('rollout', eps, k, d)\n",
    "#         else:\n",
    "#             method = (sampling_method,)\n",
    "        \n",
    "#         b = 0\n",
    "#         new = []\n",
    "#         while(b < batch_size):\n",
    "#             s = agent.pick_action(method)\n",
    "#             if not s in noisy_landscape_RL.measured_sequences.keys() and not s in new:\n",
    "#                 new.append(s)\n",
    "#                 b += 1\n",
    "#     #     new=[agent.pick_action_epsilon_greedy(epsilon=eps) for _ in range(batch_size)]\n",
    "#         noisy_landscape_RL.measure_true_landscape(new)\n",
    "#         observations += new\n",
    "#         avg_loss = agent.train_actor(noisy_landscape_RL,observations, train_epochs=50)\n",
    "#         print (noisy_landscape_RL.cost, noisy_landscape_RL.get_fitness(new_sequences[-1][1][0]), avg_loss)\n",
    "#         new_sequences += [(noisy_landscape_RL.get_fitness(new[i]),[new[i]]) for i in range(len(new))]\n",
    "#         new_sequences = sorted(new_sequences)\n",
    "\n",
    "#         RL_top_seqs += [(noisy_landscape_RL.cost, new_sequences[-1][0])]\n",
    "#     return RL_top_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i*0.01 for i in range(100)], [np.exp(-3*i*0.01) for i in range(100)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RL(initial_genotypes, batch_size, generations, sampling_method):\n",
    "    noisy_landscape_RL.reset()\n",
    "    noisy_landscape_RL.measure_true_landscape(initial_genotypes)\n",
    "    noisy_landscape_RL.natural_mode=False\n",
    "    noisy_landscape_RL.local_mode=False\n",
    "    noisy_landscape_RL.cost\n",
    "    agent = RL_agent_QN(noisy_landscape_RL,wt,alphabet=RAA,memory_size=10000, device=device)\n",
    "    observations=[x for x in initial_genotypes]\n",
    "    agent.train_actor(noisy_landscape_RL,observations, train_epochs=10)\n",
    "    new_sequences = sorted([(noisy_landscape_RL.get_fitness(observations[i]),observations[i])\n",
    "                            for i in range(len(observations))])\n",
    "#     agent.memory = new_sequences\n",
    "    print (noisy_landscape_RL.cost, new_sequences[-1][0])#, avg_loss)\n",
    "    \n",
    "    RL_top_seqs = []\n",
    "    while noisy_landscape_RL.cost<batch_size*generations:\n",
    "        if (sampling_method == 'eps' or sampling_method == 'multi_eps'):\n",
    "            eps = 0.1+0.5*np.exp(-3*noisy_landscape_RL.cost / (batch_size * generations))\n",
    "                    #max(0.1,1-2*noisy_landscape_RL.cost / (batch_size * generations)) #max(0.2,(0.5 - noisy_landscape_RL.cost / (batch_size * generations)))\n",
    "            method = (sampling_method, eps)\n",
    "            \n",
    "            b = 0\n",
    "            new = []\n",
    "            cost_start = noisy_landscape_RL.cost\n",
    "            # get b new mutations\n",
    "            while(noisy_landscape_RL.cost < cost_start + batch_size):\n",
    "                s = agent.pick_action(method)\n",
    "                if not s in noisy_landscape_RL.measured_sequences.keys():# and not s in new:\n",
    "                    new.append(s)\n",
    "                noisy_landscape_RL.measure_true_landscape([s])\n",
    "            # measure true fitness of these mutations\n",
    "    #         noisy_landscape_RL.measure_true_landscape(new)\n",
    "            observations += new\n",
    "            new_sequences += [(noisy_landscape_RL.get_fitness(new[i]),new[i]) for i in range(len(new))]\n",
    "            new_sequences = sorted(new_sequences)\n",
    "\n",
    "            # train\n",
    "            avg_loss = agent.train_actor(noisy_landscape_RL,observations, train_epochs=20)\n",
    "\n",
    "            # print best mutation\n",
    "            print (noisy_landscape_RL.cost, new_sequences[-1][0], avg_loss)\n",
    "\n",
    "            RL_top_seqs += [(noisy_landscape_RL.cost, new_sequences[-1][0])]\n",
    "        \n",
    "        elif (sampling_method.split('.')[0] == 'rollout'):\n",
    "            eps = 0.1+0.5*np.exp(-3*noisy_landscape_RL.cost / (batch_size * generations))\n",
    "                         #max(0.1,1-2*noisy_landscape_RL.cost / (batch_size * generations)) #max(0.2,(0.5 - 2*noisy_landscape_RL.cost / (batch_size * generations)))\n",
    "            k = int(sampling_method.split('.')[1])\n",
    "            d = int(sampling_method.split('.')[2])\n",
    "            method = ('rollout', eps, k, d)\n",
    "            new = []\n",
    "            cost_start = noisy_landscape_RL.cost\n",
    "            samples = agent.pick_action_batch(method, batch_size)\n",
    "            ix = 0\n",
    "            while(noisy_landscape_RL.cost < cost_start + batch_size):\n",
    "                s = samples[ix][0] if random.random() > eps and ix < len(samples) else agent.pick_action(('eps',eps))\n",
    "#                 s = samples[np.random.int(0,len(samples)-1)][1] if random.random() < eps else agent.memory[ix][1]\n",
    "                if not s in noisy_landscape_RL.measured_sequences.keys() and not s in new:\n",
    "                    new.append(s)\n",
    "#                     print(ix)\n",
    "                    noisy_landscape_RL.measure_true_landscape([s])\n",
    "                ix += 1\n",
    "            # measure true fitness of these mutations\n",
    "            observations += new\n",
    "            new_sequences += [(noisy_landscape_RL.get_fitness(new[i]),new[i]) for i in range(len(new))]\n",
    "#             print ([x[0] for x in new_sequences])\n",
    "            new_sequences = sorted(new_sequences)\n",
    "\n",
    "            # train\n",
    "            avg_loss = agent.train_actor(noisy_landscape_RL,observations, train_epochs=20)\n",
    "\n",
    "            # print best mutation and move state there\n",
    "            print (noisy_landscape_RL.cost, new_sequences[-1][0], avg_loss)\n",
    "            agent.state = translate_string_to_one_hot(new_sequences[-1][1],agent.alphabet)\n",
    "\n",
    "            RL_top_seqs += [(noisy_landscape_RL.cost, new_sequences[-1][0])]\n",
    "            \n",
    "            \n",
    "    return RL_top_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.09647058599135455\n",
      "60 0.18000000224393956 0.00673231715336442\n",
      "110 0.19411764705882353 0.002275396045297384\n",
      "160 0.2552941266228171 0.0027023333124816416\n",
      "210 0.26823528514188877 0.004600208019837737\n",
      "260 0.36705883250517 0.007736112363636494\n",
      "310 0.4117647058823529 0.009103940008208156\n",
      "360 0.4176470588235294 0.011256410647183657\n",
      "410 0.4176470588235294 0.011765931686386465\n",
      "460 0.4176470588235294 0.012323042144998908\n",
      "510 0.4176470588235294 0.012926207389682531\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "generations = 10\n",
    "RL_data = run_RL(initial_genotypes, batch_size, generations, 'rollout.20.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_diff_parameters(batch_size, generations):\n",
    "    top_seqs = {}\n",
    "    top_seqs['CE'] = run_CE(initial_genotypes, batch_size, generations)\n",
    "    top_seqs['RL_eps'] = run_RL(initial_genotypes, batch_size, generations, \"eps\")\n",
    "#     top_seqs['RL_rollout2_k20_d2'] = run_RL(initial_genotypes, batch_size, generations, \"rollout.20.2\")\n",
    "    top_seqs['RL_rollout3_k20_d5'] = run_RL(initial_genotypes, batch_size, generations, \"rollout.20.5\")\n",
    "#     top_seqs['RL_rollout2_k7_d4'] = run_RL(initial_genotypes, batch_size, generations, \"rollout.7.4\")\n",
    "#     top_seqs['RL_rollout2_k3_d7'] = run_RL(initial_genotypes, batch_size, generations, \"rollout.3.7\")\n",
    "    return top_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim: 0, Batch size: 1000, Generations: 10\n",
      "10 0.09647058599135455\n",
      "160 0.14588234845329734\n",
      "1160 0.28470589132869945\n",
      "2160 0.28470589132869945\n",
      "3160 0.2905882442698759\n",
      "4160 0.33882352043600644\n",
      "5160 0.38235294117647056\n",
      "6160 0.3941176470588235\n",
      "7160 0.421176461612477\n",
      "8160 0.4235294117647059\n",
      "9160 0.4658823349896599\n",
      "10160 0.4729411854463465\n",
      "10 0.09647058599135455\n",
      "1010 0.15411765154670268 0.0032347057131119072\n",
      "2010 0.1588235294117647 0.001042912426055409\n",
      "3010 0.21882353389964385 0.0016234956216067075\n",
      "4010 0.24588234845329734 0.001822294620797038\n",
      "5010 0.24588234845329734 0.0017235942708794028\n",
      "6010 0.2529411764705882 0.0018227325344923884\n",
      "7010 0.25764705433565027 0.0019329326401930302\n",
      "8010 0.25882352941176473 0.0018723543791566045\n",
      "9010 0.25882352941176473 0.0018995288468431682\n",
      "10010 0.25882352941176473 0.001855286327190697\n",
      "10 0.09647058599135455\n",
      "1010 0.23999999551212087 0.003946721064858138\n",
      "2010 0.26705883250517004 0.002754692151211202\n",
      "3010 0.32588236191693476 0.004222423583269119\n",
      "4010 0.35764705433565025 0.004403284122236073\n"
     ]
    }
   ],
   "source": [
    "for sim in range(10):\n",
    "    for batch_size, generations in [(1000,10)]:#[(10,10),(50,10),(100,10)]:#,(1000,10)]:\n",
    "        print(\"Sim: {}, Batch size: {}, Generations: {}\".format(sim, batch_size, generations))\n",
    "        top_seqs = compare_diff_parameters(batch_size, generations)\n",
    "        np.save('./simulations/CE/batch{batch_size}_generations{generations}_{sim}'.format(\n",
    "            batch_size=batch_size, generations=generations, sim=sim), top_seqs['CE'])\n",
    "        for explorer in ['RL_eps', 'RL_rollout3_k20_d5']:\n",
    "            np.save('./simulations/RL/{sampling}_batch{batch_size}_generations{generations}_{sim}'.format(\n",
    "            sampling=explorer[3:],batch_size=batch_size, generations=generations, sim=sim), \n",
    "                    top_seqs[explorer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "generations = 10\n",
    "f,ax = plt.subplots(1,1,figsize=(6,4))\n",
    "plt.xlabel(\"cost\")\n",
    "plt.ylabel(\"maximum fitness observed\")\n",
    "\n",
    "for sampling,explorer,label in [('','CE','CE'), ('eps_','RL','RL_eps'), \n",
    "                                ('rollout3_k20_d5_', 'RL','RL_rollout3_k20_d5')]:#, \n",
    "#                                 ('rollout2_k7_d4_', 'RL', 'RL_rollout2_k7_d4'),\n",
    "#                                ('rollout2_k10_d3_', 'RL', 'RL_rollout2_k10_d3'),\n",
    "#                                ('rollout2_k20_d2_', 'RL', 'RL_rollout2_k20_d2')]:\n",
    "    data_explorer = pd.DataFrame(columns = ['cost', explorer])\n",
    "    for sim in range(10):\n",
    "        top_seqs_explorer = np.load('./simulations/{explorer}/{sampling}batch{batch_size}_generations{generations}_{sim}.npy'.format(\n",
    "                explorer=explorer,sampling=sampling, batch_size=batch_size, generations=generations, sim=sim))\n",
    "#         print(top_seqs_explorer)\n",
    "        data_explorer = data_explorer.append(pd.DataFrame(data=np.array([[s[0] for s in top_seqs_explorer if s[0] <= batch_size*generations],\n",
    "                                                                         [s[1] for s in top_seqs_explorer if s[0] <= batch_size*generations]]).T, \n",
    "                                         columns = ['cost', explorer]))\n",
    "\n",
    "#     print(data_explorer)\n",
    "    data_explorer = data_explorer.sort_values('cost')#.rolling(10).mean()\n",
    "#     data_explorer.plot(x='cost',y=explorer, ax = ax)\n",
    "    sns.lineplot(x='cost',y=explorer,data=data_explorer, label=label, ci = 'sd')\n",
    "plt.legend()\n",
    "plt.title(\"Batch Size={batch_size}, Generations={generations}\".format(\n",
    "    batch_size=batch_size, generations=generations))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "f.savefig('./figs/comparison_CE_eps_rollout3_batch{batch}_generations{generations}.png'.format(batch=batch_size,\n",
    "                                                                                         generations=generations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI AGENT RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RL_multi_agent_QN():\n",
    "    def __init__(self,agent_type,landscape,wt,alphabet, pop_size,memory_size=1200,best_seq_prop=1):\n",
    "        self.memory=[]\n",
    "        self.pop_size=pop_size\n",
    "        self.alphabet=alphabet\n",
    "        self.wt=wt\n",
    "        self.agents=[agent_type(self.wt,self.alphabet) for i in range(self.pop_size)]\n",
    "        self.memory_size=memory_size\n",
    "        self.memory=[]\n",
    "        self.landscape=landscape\n",
    "        self.best_seqs=[]\n",
    "        self.best_seqs_len=self.pop_size*best_seq_prop\n",
    "\n",
    "    def add_to_top_seqs(self,sequence):\n",
    "        fitness= self.landscape.get_fitness(sequence)\n",
    "        if len(self.best_seqs)<self.best_seqs_len:\n",
    "            self.best_seqs.append((fitness,sequence))\n",
    "\n",
    "        else:\n",
    "            if fitness > self.best_seqs[0][0] and (fitness,sequence) not in self.best_seqs:\n",
    "                self.best_seqs.append((fitness,sequence))\n",
    "                self.best_seqs=sorted(self.best_seqs)\n",
    "                self.best_seqs=self.best_seqs[1:]\n",
    "\n",
    "    def reset_position(self,sequence):\n",
    "        for agent in self.agents:\n",
    "            agent.reset_position(sequence)\n",
    "\n",
    "    def observe(self, num_observations=1000, costly=False, depth=10):\n",
    "        for agent in self.agents:\n",
    "            observations=agent.observe(self.landscape,[generate_random_mutant(agent.get_position(),0.1,self.alphabet) for i in range(num_observations)],costly=True,depth=depth)\n",
    "            self.memory.extend(observations)\n",
    "        if len(self.memory)>self.memory_size:\n",
    "            self.memory=random.sample(self.memory,self.memory_size)\n",
    "            \n",
    "    def force_observations(self, observations):\n",
    "        num_agents = len(self.agents)\n",
    "        for agent in self.agents:\n",
    "            agent.memory.extend(observations)\n",
    "            if len(agent.memory) > agent.memory_size:\n",
    "                agent.memory = random.sample(agent.memory, agent.memory_size)\n",
    "\n",
    "    def train_agents(self, observations):\n",
    "        total_loss = 0.0\n",
    "        for agent in self.agents:\n",
    "            total_loss += agent.train_actor(self.landscape, observations, train_epochs=20)\n",
    "        return total_loss/len(self.agents)\n",
    "\n",
    "    def cross_train_agents(self, observations, num_x_obs=1000):\n",
    "        total_loss = 0.0\n",
    "        for agent in self.agents:\n",
    "            total_loss += agent.xtrain_actor(self.landscape, random.sample(observations,num_x_obs), train_size=max(len(observations), num_x_obs), train_epochs=20)\n",
    "        return total_loss/len(self.agents)\n",
    "\n",
    "    def pick_action(self, method):\n",
    "        self.sequences=[]\n",
    "        sequences=[]\n",
    "        for agent_id, agent in enumerate(self.agents):\n",
    "            action = agent.pick_action(method)\n",
    "            self.sequences.append(action)\n",
    "            sequences.append((action, agent_id))\n",
    "#             self.memory.extend(agent.memory)\n",
    "\n",
    "#         if len(self.memory)>self.memory_size:\n",
    "#             self.memory=random.sample(self.memory,self.memory_size)\n",
    "\n",
    "        for seq in self.sequences:\n",
    "            self.add_to_top_seqs(seq)\n",
    "\n",
    "        return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RL_multi_agent(initial_genotypes, batch_size, generations, sampling_method, num_agents=10):\n",
    "    noisy_landscape_RL_multiple.reset()\n",
    "    noisy_landscape_RL_multiple.measure_true_landscape(initial_genotypes)\n",
    "    noisy_landscape_RL_multiple.natural_mode=False\n",
    "    noisy_landscape_RL_multiple.local_mode=False\n",
    "    noisy_landscape_RL_multiple.cost\n",
    "\n",
    "    multi_agents = RL_multi_agent_QN(RL_agent_QN,\n",
    "                              noisy_landscape_RL_multiple,\n",
    "                              wt,\n",
    "                              RAA,\n",
    "                              num_agents,\n",
    "                              memory_size=batch_size)\n",
    "\n",
    "    # set the SAME initial position for each\n",
    "    for i in range(num_agents):\n",
    "        multi_agents.agents[i].reset_position(initial_genotypes[0])\n",
    "\n",
    "    # keep separate list of observations for each agent\n",
    "    observations = [[x for x in initial_genotypes] for i in range(num_agents)]\n",
    "    new_sequences = sorted([(noisy_landscape_RL_multiple.get_fitness(observations[i]),[observations[i]])\n",
    "                            for i in range(len(observations))])\n",
    "\n",
    "    multi_RL_top_seqs = []\n",
    "    \n",
    "    while noisy_landscape_RL_multiple.cost < batch_size * generations:\n",
    "        if (sampling_method == 'eps'):\n",
    "            eps = max(0.2,(0.5 - noisy_landscape_RL.cost / (batch_size * generations)))\n",
    "            method = (sampling_method, eps)\n",
    "        elif (sampling_method == 'multi_eps'):\n",
    "            eps = max(0.2,(0.5 - noisy_landscape_RL.cost / (batch_size * generations)))\n",
    "            method = (sampling_method, eps)\n",
    "        elif (sampling_method == 'rollout'):\n",
    "            eps = max(0.2,(0.5 - noisy_landscape_RL.cost / (batch_size * generations)))\n",
    "            method = (sampling_method, eps)\n",
    "        else:\n",
    "            method = (sampling_method,)\n",
    "        \n",
    "        # DOESN'T WORK: goal; train each agent on their own observations, and a subsample of other agents observations\n",
    "        b = 0\n",
    "        new = []\n",
    "        new_indices = []\n",
    "        while(b < batch_size):\n",
    "            seqs = multi_agents.pick_action(method)\n",
    "            for s in seqs:\n",
    "                if not s[0] in noisy_landscape_RL_multiple.measured_sequences.keys():\n",
    "                    new += [s[0]]\n",
    "                    new_indices += [s[1]]\n",
    "                    b += 1\n",
    "\n",
    "        noisy_landscape_RL_multiple.measure_true_landscape(new)\n",
    "        observations += new\n",
    "    #     multi_agents.force_observations(observations)\n",
    "        avg_loss = multi_agents.train_agents(observations)\n",
    "        print(noisy_landscape_RL_multiple.cost, noisy_landscape_RL_multiple.get_fitness(new_sequences[-1][1][0]), avg_loss)\n",
    "        new_sequences += [(noisy_landscape_RL_multiple.get_fitness(new[i]),[new[i]]) for i in range(len(new))]\n",
    "        new_sequences = sorted(new_sequences)\n",
    "        multi_RL_top_seqs += [(noisy_landscape_RL_multiple.cost, new_sequences[-1][0])]\n",
    "        \n",
    "    return multi_RL_top_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.12823528962976793 0.012512424145825207\n",
      "30 0.1411764705882353 0.0030382839759113267\n",
      "40 0.1411764705882353 0.0010462194797582923\n",
      "50 0.16823529636158663 0.0009342695659142919\n",
      "58 0.19529412213493796 0.0009595630734111182\n",
      "67 0.24235294566434973 0.001135399741178844\n",
      "75 0.28705881904153263 0.001163351938885171\n",
      "85 0.3729411854463465 0.0011376501337508672\n",
      "92 0.3729411854463465 0.0008774404850555584\n",
      "100 0.3729411854463465 0.0012642273897654375\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "generations = 10\n",
    "num_agents = 2\n",
    "RL_data = run_RL_multi_agent(initial_genotypes, batch_size, generations, 'multi_eps', num_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
