{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import bisect\n",
    "import copy \n",
    "import os \n",
    "from collections import deque, Counter\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import editdistance\n",
    "import sys\n",
    "import RNA\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# import path \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.sequence_utils import translate_one_hot_to_string,generate_random_mutant\n",
    "from utils.sequence_utils import translate_string_to_one_hot, translate_one_hot_to_string\n",
    "from models.Theoretical_models import *\n",
    "from models.Noise_wrapper import *\n",
    "from exploration_strategies.CE import *\n",
    "from utils.landscape_utils import *\n",
    "from models.RNA_landscapes import *\n",
    "from models.Multi_dimensional_model import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.agents import tf_agent\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.agents.ppo import ppo_policy, ppo_agent, ppo_utils\n",
    "from tf_agents.environments import py_environment, tf_py_environment\n",
    "from tf_agents.environments.utils import validate_py_environment\n",
    "from tf_agents.drivers import dynamic_episode_driver\n",
    "from tf_agents.networks import network, normal_projection_network\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.specs import array_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAA=\"UGCA\" #alphabet\n",
    "alphabet_len=len(RAA)\n",
    "# TODO: UNDO THIS\n",
    "# length=40\n",
    "length=20\n",
    "noise_alpha=1\n",
    "generations = 10\n",
    "experiment_batch_size = 1000\n",
    "wt=generate_random_sequences(length,1,alphabet=RAA)[0]\n",
    "landscape1=RNA_landscape(wt)\n",
    "landscape2=RNA_landscape(wt)\n",
    "noisy_landscape=Noise_wrapper(landscape1,\n",
    "                              noise_alpha=noise_alpha,\n",
    "                              always_costly=True)\n",
    "initial_genotypes=list(set([wt]+[generate_random_mutant(wt,0.05,RAA) \n",
    "                                 for i in range(experiment_batch_size*10)]))[:experiment_batch_size]\n",
    "noisy_landscape.reset()\n",
    "noisy_landscape.measure_true_landscape(initial_genotypes)\n",
    "noisy_landscape.natural_mode=False\n",
    "noisy_landscape.local_mode=False\n",
    "noisy_landscape.cost\n",
    "\n",
    "def renormalize_moves(one_hot_input, rewards_output):\n",
    "    \"\"\"ensures that staying in place gives no reward\"\"\"\n",
    "    zero_current_state = (one_hot_input - 1) * (-1)\n",
    "    return np.multiply(rewards_output, zero_current_state)\n",
    "\n",
    "def walk_away_renormalize_moves(one_hot_input, one_hot_wt, rewards_output):\n",
    "    \"\"\"ensures that moving toward wt is also not useful\"\"\"\n",
    "    zero_current_state=(one_hot_input-1)*-1\n",
    "    zero_wt=((one_hot_wt-1)*-1)\n",
    "    zero_conservative_moves=np.multiply(zero_wt,zero_current_state)\n",
    "    return np.multiply(rewards_output,zero_conservative_moves)\n",
    "\n",
    "def get_all_singles_fitness(model,sequence,alphabet):\n",
    "    prob_singles=np.zeros((len(alphabet),len(sequence)))\n",
    "    for i in range(len(sequence)):\n",
    "        for j in range(len(alphabet)):\n",
    "            putative_seq=sequence[:i]+alphabet[j]+sequence[i+1:]\n",
    "           # print (putative_seq)\n",
    "            prob_singles[j][i]=model.get_fitness(putative_seq)\n",
    "    return prob_singles\n",
    "\n",
    "def get_all_mutants(sequence):\n",
    "    mutants = []\n",
    "    for i in range(sequence.shape[0]):\n",
    "        for j in range(sequence.shape[1]):\n",
    "            putative_seq = sequence.copy()\n",
    "            putative_seq[:, j] = 0\n",
    "            putative_seq[i, j] = 1\n",
    "            mutants.append(putative_seq)\n",
    "    return np.array(mutants)\n",
    "\n",
    "def sample_greedy(matrix):\n",
    "    i,j=matrix.shape\n",
    "    max_arg=np.argmax(matrix)\n",
    "    y=max_arg%j\n",
    "    x=int(max_arg/j)\n",
    "    output=np.zeros((i,j))\n",
    "    output[x][y]=matrix[x][y]\n",
    "    return output\n",
    "\n",
    "def sample_multi_greedy(matrix):\n",
    "    n = 5 # the number of base positions to greedily change\n",
    "    max_args = np.argpartition(matrix.flatten(), -n)[-n:]\n",
    "    i,j=matrix.shape\n",
    "    output=np.zeros((i,j))\n",
    "    for max_arg in max_args:\n",
    "        y=max_arg%j\n",
    "        x=int(max_arg/j)\n",
    "        output[x][y]=matrix[x][y]\n",
    "    return output\n",
    "\n",
    "def sample_random(matrix):\n",
    "    i,j=matrix.shape\n",
    "    non_zero_moves=np.nonzero(matrix)\n",
    "   # print (non_zero_moves)\n",
    "    k=len(non_zero_moves)\n",
    "    l=len(non_zero_moves[0])\n",
    "    if k!=0 and l!=0:\n",
    "        rand_arg=random.choice([[non_zero_moves[alph][pos] for alph in range(k)] for pos in range(l)])\n",
    "    else:\n",
    "        rand_arg=[random.randint(0,i-1),random.randint(0,j-1)]\n",
    "    #print (rand_arg)\n",
    "    y=rand_arg[1]\n",
    "    x=rand_arg[0]\n",
    "    output=np.zeros((i,j))\n",
    "    output[x][y] = 1\n",
    "    return output   \n",
    "\n",
    "def action_to_scalar(matrix):\n",
    "    matrix = matrix.ravel()\n",
    "    for i in range(len(matrix)):\n",
    "        if matrix[i] != 0:\n",
    "            return i\n",
    "    \n",
    "def construct_mutant_from_sample(pwm_sample, one_hot_base):\n",
    "    one_hot = np.zeros(one_hot_base.shape)\n",
    "    one_hot += one_hot_base\n",
    "    nonzero = np.nonzero(pwm_sample)\n",
    "    nonzero = list(zip(nonzero[0], nonzero[1]))\n",
    "    for nz in nonzero: # this can be problematic for non-positive fitnesses\n",
    "        i, j = nz\n",
    "        one_hot[:,j]=0\n",
    "        one_hot[i,j]=1\n",
    "    return one_hot\n",
    "\n",
    "def best_predicted_new_gen(actor, genotypes, alphabet, pop_size):\n",
    "    mutants = get_all_mutants(genotypes)\n",
    "    one_hot_mutants = np.array([translate_string_to_one_hot(mutant, alphabet) for mutant in mutants])\n",
    "    torch_one_hot_mutants = torch.from_numpy(np.expand_dims(one_hot_mutants, axis=0)).float()\n",
    "    predictions = actor(torch_one_hot_mutants)\n",
    "    predictions = predictions.detach().numpy()\n",
    "    best_pred_ind = predictions.argsort()[-pop_size:]\n",
    "    return mutants[best_pred_ind]\n",
    "\n",
    "def make_one_hot_train_test(genotypes, model, alphabet):\n",
    "    genotypes_one_hot = np.array([translate_string_to_one_hot(genotype, alphabet) for genotype in genotypes])\n",
    "    genotype_fitnesses = []\n",
    "    for genotype in genotypes:\n",
    "        genotype_fitnesses.append(model.get_fitness(genotype))\n",
    "    genotype_fitnesses = np.array(genotype_fitnesses)\n",
    "\n",
    "    return genotypes_one_hot, genotype_fitnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for PPO Agent \n",
    "generations = 10\n",
    "experiment_batch_size = 1000\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "optimizer.iterations = global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment for PPO Agent\n",
    "class FitnessLandscapeEnvironment(py_environment.PyEnvironment):\n",
    "    # Based on this: https://www.mikulskibartosz.name/how-to-create-an-environment-for-a-tensorflow-agent/\n",
    "    def __init__(self, alphabet, seq_len, landscape, max_episodes):\n",
    "        self.alphabet = alphabet\n",
    "        self.alphabet_len = len(self.alphabet)\n",
    "        self.landscape = copy.deepcopy(landscape)\n",
    "        self.seq_len = seq_len\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(1, 2), dtype=np.float32, minimum=0, \n",
    "            maximum=1, name='action_x')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(self.alphabet_len, self.seq_len), dtype=np.float32, minimum=0, \n",
    "            maximum=1, name='observation')\n",
    "        self._time_step_spec = ts.time_step_spec(self._observation_spec)\n",
    "        self._state = translate_string_to_one_hot(wt, self.alphabet)\n",
    "        self._episode_ended = False\n",
    "        self.ctr = 0\n",
    "        self.max_episodes = max_episodes\n",
    "        self.seen_sequences = {}\n",
    "        \n",
    "    def _reset(self):\n",
    "        self.ctr = 0\n",
    "        # TODO: UNDO THIS\n",
    "#         self._state = translate_string_to_one_hot(wt, self.alphabet)\n",
    "        self._state = translate_string_to_one_hot(generate_random_sequences(length,1,alphabet=RAA)[0], self.alphabet)\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(np.array(self._state, dtype=np.float32))\n",
    "    \n",
    "    def time_step_spec(self):\n",
    "        return self._time_step_spec \n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "    \n",
    "    def get_state_string(self):\n",
    "        return translate_one_hot_to_string(self._state, self.alphabet)\n",
    "    \n",
    "    def _step(self, action):\n",
    "        if self.ctr < self.max_episodes:\n",
    "            self.ctr += 1\n",
    "            action_one_hot = np.zeros((self.alphabet_len, self.seq_len))\n",
    "#             print(action)\n",
    "            if np.amax(action) > 1 or np.amin(action) < 0:\n",
    "                return ts.termination(np.array(self._state, dtype=np.float32), 0)\n",
    "            x, y = action[0]\n",
    "            x, y = int(self.alphabet_len*x), int(self.seq_len*y)\n",
    "            action_one_hot[x, y] = 1\n",
    "            assert self._state.sum() == self._state.shape[1]\n",
    "            if self._state[x, y] == 1:\n",
    "                self._episode_ended = True\n",
    "                return ts.termination(np.array(self._state, dtype=np.float32), 0)\n",
    "            else:\n",
    "                self._state = construct_mutant_from_sample(action_one_hot, self._state)\n",
    "                state_string = translate_one_hot_to_string(self._state, self.alphabet)\n",
    "                \n",
    "                if state_string in self.seen_sequences:\n",
    "                    return ts.termination(np.array(self._state, dtype=np.float32), 0)\n",
    "                self.seen_sequences[state_string] = 1\n",
    "                \n",
    "                reward = self.landscape.get_fitness(state_string)\n",
    "                assert self._state.sum() == self._state.shape[1]\n",
    "                return ts.transition(np.array(self._state, dtype=np.float32), reward=reward)\n",
    "        else:\n",
    "            self._episode_ended = True\n",
    "            assert self._state.sum() == self._state.shape[1]\n",
    "            return ts.termination(np.array(self._state, dtype=np.float32), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting validating environment...\n",
      "done validating environment.\n"
     ]
    }
   ],
   "source": [
    "#max_iter = experiment_batch_size * generations \n",
    "max_iter = 10 ** 6\n",
    "fle2 = FitnessLandscapeEnvironment(RAA, length, landscape1, max_iter)\n",
    "print(\"starting validating environment...\")\n",
    "validate_py_environment(fle2, episodes=2)\n",
    "print(\"done validating environment.\")\n",
    "fle = FitnessLandscapeEnvironment(RAA, length, landscape2, max_iter)\n",
    "tf_env = tf_py_environment.TFPyEnvironment(fle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specs \n",
    "time_step_spec = tf_env.time_step_spec()\n",
    "observation_spec = tf_env.observation_spec()\n",
    "action_spec = tf_env.action_spec()\n",
    "alphabet_len = len(RAA)\n",
    "seq_len = length\n",
    "\n",
    "def BoostedEnvironment():\n",
    "    return FitnessLandscapeEnvironment(RAA, length, landscape2, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Spawning all processes.\n",
      "INFO:absl:All processes started.\n",
      "INFO:absl:Checkpoint available: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-6000\n",
      "INFO:absl:Checkpoint available: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-6000\n",
      "INFO:absl:step = 6050, loss = 0.327176\n",
      "INFO:absl:0.488 steps/sec\n",
      "INFO:absl:collect_time = 0.913827657699585, train_time = 50.274866342544556\n",
      "INFO:absl:step = 6100, loss = 0.593229\n",
      "INFO:absl:258.382 steps/sec\n",
      "INFO:absl:collect_time = 0.08973288536071777, train_time = 0.10377907752990723\n",
      "INFO:absl:step = 6150, loss = 0.491860\n",
      "INFO:absl:225.788 steps/sec\n",
      "INFO:absl:collect_time = 0.1052849292755127, train_time = 0.11616206169128418\n",
      "INFO:absl:step = 6200, loss = 0.431152\n",
      "INFO:absl:198.255 steps/sec\n",
      "INFO:absl:collect_time = 0.11707305908203125, train_time = 0.13512778282165527\n",
      "INFO:absl:step = 6250, loss = 3.424420\n",
      "INFO:absl:199.480 steps/sec\n",
      "INFO:absl:collect_time = 0.14392495155334473, train_time = 0.10672688484191895\n",
      "INFO:absl:step = 6300, loss = 0.448811\n",
      "INFO:absl:255.893 steps/sec\n",
      "INFO:absl:collect_time = 0.09348607063293457, train_time = 0.10190820693969727\n",
      "INFO:absl:step = 6350, loss = 1.077134\n",
      "INFO:absl:256.815 steps/sec\n",
      "INFO:absl:collect_time = 0.08409714698791504, train_time = 0.1105952262878418\n",
      "INFO:absl:step = 6400, loss = 20.954617\n",
      "INFO:absl:259.299 steps/sec\n",
      "INFO:absl:collect_time = 0.08932805061340332, train_time = 0.1034994125366211\n",
      "INFO:absl:step = 6450, loss = 3.990386\n",
      "INFO:absl:265.106 steps/sec\n",
      "INFO:absl:collect_time = 0.08485293388366699, train_time = 0.10375118255615234\n",
      "INFO:absl:step = 6500, loss = 1.353493\n",
      "INFO:absl:236.964 steps/sec\n",
      "INFO:absl:collect_time = 0.08514189720153809, train_time = 0.12586021423339844\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-6500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000006500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000006500/assets\n",
      "INFO:absl:step = 6550, loss = 0.457388\n",
      "INFO:absl:301.313 steps/sec\n",
      "INFO:absl:collect_time = 0.07382988929748535, train_time = 0.09211039543151855\n",
      "INFO:absl:step = 6600, loss = 2.678300\n",
      "INFO:absl:263.632 steps/sec\n",
      "INFO:absl:collect_time = 0.08650803565979004, train_time = 0.1031501293182373\n",
      "INFO:absl:step = 6650, loss = 2.355242\n",
      "INFO:absl:248.940 steps/sec\n",
      "INFO:absl:collect_time = 0.08457183837890625, train_time = 0.11627960205078125\n",
      "INFO:absl:step = 6700, loss = 3.222640\n",
      "INFO:absl:302.447 steps/sec\n",
      "INFO:absl:collect_time = 0.07122921943664551, train_time = 0.09408926963806152\n",
      "INFO:absl:step = 6750, loss = 0.195254\n",
      "INFO:absl:277.279 steps/sec\n",
      "INFO:absl:collect_time = 0.07951688766479492, train_time = 0.10080718994140625\n",
      "INFO:absl:step = 6800, loss = 0.496647\n",
      "INFO:absl:226.840 steps/sec\n",
      "INFO:absl:collect_time = 0.10196495056152344, train_time = 0.1184544563293457\n",
      "INFO:absl:step = 6850, loss = 0.548117\n",
      "INFO:absl:163.612 steps/sec\n",
      "INFO:absl:collect_time = 0.15923786163330078, train_time = 0.1463623046875\n",
      "INFO:absl:step = 6900, loss = 0.479436\n",
      "INFO:absl:275.203 steps/sec\n",
      "INFO:absl:collect_time = 0.08068108558654785, train_time = 0.10100293159484863\n",
      "INFO:absl:step = 6950, loss = 0.393007\n",
      "INFO:absl:193.115 steps/sec\n",
      "INFO:absl:collect_time = 0.13066434860229492, train_time = 0.1282491683959961\n",
      "INFO:absl:step = 7000, loss = 0.865323\n",
      "INFO:absl:276.328 steps/sec\n",
      "INFO:absl:collect_time = 0.07707500457763672, train_time = 0.10386919975280762\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-7000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000007000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000007000/assets\n",
      "INFO:absl:step = 7050, loss = 1.937962\n",
      "INFO:absl:266.433 steps/sec\n",
      "INFO:absl:collect_time = 0.07274985313415527, train_time = 0.1149144172668457\n",
      "INFO:absl:step = 7100, loss = 0.306742\n",
      "INFO:absl:271.658 steps/sec\n",
      "INFO:absl:collect_time = 0.07436990737915039, train_time = 0.10968518257141113\n",
      "INFO:absl:step = 7150, loss = 0.339729\n",
      "INFO:absl:288.976 steps/sec\n",
      "INFO:absl:collect_time = 0.07502388954162598, train_time = 0.09800100326538086\n",
      "INFO:absl:step = 7200, loss = 0.431425\n",
      "INFO:absl:276.842 steps/sec\n",
      "INFO:absl:collect_time = 0.08433699607849121, train_time = 0.09627127647399902\n",
      "INFO:absl:step = 7250, loss = 0.269292\n",
      "INFO:absl:287.913 steps/sec\n",
      "INFO:absl:collect_time = 0.08380722999572754, train_time = 0.08985614776611328\n",
      "INFO:absl:step = 7300, loss = 4.611185\n",
      "INFO:absl:322.968 steps/sec\n",
      "INFO:absl:collect_time = 0.06992697715759277, train_time = 0.08488702774047852\n",
      "INFO:absl:step = 7350, loss = 0.334353\n",
      "INFO:absl:299.516 steps/sec\n",
      "INFO:absl:collect_time = 0.07109308242797852, train_time = 0.09584307670593262\n",
      "INFO:absl:step = 7400, loss = 0.203868\n",
      "INFO:absl:250.785 steps/sec\n",
      "INFO:absl:collect_time = 0.09252810478210449, train_time = 0.10684585571289062\n",
      "INFO:absl:step = 7450, loss = 0.903092\n",
      "INFO:absl:265.204 steps/sec\n",
      "INFO:absl:collect_time = 0.09177780151367188, train_time = 0.0967562198638916\n",
      "INFO:absl:step = 7500, loss = 0.663740\n",
      "INFO:absl:272.583 steps/sec\n",
      "INFO:absl:collect_time = 0.07460546493530273, train_time = 0.1088249683380127\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-7500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000007500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000007500/assets\n",
      "INFO:absl:step = 7550, loss = 0.419848\n",
      "INFO:absl:304.936 steps/sec\n",
      "INFO:absl:collect_time = 0.07573127746582031, train_time = 0.08823776245117188\n",
      "INFO:absl:step = 7600, loss = 0.624562\n",
      "INFO:absl:310.141 steps/sec\n",
      "INFO:absl:collect_time = 0.06985688209533691, train_time = 0.09136009216308594\n",
      "INFO:absl:step = 7650, loss = 0.933148\n",
      "INFO:absl:293.328 steps/sec\n",
      "INFO:absl:collect_time = 0.07640576362609863, train_time = 0.09405207633972168\n",
      "INFO:absl:step = 7700, loss = 0.608489\n",
      "INFO:absl:302.729 steps/sec\n",
      "INFO:absl:collect_time = 0.0725867748260498, train_time = 0.09257721900939941\n",
      "INFO:absl:step = 7750, loss = 0.210870\n",
      "INFO:absl:299.651 steps/sec\n",
      "INFO:absl:collect_time = 0.07546114921569824, train_time = 0.0913994312286377\n",
      "INFO:absl:step = 7800, loss = 0.437889\n",
      "INFO:absl:289.831 steps/sec\n",
      "INFO:absl:collect_time = 0.07190132141113281, train_time = 0.10061287879943848\n",
      "INFO:absl:step = 7850, loss = 0.183174\n",
      "INFO:absl:246.473 steps/sec\n",
      "INFO:absl:collect_time = 0.08505749702453613, train_time = 0.11780476570129395\n",
      "INFO:absl:step = 7900, loss = 1.044626\n",
      "INFO:absl:234.035 steps/sec\n",
      "INFO:absl:collect_time = 0.09655094146728516, train_time = 0.11709213256835938\n",
      "INFO:absl:step = 7950, loss = 1.243440\n",
      "INFO:absl:269.714 steps/sec\n",
      "INFO:absl:collect_time = 0.08315300941467285, train_time = 0.10222887992858887\n",
      "INFO:absl:step = 8000, loss = 0.425307\n",
      "INFO:absl:314.438 steps/sec\n",
      "INFO:absl:collect_time = 0.07258796691894531, train_time = 0.08642578125\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-8000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000008000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000008000/assets\n",
      "INFO:absl:step = 8050, loss = 1.309322\n",
      "INFO:absl:307.204 steps/sec\n",
      "INFO:absl:collect_time = 0.07191824913024902, train_time = 0.09083986282348633\n",
      "INFO:absl:step = 8100, loss = 1.232553\n",
      "INFO:absl:341.034 steps/sec\n",
      "INFO:absl:collect_time = 0.06228017807006836, train_time = 0.08433294296264648\n",
      "INFO:absl:step = 8150, loss = 0.193988\n",
      "INFO:absl:328.718 steps/sec\n",
      "INFO:absl:collect_time = 0.06548810005187988, train_time = 0.08661818504333496\n",
      "INFO:absl:step = 8200, loss = 0.737521\n",
      "INFO:absl:309.207 steps/sec\n",
      "INFO:absl:collect_time = 0.06781888008117676, train_time = 0.09388518333435059\n",
      "INFO:absl:step = 8250, loss = 1.769880\n",
      "INFO:absl:280.868 steps/sec\n",
      "INFO:absl:collect_time = 0.07486581802368164, train_time = 0.10315394401550293\n",
      "INFO:absl:step = 8300, loss = 2.907954\n",
      "INFO:absl:270.684 steps/sec\n",
      "INFO:absl:collect_time = 0.08800125122070312, train_time = 0.09671616554260254\n",
      "INFO:absl:step = 8350, loss = 0.152598\n",
      "INFO:absl:334.473 steps/sec\n",
      "INFO:absl:collect_time = 0.0616002082824707, train_time = 0.08788871765136719\n",
      "INFO:absl:step = 8400, loss = 0.297186\n",
      "INFO:absl:309.021 steps/sec\n",
      "INFO:absl:collect_time = 0.06895208358764648, train_time = 0.0928490161895752\n",
      "INFO:absl:step = 8450, loss = 0.237400\n",
      "INFO:absl:278.259 steps/sec\n",
      "INFO:absl:collect_time = 0.07834601402282715, train_time = 0.10134291648864746\n",
      "INFO:absl:step = 8500, loss = 0.470656\n",
      "INFO:absl:284.336 steps/sec\n",
      "INFO:absl:collect_time = 0.07572770118713379, train_time = 0.10012078285217285\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-8500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000008500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000008500/assets\n",
      "INFO:absl:step = 8550, loss = 2.763157\n",
      "INFO:absl:305.681 steps/sec\n",
      "INFO:absl:collect_time = 0.0662531852722168, train_time = 0.09731578826904297\n",
      "INFO:absl:step = 8600, loss = 0.397839\n",
      "INFO:absl:289.563 steps/sec\n",
      "INFO:absl:collect_time = 0.06387686729431152, train_time = 0.10879707336425781\n",
      "INFO:absl:step = 8650, loss = 0.531880\n",
      "INFO:absl:193.691 steps/sec\n",
      "INFO:absl:collect_time = 0.12361407279968262, train_time = 0.13452887535095215\n",
      "INFO:absl:step = 8700, loss = 0.901585\n",
      "INFO:absl:217.511 steps/sec\n",
      "INFO:absl:collect_time = 0.10374808311462402, train_time = 0.12612581253051758\n",
      "INFO:absl:step = 8750, loss = 0.342611\n",
      "INFO:absl:231.161 steps/sec\n",
      "INFO:absl:collect_time = 0.10838198661804199, train_time = 0.10791707038879395\n",
      "INFO:absl:step = 8800, loss = 0.857926\n",
      "INFO:absl:285.709 steps/sec\n",
      "INFO:absl:collect_time = 0.07627224922180176, train_time = 0.09873080253601074\n",
      "INFO:absl:step = 8850, loss = 0.662232\n",
      "INFO:absl:280.393 steps/sec\n",
      "INFO:absl:collect_time = 0.07929039001464844, train_time = 0.09903073310852051\n",
      "INFO:absl:step = 8900, loss = 0.879746\n",
      "INFO:absl:272.853 steps/sec\n",
      "INFO:absl:collect_time = 0.08162093162536621, train_time = 0.10162806510925293\n",
      "INFO:absl:step = 8950, loss = 0.564327\n",
      "INFO:absl:345.671 steps/sec\n",
      "INFO:absl:collect_time = 0.05928301811218262, train_time = 0.08536314964294434\n",
      "INFO:absl:step = 9000, loss = 0.645977\n",
      "INFO:absl:250.372 steps/sec\n",
      "INFO:absl:collect_time = 0.0801839828491211, train_time = 0.11951899528503418\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-9000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000009000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000009000/assets\n",
      "INFO:absl:step = 9050, loss = 0.446990\n",
      "INFO:absl:248.140 steps/sec\n",
      "INFO:absl:collect_time = 0.08246493339538574, train_time = 0.1190342903137207\n",
      "INFO:absl:step = 9100, loss = 0.870448\n",
      "INFO:absl:292.735 steps/sec\n",
      "INFO:absl:collect_time = 0.07385897636413574, train_time = 0.09694385528564453\n",
      "INFO:absl:step = 9150, loss = 0.333921\n",
      "INFO:absl:243.206 steps/sec\n",
      "INFO:absl:collect_time = 0.08575320243835449, train_time = 0.11983370780944824\n",
      "INFO:absl:step = 9200, loss = 0.468378\n",
      "INFO:absl:309.426 steps/sec\n",
      "INFO:absl:collect_time = 0.07043075561523438, train_time = 0.09115886688232422\n",
      "INFO:absl:step = 9250, loss = 0.988557\n",
      "INFO:absl:271.993 steps/sec\n",
      "INFO:absl:collect_time = 0.07933330535888672, train_time = 0.10449528694152832\n",
      "INFO:absl:step = 9300, loss = 0.589139\n",
      "INFO:absl:315.100 steps/sec\n",
      "INFO:absl:collect_time = 0.0632009506225586, train_time = 0.09547901153564453\n",
      "INFO:absl:step = 9350, loss = 0.219566\n",
      "INFO:absl:243.490 steps/sec\n",
      "INFO:absl:collect_time = 0.0938560962677002, train_time = 0.11149120330810547\n",
      "INFO:absl:step = 9400, loss = 0.701671\n",
      "INFO:absl:224.815 steps/sec\n",
      "INFO:absl:collect_time = 0.07935142517089844, train_time = 0.14305400848388672\n",
      "INFO:absl:step = 9450, loss = 2.517996\n",
      "INFO:absl:260.392 steps/sec\n",
      "INFO:absl:collect_time = 0.09547686576843262, train_time = 0.09654116630554199\n",
      "INFO:absl:step = 9500, loss = 1.112295\n",
      "INFO:absl:246.952 steps/sec\n",
      "INFO:absl:collect_time = 0.09116101264953613, train_time = 0.11130714416503906\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-9500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000009500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000009500/assets\n",
      "INFO:absl:step = 9550, loss = 0.553869\n",
      "INFO:absl:302.187 steps/sec\n",
      "INFO:absl:collect_time = 0.0704808235168457, train_time = 0.09497976303100586\n",
      "INFO:absl:step = 9600, loss = 0.166596\n",
      "INFO:absl:300.626 steps/sec\n",
      "INFO:absl:collect_time = 0.07394981384277344, train_time = 0.09237003326416016\n",
      "INFO:absl:step = 9650, loss = 0.326670\n",
      "INFO:absl:324.197 steps/sec\n",
      "INFO:absl:collect_time = 0.06292891502380371, train_time = 0.09129810333251953\n",
      "INFO:absl:step = 9700, loss = 0.840337\n",
      "INFO:absl:298.213 steps/sec\n",
      "INFO:absl:collect_time = 0.06781315803527832, train_time = 0.09985208511352539\n",
      "INFO:absl:step = 9750, loss = 0.253269\n",
      "INFO:absl:275.317 steps/sec\n",
      "INFO:absl:collect_time = 0.08143901824951172, train_time = 0.10017013549804688\n",
      "INFO:absl:step = 9800, loss = 0.373666\n",
      "INFO:absl:242.934 steps/sec\n",
      "INFO:absl:collect_time = 0.10892891883850098, train_time = 0.09688806533813477\n",
      "INFO:absl:step = 9850, loss = 1.696999\n",
      "INFO:absl:233.508 steps/sec\n",
      "INFO:absl:collect_time = 0.09383106231689453, train_time = 0.12029409408569336\n",
      "INFO:absl:step = 9900, loss = 1.461075\n",
      "INFO:absl:314.981 steps/sec\n",
      "INFO:absl:collect_time = 0.0657813549041748, train_time = 0.09295821189880371\n",
      "INFO:absl:step = 9950, loss = 2.377044\n",
      "INFO:absl:285.242 steps/sec\n",
      "INFO:absl:collect_time = 0.07725882530212402, train_time = 0.09803104400634766\n",
      "INFO:absl:step = 10000, loss = 0.299411\n",
      "INFO:absl:234.866 steps/sec\n",
      "INFO:absl:collect_time = 0.08699703216552734, train_time = 0.12589001655578613\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-10000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000010000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000010000/assets\n",
      "INFO:absl:step = 10050, loss = 1.308379\n",
      "INFO:absl:325.529 steps/sec\n",
      "INFO:absl:collect_time = 0.06386399269104004, train_time = 0.08973193168640137\n",
      "INFO:absl:step = 10100, loss = 0.174692\n",
      "INFO:absl:277.958 steps/sec\n",
      "INFO:absl:collect_time = 0.08427596092224121, train_time = 0.09560751914978027\n",
      "INFO:absl:step = 10150, loss = 0.280670\n",
      "INFO:absl:289.711 steps/sec\n",
      "INFO:absl:collect_time = 0.07226872444152832, train_time = 0.10031700134277344\n",
      "INFO:absl:step = 10200, loss = 0.964488\n",
      "INFO:absl:271.435 steps/sec\n",
      "INFO:absl:collect_time = 0.07799005508422852, train_time = 0.1062159538269043\n",
      "INFO:absl:step = 10250, loss = 1.047303\n",
      "INFO:absl:194.629 steps/sec\n",
      "INFO:absl:collect_time = 0.12446761131286621, train_time = 0.1324319839477539\n",
      "INFO:absl:step = 10300, loss = 0.287490\n",
      "INFO:absl:250.601 steps/sec\n",
      "INFO:absl:collect_time = 0.08243417739868164, train_time = 0.11708593368530273\n",
      "INFO:absl:step = 10350, loss = 1.310510\n",
      "INFO:absl:221.890 steps/sec\n",
      "INFO:absl:collect_time = 0.1064298152923584, train_time = 0.11890721321105957\n",
      "INFO:absl:step = 10400, loss = 0.588775\n",
      "INFO:absl:215.173 steps/sec\n",
      "INFO:absl:collect_time = 0.10202407836914062, train_time = 0.13034701347351074\n",
      "INFO:absl:step = 10450, loss = 0.614248\n",
      "INFO:absl:335.918 steps/sec\n",
      "INFO:absl:collect_time = 0.070159912109375, train_time = 0.07868599891662598\n",
      "INFO:absl:step = 10500, loss = 0.441397\n",
      "INFO:absl:313.568 steps/sec\n",
      "INFO:absl:collect_time = 0.07143783569335938, train_time = 0.08801722526550293\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-10500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-10500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000010500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000010500/assets\n",
      "INFO:absl:step = 10550, loss = 2.326523\n",
      "INFO:absl:290.012 steps/sec\n",
      "INFO:absl:collect_time = 0.07677698135375977, train_time = 0.09562969207763672\n",
      "INFO:absl:step = 10600, loss = 1.399264\n",
      "INFO:absl:278.484 steps/sec\n",
      "INFO:absl:collect_time = 0.08447504043579102, train_time = 0.09506821632385254\n",
      "INFO:absl:step = 10650, loss = 1.339389\n",
      "INFO:absl:295.072 steps/sec\n",
      "INFO:absl:collect_time = 0.07990121841430664, train_time = 0.08954906463623047\n",
      "INFO:absl:step = 10700, loss = 1.193581\n",
      "INFO:absl:312.385 steps/sec\n",
      "INFO:absl:collect_time = 0.07043099403381348, train_time = 0.08962798118591309\n",
      "INFO:absl:step = 10750, loss = 1.513503\n",
      "INFO:absl:338.675 steps/sec\n",
      "INFO:absl:collect_time = 0.06405925750732422, train_time = 0.08357477188110352\n",
      "INFO:absl:step = 10800, loss = 0.741922\n",
      "INFO:absl:282.860 steps/sec\n",
      "INFO:absl:collect_time = 0.08315086364746094, train_time = 0.09361481666564941\n",
      "INFO:absl:step = 10850, loss = 0.148338\n",
      "INFO:absl:249.668 steps/sec\n",
      "INFO:absl:collect_time = 0.09277081489562988, train_time = 0.10749506950378418\n",
      "INFO:absl:step = 10900, loss = 0.325065\n",
      "INFO:absl:259.173 steps/sec\n",
      "INFO:absl:collect_time = 0.07622289657592773, train_time = 0.1166982650756836\n",
      "INFO:absl:step = 10950, loss = 0.090714\n",
      "INFO:absl:160.212 steps/sec\n",
      "INFO:absl:collect_time = 0.14705610275268555, train_time = 0.16503000259399414\n",
      "INFO:absl:step = 11000, loss = 0.318839\n",
      "INFO:absl:239.799 steps/sec\n",
      "INFO:absl:collect_time = 0.09249520301818848, train_time = 0.1160128116607666\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-11000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-11000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000011000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000011000/assets\n",
      "INFO:absl:step = 11050, loss = 0.305020\n",
      "INFO:absl:252.240 steps/sec\n",
      "INFO:absl:collect_time = 0.08259701728820801, train_time = 0.11562705039978027\n",
      "INFO:absl:step = 11100, loss = 0.517850\n",
      "INFO:absl:257.036 steps/sec\n",
      "INFO:absl:collect_time = 0.08251667022705078, train_time = 0.11200857162475586\n",
      "INFO:absl:step = 11150, loss = 1.212381\n",
      "INFO:absl:243.084 steps/sec\n",
      "INFO:absl:collect_time = 0.10069441795349121, train_time = 0.1049957275390625\n",
      "INFO:absl:step = 11200, loss = 2.142819\n",
      "INFO:absl:218.023 steps/sec\n",
      "INFO:absl:collect_time = 0.11751413345336914, train_time = 0.11181998252868652\n",
      "INFO:absl:step = 11250, loss = 0.817836\n",
      "INFO:absl:277.946 steps/sec\n",
      "INFO:absl:collect_time = 0.07600998878479004, train_time = 0.1038811206817627\n",
      "INFO:absl:step = 11300, loss = 0.409746\n",
      "INFO:absl:292.860 steps/sec\n",
      "INFO:absl:collect_time = 0.07764720916748047, train_time = 0.09308266639709473\n",
      "INFO:absl:step = 11350, loss = 2.336945\n",
      "INFO:absl:178.881 steps/sec\n",
      "INFO:absl:collect_time = 0.1371450424194336, train_time = 0.14236998558044434\n",
      "INFO:absl:step = 11400, loss = 0.293138\n",
      "INFO:absl:212.966 steps/sec\n",
      "INFO:absl:collect_time = 0.11167788505554199, train_time = 0.12310171127319336\n",
      "INFO:absl:step = 11450, loss = 0.455075\n",
      "INFO:absl:271.204 steps/sec\n",
      "INFO:absl:collect_time = 0.08524203300476074, train_time = 0.0991213321685791\n",
      "INFO:absl:step = 11500, loss = 2.327032\n",
      "INFO:absl:212.008 steps/sec\n",
      "INFO:absl:collect_time = 0.10271573066711426, train_time = 0.13312482833862305\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-11500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-11500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000011500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000011500/assets\n",
      "INFO:absl:step = 11550, loss = 1.328672\n",
      "INFO:absl:247.316 steps/sec\n",
      "INFO:absl:collect_time = 0.10334014892578125, train_time = 0.0988306999206543\n",
      "INFO:absl:step = 11600, loss = 2.014152\n",
      "INFO:absl:316.749 steps/sec\n",
      "INFO:absl:collect_time = 0.06581425666809082, train_time = 0.09203934669494629\n",
      "INFO:absl:step = 11650, loss = 0.295014\n",
      "INFO:absl:276.185 steps/sec\n",
      "INFO:absl:collect_time = 0.08395862579345703, train_time = 0.09707975387573242\n",
      "INFO:absl:step = 11700, loss = 0.039500\n",
      "INFO:absl:245.239 steps/sec\n",
      "INFO:absl:collect_time = 0.10793399810791016, train_time = 0.09594893455505371\n",
      "INFO:absl:step = 11750, loss = 0.747795\n",
      "INFO:absl:256.776 steps/sec\n",
      "INFO:absl:collect_time = 0.08163666725158691, train_time = 0.11308574676513672\n",
      "INFO:absl:step = 11800, loss = 0.340987\n",
      "INFO:absl:195.799 steps/sec\n",
      "INFO:absl:collect_time = 0.09890222549438477, train_time = 0.1564619541168213\n",
      "INFO:absl:step = 11850, loss = 0.782293\n",
      "INFO:absl:173.943 steps/sec\n",
      "INFO:absl:collect_time = 0.11888718605041504, train_time = 0.1685631275177002\n",
      "INFO:absl:step = 11900, loss = 0.481582\n",
      "INFO:absl:305.253 steps/sec\n",
      "INFO:absl:collect_time = 0.0677638053894043, train_time = 0.09603500366210938\n",
      "INFO:absl:step = 11950, loss = 4.143607\n",
      "INFO:absl:229.605 steps/sec\n",
      "INFO:absl:collect_time = 0.0897679328918457, train_time = 0.12799692153930664\n",
      "INFO:absl:step = 12000, loss = 0.848431\n",
      "INFO:absl:189.252 steps/sec\n",
      "INFO:absl:collect_time = 0.11423850059509277, train_time = 0.14995908737182617\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-12000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000012000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000012000/assets\n",
      "INFO:absl:step = 12050, loss = 0.711768\n",
      "INFO:absl:270.078 steps/sec\n",
      "INFO:absl:collect_time = 0.08239984512329102, train_time = 0.10273218154907227\n",
      "INFO:absl:step = 12100, loss = 0.748969\n",
      "INFO:absl:297.148 steps/sec\n",
      "INFO:absl:collect_time = 0.07575321197509766, train_time = 0.09251284599304199\n",
      "INFO:absl:step = 12150, loss = 1.462781\n",
      "INFO:absl:278.672 steps/sec\n",
      "INFO:absl:collect_time = 0.08157515525817871, train_time = 0.09784698486328125\n",
      "INFO:absl:step = 12200, loss = 0.173812\n",
      "INFO:absl:311.970 steps/sec\n",
      "INFO:absl:collect_time = 0.07246685028076172, train_time = 0.08780503273010254\n",
      "INFO:absl:step = 12250, loss = 0.740221\n",
      "INFO:absl:211.538 steps/sec\n",
      "INFO:absl:collect_time = 0.09465861320495605, train_time = 0.14170598983764648\n",
      "INFO:absl:step = 12300, loss = 2.489814\n",
      "INFO:absl:261.378 steps/sec\n",
      "INFO:absl:collect_time = 0.08911275863647461, train_time = 0.10218095779418945\n",
      "INFO:absl:step = 12350, loss = 0.372985\n",
      "INFO:absl:306.231 steps/sec\n",
      "INFO:absl:collect_time = 0.0720059871673584, train_time = 0.09126925468444824\n",
      "INFO:absl:step = 12400, loss = 0.471211\n",
      "INFO:absl:289.171 steps/sec\n",
      "INFO:absl:collect_time = 0.0720510482788086, train_time = 0.10085725784301758\n",
      "INFO:absl:step = 12450, loss = 2.083077\n",
      "INFO:absl:255.442 steps/sec\n",
      "INFO:absl:collect_time = 0.08230781555175781, train_time = 0.11343121528625488\n",
      "INFO:absl:step = 12500, loss = 0.352321\n",
      "INFO:absl:294.770 steps/sec\n",
      "INFO:absl:collect_time = 0.07579183578491211, train_time = 0.09383201599121094\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-12500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-12500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000012500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000012500/assets\n",
      "INFO:absl:step = 12550, loss = 0.492930\n",
      "INFO:absl:264.439 steps/sec\n",
      "INFO:absl:collect_time = 0.08505558967590332, train_time = 0.10402417182922363\n",
      "INFO:absl:step = 12600, loss = 0.692839\n",
      "INFO:absl:229.526 steps/sec\n",
      "INFO:absl:collect_time = 0.09990382194519043, train_time = 0.11793684959411621\n",
      "INFO:absl:step = 12650, loss = 0.761500\n",
      "INFO:absl:197.421 steps/sec\n",
      "INFO:absl:collect_time = 0.1198725700378418, train_time = 0.1333932876586914\n",
      "INFO:absl:step = 12700, loss = 1.089145\n",
      "INFO:absl:220.943 steps/sec\n",
      "INFO:absl:collect_time = 0.10120892524719238, train_time = 0.12509417533874512\n",
      "INFO:absl:step = 12750, loss = 0.440038\n",
      "INFO:absl:201.992 steps/sec\n",
      "INFO:absl:collect_time = 0.11603999137878418, train_time = 0.13149499893188477\n",
      "INFO:absl:step = 12800, loss = 0.243470\n",
      "INFO:absl:349.986 steps/sec\n",
      "INFO:absl:collect_time = 0.054795026779174805, train_time = 0.08806800842285156\n",
      "INFO:absl:step = 12850, loss = 0.272145\n",
      "INFO:absl:265.157 steps/sec\n",
      "INFO:absl:collect_time = 0.08801460266113281, train_time = 0.10055303573608398\n",
      "INFO:absl:step = 12900, loss = 0.541433\n",
      "INFO:absl:276.209 steps/sec\n",
      "INFO:absl:collect_time = 0.08205413818359375, train_time = 0.0989680290222168\n",
      "INFO:absl:step = 12950, loss = 2.554929\n",
      "INFO:absl:279.647 steps/sec\n",
      "INFO:absl:collect_time = 0.07718801498413086, train_time = 0.1016085147857666\n",
      "INFO:absl:step = 13000, loss = 0.151994\n",
      "INFO:absl:256.829 steps/sec\n",
      "INFO:absl:collect_time = 0.08026504516601562, train_time = 0.11441707611083984\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-13000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-13000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000013000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000013000/assets\n",
      "INFO:absl:step = 13050, loss = 0.586321\n",
      "INFO:absl:217.536 steps/sec\n",
      "INFO:absl:collect_time = 0.1100921630859375, train_time = 0.11975479125976562\n",
      "INFO:absl:step = 13100, loss = 2.351941\n",
      "INFO:absl:271.252 steps/sec\n",
      "INFO:absl:collect_time = 0.07713723182678223, train_time = 0.1071929931640625\n",
      "INFO:absl:step = 13150, loss = 3.640187\n",
      "INFO:absl:232.239 steps/sec\n",
      "INFO:absl:collect_time = 0.09544706344604492, train_time = 0.11984872817993164\n",
      "INFO:absl:step = 13200, loss = 0.602617\n",
      "INFO:absl:258.062 steps/sec\n",
      "INFO:absl:collect_time = 0.08468818664550781, train_time = 0.10906386375427246\n",
      "INFO:absl:step = 13250, loss = 0.555162\n",
      "INFO:absl:229.168 steps/sec\n",
      "INFO:absl:collect_time = 0.09299683570861816, train_time = 0.1251838207244873\n",
      "INFO:absl:step = 13300, loss = 2.115784\n",
      "INFO:absl:223.555 steps/sec\n",
      "INFO:absl:collect_time = 0.10345578193664551, train_time = 0.12020277976989746\n",
      "INFO:absl:step = 13350, loss = 0.509436\n",
      "INFO:absl:232.401 steps/sec\n",
      "INFO:absl:collect_time = 0.08905816078186035, train_time = 0.12608695030212402\n",
      "INFO:absl:step = 13400, loss = 0.847659\n",
      "INFO:absl:221.928 steps/sec\n",
      "INFO:absl:collect_time = 0.09854412078857422, train_time = 0.1267542839050293\n",
      "INFO:absl:step = 13450, loss = 0.859019\n",
      "INFO:absl:276.497 steps/sec\n",
      "INFO:absl:collect_time = 0.07256674766540527, train_time = 0.10826706886291504\n",
      "INFO:absl:step = 13500, loss = 0.350017\n",
      "INFO:absl:244.147 steps/sec\n",
      "INFO:absl:collect_time = 0.08511900901794434, train_time = 0.11967587471008301\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-13500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-13500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000013500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000013500/assets\n",
      "INFO:absl:step = 13550, loss = 0.533616\n",
      "INFO:absl:247.143 steps/sec\n",
      "INFO:absl:collect_time = 0.09393191337585449, train_time = 0.10837984085083008\n",
      "INFO:absl:step = 13600, loss = 1.653349\n",
      "INFO:absl:238.450 steps/sec\n",
      "INFO:absl:collect_time = 0.08508682250976562, train_time = 0.12460064888000488\n",
      "INFO:absl:step = 13650, loss = 1.433314\n",
      "INFO:absl:241.080 steps/sec\n",
      "INFO:absl:collect_time = 0.08287692070007324, train_time = 0.12452316284179688\n",
      "INFO:absl:step = 13700, loss = 0.609254\n",
      "INFO:absl:209.991 steps/sec\n",
      "INFO:absl:collect_time = 0.10683059692382812, train_time = 0.13127517700195312\n",
      "INFO:absl:step = 13750, loss = 0.408103\n",
      "INFO:absl:237.925 steps/sec\n",
      "INFO:absl:collect_time = 0.08275699615478516, train_time = 0.12739300727844238\n",
      "INFO:absl:step = 13800, loss = 2.558806\n",
      "INFO:absl:277.162 steps/sec\n",
      "INFO:absl:collect_time = 0.07716226577758789, train_time = 0.10323786735534668\n",
      "INFO:absl:step = 13850, loss = 0.644271\n",
      "INFO:absl:251.570 steps/sec\n",
      "INFO:absl:collect_time = 0.08745384216308594, train_time = 0.1112978458404541\n",
      "INFO:absl:step = 13900, loss = 0.681899\n",
      "INFO:absl:308.342 steps/sec\n",
      "INFO:absl:collect_time = 0.06420588493347168, train_time = 0.09795188903808594\n",
      "INFO:absl:step = 13950, loss = 0.532569\n",
      "INFO:absl:273.081 steps/sec\n",
      "INFO:absl:collect_time = 0.0742030143737793, train_time = 0.10889291763305664\n",
      "INFO:absl:step = 14000, loss = 1.119493\n",
      "INFO:absl:244.084 steps/sec\n",
      "INFO:absl:collect_time = 0.08962678909301758, train_time = 0.11522078514099121\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-14000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-14000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000014000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000014000/assets\n",
      "INFO:absl:step = 14050, loss = 0.325211\n",
      "INFO:absl:290.238 steps/sec\n",
      "INFO:absl:collect_time = 0.07297492027282715, train_time = 0.09929776191711426\n",
      "INFO:absl:step = 14100, loss = 0.375552\n",
      "INFO:absl:294.492 steps/sec\n",
      "INFO:absl:collect_time = 0.07273697853088379, train_time = 0.09704709053039551\n",
      "INFO:absl:step = 14150, loss = 0.729911\n",
      "INFO:absl:285.162 steps/sec\n",
      "INFO:absl:collect_time = 0.07390642166137695, train_time = 0.10143280029296875\n",
      "INFO:absl:step = 14200, loss = 0.426856\n",
      "INFO:absl:328.286 steps/sec\n",
      "INFO:absl:collect_time = 0.06015896797180176, train_time = 0.0921471118927002\n",
      "INFO:absl:step = 14250, loss = 1.179721\n",
      "INFO:absl:292.296 steps/sec\n",
      "INFO:absl:collect_time = 0.07336091995239258, train_time = 0.09769868850708008\n",
      "INFO:absl:step = 14300, loss = 1.339566\n",
      "INFO:absl:287.103 steps/sec\n",
      "INFO:absl:collect_time = 0.07261013984680176, train_time = 0.10154318809509277\n",
      "INFO:absl:step = 14350, loss = 0.709519\n",
      "INFO:absl:265.326 steps/sec\n",
      "INFO:absl:collect_time = 0.08228397369384766, train_time = 0.10616326332092285\n",
      "INFO:absl:step = 14400, loss = 0.544525\n",
      "INFO:absl:273.512 steps/sec\n",
      "INFO:absl:collect_time = 0.07241415977478027, train_time = 0.11039304733276367\n",
      "INFO:absl:step = 14450, loss = 2.104147\n",
      "INFO:absl:210.695 steps/sec\n",
      "INFO:absl:collect_time = 0.09961700439453125, train_time = 0.1376934051513672\n",
      "INFO:absl:step = 14500, loss = 1.216479\n",
      "INFO:absl:221.489 steps/sec\n",
      "INFO:absl:collect_time = 0.09793996810913086, train_time = 0.12780499458312988\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-14500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-14500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000014500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000014500/assets\n",
      "INFO:absl:step = 14550, loss = 0.590504\n",
      "INFO:absl:290.168 steps/sec\n",
      "INFO:absl:collect_time = 0.07311606407165527, train_time = 0.0991981029510498\n",
      "INFO:absl:step = 14600, loss = 0.981694\n",
      "INFO:absl:230.332 steps/sec\n",
      "INFO:absl:collect_time = 0.09207701683044434, train_time = 0.1250009536743164\n",
      "INFO:absl:step = 14650, loss = 0.431778\n",
      "INFO:absl:253.242 steps/sec\n",
      "INFO:absl:collect_time = 0.09139871597290039, train_time = 0.10604095458984375\n",
      "INFO:absl:step = 14700, loss = 0.731260\n",
      "INFO:absl:183.595 steps/sec\n",
      "INFO:absl:collect_time = 0.12279391288757324, train_time = 0.14954400062561035\n",
      "INFO:absl:step = 14750, loss = 1.887379\n",
      "INFO:absl:242.114 steps/sec\n",
      "INFO:absl:collect_time = 0.09748506546020508, train_time = 0.10902905464172363\n",
      "INFO:absl:step = 14800, loss = 1.014925\n",
      "INFO:absl:276.533 steps/sec\n",
      "INFO:absl:collect_time = 0.07685732841491699, train_time = 0.10395288467407227\n",
      "INFO:absl:step = 14850, loss = 2.030630\n",
      "INFO:absl:221.305 steps/sec\n",
      "INFO:absl:collect_time = 0.09475922584533691, train_time = 0.13117289543151855\n",
      "INFO:absl:step = 14900, loss = 0.457727\n",
      "INFO:absl:258.942 steps/sec\n",
      "INFO:absl:collect_time = 0.08420038223266602, train_time = 0.10889291763305664\n",
      "INFO:absl:step = 14950, loss = 0.618299\n",
      "INFO:absl:285.733 steps/sec\n",
      "INFO:absl:collect_time = 0.07725882530212402, train_time = 0.09772992134094238\n",
      "INFO:absl:step = 15000, loss = 1.255657\n",
      "INFO:absl:266.549 steps/sec\n",
      "INFO:absl:collect_time = 0.08386707305908203, train_time = 0.10371565818786621\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-15000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000015000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000015000/assets\n",
      "INFO:absl:step = 15050, loss = 0.626225\n",
      "INFO:absl:249.802 steps/sec\n",
      "INFO:absl:collect_time = 0.0877084732055664, train_time = 0.11245036125183105\n",
      "INFO:absl:step = 15100, loss = 0.571794\n",
      "INFO:absl:280.293 steps/sec\n",
      "INFO:absl:collect_time = 0.07042980194091797, train_time = 0.1079549789428711\n",
      "INFO:absl:step = 15150, loss = 2.408306\n",
      "INFO:absl:254.626 steps/sec\n",
      "INFO:absl:collect_time = 0.08498692512512207, train_time = 0.11137914657592773\n",
      "INFO:absl:step = 15200, loss = 0.465194\n",
      "INFO:absl:281.108 steps/sec\n",
      "INFO:absl:collect_time = 0.0761568546295166, train_time = 0.10171103477478027\n",
      "INFO:absl:step = 15250, loss = 0.218246\n",
      "INFO:absl:290.212 steps/sec\n",
      "INFO:absl:collect_time = 0.07130908966064453, train_time = 0.10097885131835938\n",
      "INFO:absl:step = 15300, loss = 0.401065\n",
      "INFO:absl:246.988 steps/sec\n",
      "INFO:absl:collect_time = 0.08827733993530273, train_time = 0.11416172981262207\n",
      "INFO:absl:step = 15350, loss = 0.591288\n",
      "INFO:absl:237.619 steps/sec\n",
      "INFO:absl:collect_time = 0.09936213493347168, train_time = 0.11105895042419434\n",
      "INFO:absl:step = 15400, loss = 0.197176\n",
      "INFO:absl:256.380 steps/sec\n",
      "INFO:absl:collect_time = 0.08684754371643066, train_time = 0.10817575454711914\n",
      "INFO:absl:step = 15450, loss = 0.670447\n",
      "INFO:absl:257.795 steps/sec\n",
      "INFO:absl:collect_time = 0.09169483184814453, train_time = 0.10225796699523926\n",
      "INFO:absl:step = 15500, loss = 0.661902\n",
      "INFO:absl:236.292 steps/sec\n",
      "INFO:absl:collect_time = 0.0940701961517334, train_time = 0.11753273010253906\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-15500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-15500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000015500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000015500/assets\n",
      "INFO:absl:step = 15550, loss = 0.774512\n",
      "INFO:absl:273.624 steps/sec\n",
      "INFO:absl:collect_time = 0.07900571823120117, train_time = 0.10372662544250488\n",
      "INFO:absl:step = 15600, loss = 1.421342\n",
      "INFO:absl:268.792 steps/sec\n",
      "INFO:absl:collect_time = 0.08097481727600098, train_time = 0.10504293441772461\n",
      "INFO:absl:step = 15650, loss = 2.079892\n",
      "INFO:absl:277.698 steps/sec\n",
      "INFO:absl:collect_time = 0.08473777770996094, train_time = 0.09531402587890625\n",
      "INFO:absl:step = 15700, loss = 0.661402\n",
      "INFO:absl:259.944 steps/sec\n",
      "INFO:absl:collect_time = 0.07261919975280762, train_time = 0.11972999572753906\n",
      "INFO:absl:step = 15750, loss = 0.873353\n",
      "INFO:absl:266.913 steps/sec\n",
      "INFO:absl:collect_time = 0.08523011207580566, train_time = 0.1020967960357666\n",
      "INFO:absl:step = 15800, loss = 0.669580\n",
      "INFO:absl:299.503 steps/sec\n",
      "INFO:absl:collect_time = 0.07195210456848145, train_time = 0.09499096870422363\n",
      "INFO:absl:step = 15850, loss = 3.271013\n",
      "INFO:absl:261.356 steps/sec\n",
      "INFO:absl:collect_time = 0.0819549560546875, train_time = 0.10935473442077637\n",
      "INFO:absl:step = 15900, loss = 1.029331\n",
      "INFO:absl:265.063 steps/sec\n",
      "INFO:absl:collect_time = 0.08492016792297363, train_time = 0.1037139892578125\n",
      "INFO:absl:step = 15950, loss = 0.414160\n",
      "INFO:absl:281.261 steps/sec\n",
      "INFO:absl:collect_time = 0.07480621337890625, train_time = 0.10296487808227539\n",
      "INFO:absl:step = 16000, loss = 1.178102\n",
      "INFO:absl:267.275 steps/sec\n",
      "INFO:absl:collect_time = 0.08472514152526855, train_time = 0.10234808921813965\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-16000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-16000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000016000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000016000/assets\n",
      "INFO:absl:step = 16050, loss = 1.064889\n",
      "INFO:absl:241.970 steps/sec\n",
      "INFO:absl:collect_time = 0.09121918678283691, train_time = 0.1154177188873291\n",
      "INFO:absl:step = 16100, loss = 0.442866\n",
      "INFO:absl:279.975 steps/sec\n",
      "INFO:absl:collect_time = 0.07173633575439453, train_time = 0.10685133934020996\n",
      "INFO:absl:step = 16150, loss = 1.181929\n",
      "INFO:absl:271.998 steps/sec\n",
      "INFO:absl:collect_time = 0.08653545379638672, train_time = 0.0972893238067627\n",
      "INFO:absl:step = 16200, loss = 0.114283\n",
      "INFO:absl:280.247 steps/sec\n",
      "INFO:absl:collect_time = 0.07498335838317871, train_time = 0.10343074798583984\n",
      "INFO:absl:step = 16250, loss = 2.011961\n",
      "INFO:absl:246.881 steps/sec\n",
      "INFO:absl:collect_time = 0.09777331352233887, train_time = 0.10475301742553711\n",
      "INFO:absl:step = 16300, loss = 1.241492\n",
      "INFO:absl:273.808 steps/sec\n",
      "INFO:absl:collect_time = 0.07871222496032715, train_time = 0.1038978099822998\n",
      "INFO:absl:step = 16350, loss = 1.437530\n",
      "INFO:absl:218.659 steps/sec\n",
      "INFO:absl:collect_time = 0.1259140968322754, train_time = 0.1027522087097168\n",
      "INFO:absl:step = 16400, loss = 0.382564\n",
      "INFO:absl:237.408 steps/sec\n",
      "INFO:absl:collect_time = 0.09419798851013184, train_time = 0.1164100170135498\n",
      "INFO:absl:step = 16450, loss = 0.634739\n",
      "INFO:absl:288.587 steps/sec\n",
      "INFO:absl:collect_time = 0.06978893280029297, train_time = 0.1034688949584961\n",
      "INFO:absl:step = 16500, loss = 0.271974\n",
      "INFO:absl:255.348 steps/sec\n",
      "INFO:absl:collect_time = 0.08055830001831055, train_time = 0.11525273323059082\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-16500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-16500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000016500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000016500/assets\n",
      "INFO:absl:step = 16550, loss = 0.346138\n",
      "INFO:absl:285.086 steps/sec\n",
      "INFO:absl:collect_time = 0.07293701171875, train_time = 0.10244870185852051\n",
      "INFO:absl:step = 16600, loss = 0.773807\n",
      "INFO:absl:284.576 steps/sec\n",
      "INFO:absl:collect_time = 0.07518982887268066, train_time = 0.1005103588104248\n",
      "INFO:absl:step = 16650, loss = 1.585618\n",
      "INFO:absl:308.878 steps/sec\n",
      "INFO:absl:collect_time = 0.07108592987060547, train_time = 0.0907900333404541\n",
      "INFO:absl:step = 16700, loss = 0.437658\n",
      "INFO:absl:291.819 steps/sec\n",
      "INFO:absl:collect_time = 0.07916712760925293, train_time = 0.09217214584350586\n",
      "INFO:absl:step = 16750, loss = 0.611632\n",
      "INFO:absl:307.754 steps/sec\n",
      "INFO:absl:collect_time = 0.07336115837097168, train_time = 0.08910608291625977\n",
      "INFO:absl:step = 16800, loss = 0.959614\n",
      "INFO:absl:321.847 steps/sec\n",
      "INFO:absl:collect_time = 0.07027006149291992, train_time = 0.0850832462310791\n",
      "INFO:absl:step = 16850, loss = 0.636361\n",
      "INFO:absl:273.347 steps/sec\n",
      "INFO:absl:collect_time = 0.08101820945739746, train_time = 0.1018991470336914\n",
      "INFO:absl:step = 16900, loss = 1.511796\n",
      "INFO:absl:261.336 steps/sec\n",
      "INFO:absl:collect_time = 0.0829620361328125, train_time = 0.10836219787597656\n",
      "INFO:absl:step = 16950, loss = 5.378871\n",
      "INFO:absl:254.616 steps/sec\n",
      "INFO:absl:collect_time = 0.0857539176940918, train_time = 0.11062002182006836\n",
      "INFO:absl:step = 17000, loss = 1.729682\n",
      "INFO:absl:249.408 steps/sec\n",
      "INFO:absl:collect_time = 0.10049223899841309, train_time = 0.09998226165771484\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-17000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-17000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000017000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000017000/assets\n",
      "INFO:absl:step = 17050, loss = 0.554681\n",
      "INFO:absl:278.444 steps/sec\n",
      "INFO:absl:collect_time = 0.07921290397644043, train_time = 0.1003561019897461\n",
      "INFO:absl:step = 17100, loss = 0.775526\n",
      "INFO:absl:302.040 steps/sec\n",
      "INFO:absl:collect_time = 0.07654738426208496, train_time = 0.08899378776550293\n",
      "INFO:absl:step = 17150, loss = 0.930405\n",
      "INFO:absl:293.638 steps/sec\n",
      "INFO:absl:collect_time = 0.07629084587097168, train_time = 0.09398698806762695\n",
      "INFO:absl:step = 17200, loss = 1.560384\n",
      "INFO:absl:268.157 steps/sec\n",
      "INFO:absl:collect_time = 0.08968210220336914, train_time = 0.09677577018737793\n",
      "INFO:absl:step = 17250, loss = 0.448295\n",
      "INFO:absl:318.984 steps/sec\n",
      "INFO:absl:collect_time = 0.06867480278015137, train_time = 0.0880727767944336\n",
      "INFO:absl:step = 17300, loss = 2.647143\n",
      "INFO:absl:272.853 steps/sec\n",
      "INFO:absl:collect_time = 0.08514761924743652, train_time = 0.09810090065002441\n",
      "INFO:absl:step = 17350, loss = 1.092307\n",
      "INFO:absl:285.866 steps/sec\n",
      "INFO:absl:collect_time = 0.07562613487243652, train_time = 0.09928107261657715\n",
      "INFO:absl:step = 17400, loss = 0.477948\n",
      "INFO:absl:273.600 steps/sec\n",
      "INFO:absl:collect_time = 0.07675576210021973, train_time = 0.10599279403686523\n",
      "INFO:absl:step = 17450, loss = 0.381171\n",
      "INFO:absl:270.474 steps/sec\n",
      "INFO:absl:collect_time = 0.08206701278686523, train_time = 0.10279393196105957\n",
      "INFO:absl:step = 17500, loss = 1.034437\n",
      "INFO:absl:309.014 steps/sec\n",
      "INFO:absl:collect_time = 0.07241582870483398, train_time = 0.08938908576965332\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-17500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-17500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000017500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000017500/assets\n",
      "INFO:absl:step = 17550, loss = 1.049228\n",
      "INFO:absl:284.740 steps/sec\n",
      "INFO:absl:collect_time = 0.07564783096313477, train_time = 0.09995102882385254\n",
      "INFO:absl:step = 17600, loss = 3.411746\n",
      "INFO:absl:263.107 steps/sec\n",
      "INFO:absl:collect_time = 0.08758378028869629, train_time = 0.10245299339294434\n",
      "INFO:absl:step = 17650, loss = 0.468525\n",
      "INFO:absl:297.109 steps/sec\n",
      "INFO:absl:collect_time = 0.06685638427734375, train_time = 0.10143184661865234\n",
      "INFO:absl:step = 17700, loss = 0.705234\n",
      "INFO:absl:235.911 steps/sec\n",
      "INFO:absl:collect_time = 0.10207700729370117, train_time = 0.10986757278442383\n",
      "INFO:absl:step = 17750, loss = 0.300021\n",
      "INFO:absl:262.510 steps/sec\n",
      "INFO:absl:collect_time = 0.08543109893798828, train_time = 0.10503816604614258\n",
      "INFO:absl:step = 17800, loss = 0.319752\n",
      "INFO:absl:280.233 steps/sec\n",
      "INFO:absl:collect_time = 0.08050823211669922, train_time = 0.0979149341583252\n",
      "INFO:absl:step = 17850, loss = 0.630666\n",
      "INFO:absl:248.200 steps/sec\n",
      "INFO:absl:collect_time = 0.08273911476135254, train_time = 0.11871123313903809\n",
      "INFO:absl:step = 17900, loss = 0.387768\n",
      "INFO:absl:243.431 steps/sec\n",
      "INFO:absl:collect_time = 0.0942678451538086, train_time = 0.1111292839050293\n",
      "INFO:absl:step = 17950, loss = 1.011986\n",
      "INFO:absl:214.544 steps/sec\n",
      "INFO:absl:collect_time = 0.10442781448364258, train_time = 0.12862420082092285\n",
      "INFO:absl:step = 18000, loss = 3.111973\n",
      "INFO:absl:250.046 steps/sec\n",
      "INFO:absl:collect_time = 0.09256982803344727, train_time = 0.10739326477050781\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-18000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-18000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000018000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000018000/assets\n",
      "INFO:absl:step = 18050, loss = 2.342985\n",
      "INFO:absl:263.664 steps/sec\n",
      "INFO:absl:collect_time = 0.0839688777923584, train_time = 0.1056666374206543\n",
      "INFO:absl:step = 18100, loss = 0.890483\n",
      "INFO:absl:287.107 steps/sec\n",
      "INFO:absl:collect_time = 0.07341575622558594, train_time = 0.10073518753051758\n",
      "INFO:absl:step = 18150, loss = 0.948546\n",
      "INFO:absl:271.837 steps/sec\n",
      "INFO:absl:collect_time = 0.08021211624145508, train_time = 0.10372185707092285\n",
      "INFO:absl:step = 18200, loss = 1.839524\n",
      "INFO:absl:254.775 steps/sec\n",
      "INFO:absl:collect_time = 0.08007097244262695, train_time = 0.1161808967590332\n",
      "INFO:absl:step = 18250, loss = 1.009753\n",
      "INFO:absl:273.753 steps/sec\n",
      "INFO:absl:collect_time = 0.06986832618713379, train_time = 0.1127779483795166\n",
      "INFO:absl:step = 18300, loss = 1.131612\n",
      "INFO:absl:273.673 steps/sec\n",
      "INFO:absl:collect_time = 0.08103489875793457, train_time = 0.10166501998901367\n",
      "INFO:absl:step = 18350, loss = 0.546965\n",
      "INFO:absl:256.983 steps/sec\n",
      "INFO:absl:collect_time = 0.07381677627563477, train_time = 0.12074875831604004\n",
      "INFO:absl:step = 18400, loss = 0.405513\n",
      "INFO:absl:181.255 steps/sec\n",
      "INFO:absl:collect_time = 0.10333681106567383, train_time = 0.1725170612335205\n",
      "INFO:absl:step = 18450, loss = 0.636937\n",
      "INFO:absl:251.192 steps/sec\n",
      "INFO:absl:collect_time = 0.09498095512390137, train_time = 0.10407018661499023\n",
      "INFO:absl:step = 18500, loss = 0.346190\n",
      "INFO:absl:259.228 steps/sec\n",
      "INFO:absl:collect_time = 0.09156179428100586, train_time = 0.101318359375\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-18500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-18500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000018500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000018500/assets\n",
      "INFO:absl:step = 18550, loss = 2.145594\n",
      "INFO:absl:296.190 steps/sec\n",
      "INFO:absl:collect_time = 0.07253146171569824, train_time = 0.09627914428710938\n",
      "INFO:absl:step = 18600, loss = 2.677756\n",
      "INFO:absl:277.271 steps/sec\n",
      "INFO:absl:collect_time = 0.08463621139526367, train_time = 0.09569287300109863\n",
      "INFO:absl:step = 18650, loss = 0.287529\n",
      "INFO:absl:287.863 steps/sec\n",
      "INFO:absl:collect_time = 0.07635807991027832, train_time = 0.0973358154296875\n",
      "INFO:absl:step = 18700, loss = 0.199711\n",
      "INFO:absl:332.110 steps/sec\n",
      "INFO:absl:collect_time = 0.06759309768676758, train_time = 0.08295941352844238\n",
      "INFO:absl:step = 18750, loss = 1.054546\n",
      "INFO:absl:264.175 steps/sec\n",
      "INFO:absl:collect_time = 0.09795689582824707, train_time = 0.09131169319152832\n",
      "INFO:absl:step = 18800, loss = 1.642310\n",
      "INFO:absl:276.110 steps/sec\n",
      "INFO:absl:collect_time = 0.0846858024597168, train_time = 0.09640169143676758\n",
      "INFO:absl:step = 18850, loss = 6.984704\n",
      "INFO:absl:288.184 steps/sec\n",
      "INFO:absl:collect_time = 0.07524394989013672, train_time = 0.09825611114501953\n",
      "INFO:absl:step = 18900, loss = 0.300379\n",
      "INFO:absl:269.229 steps/sec\n",
      "INFO:absl:collect_time = 0.08792519569396973, train_time = 0.09779000282287598\n",
      "INFO:absl:step = 18950, loss = 0.831949\n",
      "INFO:absl:273.162 steps/sec\n",
      "INFO:absl:collect_time = 0.08056378364562988, train_time = 0.1024777889251709\n",
      "INFO:absl:step = 19000, loss = 0.683149\n",
      "INFO:absl:299.500 steps/sec\n",
      "INFO:absl:collect_time = 0.06789398193359375, train_time = 0.09905076026916504\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-19000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-19000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000019000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000019000/assets\n",
      "INFO:absl:step = 19050, loss = 0.258332\n",
      "INFO:absl:261.149 steps/sec\n",
      "INFO:absl:collect_time = 0.0817112922668457, train_time = 0.10975027084350586\n",
      "INFO:absl:step = 19100, loss = 0.319581\n",
      "INFO:absl:268.956 steps/sec\n",
      "INFO:absl:collect_time = 0.0803060531616211, train_time = 0.10559797286987305\n",
      "INFO:absl:step = 19150, loss = 0.886249\n",
      "INFO:absl:274.698 steps/sec\n",
      "INFO:absl:collect_time = 0.0838019847869873, train_time = 0.09821605682373047\n",
      "INFO:absl:step = 19200, loss = 8.176774\n",
      "INFO:absl:240.671 steps/sec\n",
      "INFO:absl:collect_time = 0.0935831069946289, train_time = 0.11416912078857422\n",
      "INFO:absl:step = 19250, loss = 1.571269\n",
      "INFO:absl:248.843 steps/sec\n",
      "INFO:absl:collect_time = 0.09409570693969727, train_time = 0.10683393478393555\n",
      "INFO:absl:step = 19300, loss = 0.171076\n",
      "INFO:absl:327.353 steps/sec\n",
      "INFO:absl:collect_time = 0.07039499282836914, train_time = 0.08234524726867676\n",
      "INFO:absl:step = 19350, loss = 2.240750\n",
      "INFO:absl:256.996 steps/sec\n",
      "INFO:absl:collect_time = 0.08768200874328613, train_time = 0.1068732738494873\n",
      "INFO:absl:step = 19400, loss = 0.903909\n",
      "INFO:absl:283.371 steps/sec\n",
      "INFO:absl:collect_time = 0.0799870491027832, train_time = 0.09646010398864746\n",
      "INFO:absl:step = 19450, loss = 0.925070\n",
      "INFO:absl:225.189 steps/sec\n",
      "INFO:absl:collect_time = 0.10872316360473633, train_time = 0.11331295967102051\n",
      "INFO:absl:step = 19500, loss = 0.552456\n",
      "INFO:absl:281.679 steps/sec\n",
      "INFO:absl:collect_time = 0.07689285278320312, train_time = 0.10061407089233398\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-19500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-19500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000019500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000019500/assets\n",
      "INFO:absl:step = 19550, loss = 0.555005\n",
      "INFO:absl:323.241 steps/sec\n",
      "INFO:absl:collect_time = 0.06580519676208496, train_time = 0.08887791633605957\n",
      "INFO:absl:step = 19600, loss = 2.917080\n",
      "INFO:absl:277.823 steps/sec\n",
      "INFO:absl:collect_time = 0.08420228958129883, train_time = 0.09576845169067383\n",
      "INFO:absl:step = 19650, loss = 0.333149\n",
      "INFO:absl:305.738 steps/sec\n",
      "INFO:absl:collect_time = 0.07011985778808594, train_time = 0.09341907501220703\n",
      "INFO:absl:step = 19700, loss = 0.231886\n",
      "INFO:absl:289.871 steps/sec\n",
      "INFO:absl:collect_time = 0.07820415496826172, train_time = 0.09428620338439941\n",
      "INFO:absl:step = 19750, loss = 0.761755\n",
      "INFO:absl:272.907 steps/sec\n",
      "INFO:absl:collect_time = 0.08734321594238281, train_time = 0.09586906433105469\n",
      "INFO:absl:step = 19800, loss = 0.859842\n",
      "INFO:absl:257.010 steps/sec\n",
      "INFO:absl:collect_time = 0.09461188316345215, train_time = 0.09993314743041992\n",
      "INFO:absl:step = 19850, loss = 5.678697\n",
      "INFO:absl:261.228 steps/sec\n",
      "INFO:absl:collect_time = 0.09185385704040527, train_time = 0.09955000877380371\n",
      "INFO:absl:step = 19900, loss = 1.070007\n",
      "INFO:absl:271.934 steps/sec\n",
      "INFO:absl:collect_time = 0.09080004692077637, train_time = 0.09306836128234863\n",
      "INFO:absl:step = 19950, loss = 0.426231\n",
      "INFO:absl:290.858 steps/sec\n",
      "INFO:absl:collect_time = 0.08145475387573242, train_time = 0.09045052528381348\n",
      "INFO:absl:step = 20000, loss = 0.675387\n",
      "INFO:absl:290.653 steps/sec\n",
      "INFO:absl:collect_time = 0.07538104057312012, train_time = 0.09664559364318848\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-20000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000020000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000020000/assets\n",
      "INFO:absl:step = 20050, loss = 0.783475\n",
      "INFO:absl:260.880 steps/sec\n",
      "INFO:absl:collect_time = 0.07433104515075684, train_time = 0.11732769012451172\n",
      "INFO:absl:step = 20100, loss = 0.582978\n",
      "INFO:absl:284.921 steps/sec\n",
      "INFO:absl:collect_time = 0.08052301406860352, train_time = 0.09496402740478516\n",
      "INFO:absl:step = 20150, loss = 0.748215\n",
      "INFO:absl:268.500 steps/sec\n",
      "INFO:absl:collect_time = 0.08720660209655762, train_time = 0.09901309013366699\n",
      "INFO:absl:step = 20200, loss = 0.511851\n",
      "INFO:absl:310.435 steps/sec\n",
      "INFO:absl:collect_time = 0.07375979423522949, train_time = 0.08730435371398926\n",
      "INFO:absl:step = 20250, loss = 0.336765\n",
      "INFO:absl:315.264 steps/sec\n",
      "INFO:absl:collect_time = 0.07317399978637695, train_time = 0.08542299270629883\n",
      "INFO:absl:step = 20300, loss = 1.909381\n",
      "INFO:absl:282.716 steps/sec\n",
      "INFO:absl:collect_time = 0.08259892463684082, train_time = 0.09425687789916992\n",
      "INFO:absl:step = 20350, loss = 0.625037\n",
      "INFO:absl:272.999 steps/sec\n",
      "INFO:absl:collect_time = 0.08237695693969727, train_time = 0.10077404975891113\n",
      "INFO:absl:step = 20400, loss = 0.719684\n",
      "INFO:absl:275.771 steps/sec\n",
      "INFO:absl:collect_time = 0.08229589462280273, train_time = 0.0990140438079834\n",
      "INFO:absl:step = 20450, loss = 1.078693\n",
      "INFO:absl:278.534 steps/sec\n",
      "INFO:absl:collect_time = 0.08217310905456543, train_time = 0.09733796119689941\n",
      "INFO:absl:step = 20500, loss = 0.536156\n",
      "INFO:absl:265.449 steps/sec\n",
      "INFO:absl:collect_time = 0.08434391021728516, train_time = 0.10401606559753418\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-20500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-20500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000020500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000020500/assets\n",
      "INFO:absl:step = 20550, loss = 1.109267\n",
      "INFO:absl:322.878 steps/sec\n",
      "INFO:absl:collect_time = 0.06535816192626953, train_time = 0.08949899673461914\n",
      "INFO:absl:step = 20600, loss = 0.529880\n",
      "INFO:absl:323.839 steps/sec\n",
      "INFO:absl:collect_time = 0.06579971313476562, train_time = 0.08859801292419434\n",
      "INFO:absl:step = 20650, loss = 1.769297\n",
      "INFO:absl:273.677 steps/sec\n",
      "INFO:absl:collect_time = 0.08045697212219238, train_time = 0.10224008560180664\n",
      "INFO:absl:step = 20700, loss = 1.651883\n",
      "INFO:absl:300.563 steps/sec\n",
      "INFO:absl:collect_time = 0.07368016242980957, train_time = 0.09267425537109375\n",
      "INFO:absl:step = 20750, loss = 1.025844\n",
      "INFO:absl:255.737 steps/sec\n",
      "INFO:absl:collect_time = 0.09016919136047363, train_time = 0.10534405708312988\n",
      "INFO:absl:step = 20800, loss = 1.521464\n",
      "INFO:absl:276.414 steps/sec\n",
      "INFO:absl:collect_time = 0.07941317558288574, train_time = 0.10147500038146973\n",
      "INFO:absl:step = 20850, loss = 13.059580\n",
      "INFO:absl:299.980 steps/sec\n",
      "INFO:absl:collect_time = 0.07548284530639648, train_time = 0.09119510650634766\n",
      "INFO:absl:step = 20900, loss = 1.035414\n",
      "INFO:absl:257.070 steps/sec\n",
      "INFO:absl:collect_time = 0.09255075454711914, train_time = 0.10194897651672363\n",
      "INFO:absl:step = 20950, loss = 0.800769\n",
      "INFO:absl:277.761 steps/sec\n",
      "INFO:absl:collect_time = 0.07982993125915527, train_time = 0.10018110275268555\n",
      "INFO:absl:step = 21000, loss = 1.884099\n",
      "INFO:absl:258.285 steps/sec\n",
      "INFO:absl:collect_time = 0.08979415893554688, train_time = 0.1037907600402832\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-21000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-21000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000021000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000021000/assets\n",
      "INFO:absl:step = 21050, loss = 2.445268\n",
      "INFO:absl:282.973 steps/sec\n",
      "INFO:absl:collect_time = 0.07939934730529785, train_time = 0.09729576110839844\n",
      "INFO:absl:step = 21100, loss = 0.847258\n",
      "INFO:absl:276.992 steps/sec\n",
      "INFO:absl:collect_time = 0.08600401878356934, train_time = 0.09450674057006836\n",
      "INFO:absl:step = 21150, loss = 0.487143\n",
      "INFO:absl:289.541 steps/sec\n",
      "INFO:absl:collect_time = 0.07222628593444824, train_time = 0.10046076774597168\n",
      "INFO:absl:step = 21200, loss = 2.390611\n",
      "INFO:absl:233.453 steps/sec\n",
      "INFO:absl:collect_time = 0.11032295227050781, train_time = 0.10385298728942871\n",
      "INFO:absl:step = 21250, loss = 0.656210\n",
      "INFO:absl:308.165 steps/sec\n",
      "INFO:absl:collect_time = 0.06946897506713867, train_time = 0.09278202056884766\n",
      "INFO:absl:step = 21300, loss = 1.622292\n",
      "INFO:absl:289.618 steps/sec\n",
      "INFO:absl:collect_time = 0.07548689842224121, train_time = 0.09715414047241211\n",
      "INFO:absl:step = 21350, loss = 0.667349\n",
      "INFO:absl:302.592 steps/sec\n",
      "INFO:absl:collect_time = 0.07230114936828613, train_time = 0.09293794631958008\n",
      "INFO:absl:step = 21400, loss = 3.099368\n",
      "INFO:absl:254.500 steps/sec\n",
      "INFO:absl:collect_time = 0.10157895088195801, train_time = 0.09488487243652344\n",
      "INFO:absl:step = 21450, loss = 1.893777\n",
      "INFO:absl:239.804 steps/sec\n",
      "INFO:absl:collect_time = 0.10151290893554688, train_time = 0.10699105262756348\n",
      "INFO:absl:step = 21500, loss = 1.531781\n",
      "INFO:absl:261.894 steps/sec\n",
      "INFO:absl:collect_time = 0.08384299278259277, train_time = 0.10707426071166992\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-21500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-21500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000021500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000021500/assets\n",
      "INFO:absl:step = 21550, loss = 0.956250\n",
      "INFO:absl:308.873 steps/sec\n",
      "INFO:absl:collect_time = 0.07081079483032227, train_time = 0.09106802940368652\n",
      "INFO:absl:step = 21600, loss = 3.301107\n",
      "INFO:absl:246.563 steps/sec\n",
      "INFO:absl:collect_time = 0.09644103050231934, train_time = 0.10634684562683105\n",
      "INFO:absl:step = 21650, loss = 1.391212\n",
      "INFO:absl:315.356 steps/sec\n",
      "INFO:absl:collect_time = 0.07228207588195801, train_time = 0.08626890182495117\n",
      "INFO:absl:step = 21700, loss = 4.618543\n",
      "INFO:absl:281.693 steps/sec\n",
      "INFO:absl:collect_time = 0.08724617958068848, train_time = 0.09025192260742188\n",
      "INFO:absl:step = 21750, loss = 4.759870\n",
      "INFO:absl:289.852 steps/sec\n",
      "INFO:absl:collect_time = 0.07515120506286621, train_time = 0.0973503589630127\n",
      "INFO:absl:step = 21800, loss = 1.073486\n",
      "INFO:absl:260.093 steps/sec\n",
      "INFO:absl:collect_time = 0.08922410011291504, train_time = 0.10301494598388672\n",
      "INFO:absl:step = 21850, loss = 0.649918\n",
      "INFO:absl:313.326 steps/sec\n",
      "INFO:absl:collect_time = 0.07036900520324707, train_time = 0.08920931816101074\n",
      "INFO:absl:step = 21900, loss = 0.731775\n",
      "INFO:absl:257.912 steps/sec\n",
      "INFO:absl:collect_time = 0.08474063873291016, train_time = 0.10912370681762695\n",
      "INFO:absl:step = 21950, loss = 0.459689\n",
      "INFO:absl:268.318 steps/sec\n",
      "INFO:absl:collect_time = 0.08348226547241211, train_time = 0.10286378860473633\n",
      "INFO:absl:step = 22000, loss = 0.822193\n",
      "INFO:absl:273.839 steps/sec\n",
      "INFO:absl:collect_time = 0.0793600082397461, train_time = 0.10322904586791992\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-22000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-22000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000022000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000022000/assets\n",
      "INFO:absl:step = 22050, loss = 2.890740\n",
      "INFO:absl:277.737 steps/sec\n",
      "INFO:absl:collect_time = 0.07994413375854492, train_time = 0.1000821590423584\n",
      "INFO:absl:step = 22100, loss = 0.592835\n",
      "INFO:absl:264.462 steps/sec\n",
      "INFO:absl:collect_time = 0.08749508857727051, train_time = 0.10156798362731934\n",
      "INFO:absl:step = 22150, loss = 1.314694\n",
      "INFO:absl:284.912 steps/sec\n",
      "INFO:absl:collect_time = 0.07896733283996582, train_time = 0.09652566909790039\n",
      "INFO:absl:step = 22200, loss = 0.728177\n",
      "INFO:absl:285.222 steps/sec\n",
      "INFO:absl:collect_time = 0.07714986801147461, train_time = 0.09815192222595215\n",
      "INFO:absl:step = 22250, loss = 1.908714\n",
      "INFO:absl:251.489 steps/sec\n",
      "INFO:absl:collect_time = 0.07688379287719727, train_time = 0.12193179130554199\n",
      "INFO:absl:step = 22300, loss = 0.516932\n",
      "INFO:absl:294.181 steps/sec\n",
      "INFO:absl:collect_time = 0.07644152641296387, train_time = 0.0935220718383789\n",
      "INFO:absl:step = 22350, loss = 0.978631\n",
      "INFO:absl:308.701 steps/sec\n",
      "INFO:absl:collect_time = 0.07363486289978027, train_time = 0.0883340835571289\n",
      "INFO:absl:step = 22400, loss = 1.067689\n",
      "INFO:absl:271.493 steps/sec\n",
      "INFO:absl:collect_time = 0.0942697525024414, train_time = 0.08989691734313965\n",
      "INFO:absl:step = 22450, loss = 0.730748\n",
      "INFO:absl:187.014 steps/sec\n",
      "INFO:absl:collect_time = 0.13201498985290527, train_time = 0.1353449821472168\n",
      "INFO:absl:step = 22500, loss = 1.861845\n",
      "INFO:absl:219.727 steps/sec\n",
      "INFO:absl:collect_time = 0.09813308715820312, train_time = 0.12942194938659668\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-22500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-22500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000022500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000022500/assets\n",
      "INFO:absl:step = 22550, loss = 0.327956\n",
      "INFO:absl:312.182 steps/sec\n",
      "INFO:absl:collect_time = 0.062274932861328125, train_time = 0.09788799285888672\n",
      "INFO:absl:step = 22600, loss = 2.295183\n",
      "INFO:absl:267.137 steps/sec\n",
      "INFO:absl:collect_time = 0.08711910247802734, train_time = 0.10005068778991699\n",
      "INFO:absl:step = 22650, loss = 0.476926\n",
      "INFO:absl:266.173 steps/sec\n",
      "INFO:absl:collect_time = 0.08427667617797852, train_time = 0.10357093811035156\n",
      "INFO:absl:step = 22700, loss = 0.451653\n",
      "INFO:absl:284.131 steps/sec\n",
      "INFO:absl:collect_time = 0.07968926429748535, train_time = 0.09628605842590332\n",
      "INFO:absl:step = 22750, loss = 0.381163\n",
      "INFO:absl:282.745 steps/sec\n",
      "INFO:absl:collect_time = 0.07924580574035645, train_time = 0.09759187698364258\n",
      "INFO:absl:step = 22800, loss = 0.345754\n",
      "INFO:absl:317.822 steps/sec\n",
      "INFO:absl:collect_time = 0.0711979866027832, train_time = 0.08612298965454102\n",
      "INFO:absl:step = 22850, loss = 0.889818\n",
      "INFO:absl:255.551 steps/sec\n",
      "INFO:absl:collect_time = 0.09596920013427734, train_time = 0.0996861457824707\n",
      "INFO:absl:step = 22900, loss = 0.664179\n",
      "INFO:absl:289.884 steps/sec\n",
      "INFO:absl:collect_time = 0.07505178451538086, train_time = 0.09743094444274902\n",
      "INFO:absl:step = 22950, loss = 6.208838\n",
      "INFO:absl:244.026 steps/sec\n",
      "INFO:absl:collect_time = 0.09712004661560059, train_time = 0.10777592658996582\n",
      "INFO:absl:step = 23000, loss = 1.804308\n",
      "INFO:absl:318.311 steps/sec\n",
      "INFO:absl:collect_time = 0.0714101791381836, train_time = 0.08566904067993164\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-23000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-23000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000023000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000023000/assets\n",
      "INFO:absl:step = 23050, loss = 3.873787\n",
      "INFO:absl:291.867 steps/sec\n",
      "INFO:absl:collect_time = 0.07251095771789551, train_time = 0.0988001823425293\n",
      "INFO:absl:step = 23100, loss = 0.472751\n",
      "INFO:absl:289.081 steps/sec\n",
      "INFO:absl:collect_time = 0.08509492874145508, train_time = 0.08786702156066895\n",
      "INFO:absl:step = 23150, loss = 1.555418\n",
      "INFO:absl:285.656 steps/sec\n",
      "INFO:absl:collect_time = 0.07810091972351074, train_time = 0.09693503379821777\n",
      "INFO:absl:step = 23200, loss = 1.413200\n",
      "INFO:absl:286.980 steps/sec\n",
      "INFO:absl:collect_time = 0.07930803298950195, train_time = 0.09492039680480957\n",
      "INFO:absl:step = 23250, loss = 1.300969\n",
      "INFO:absl:262.049 steps/sec\n",
      "INFO:absl:collect_time = 0.09003496170043945, train_time = 0.10076904296875\n",
      "INFO:absl:step = 23300, loss = 1.174142\n",
      "INFO:absl:268.369 steps/sec\n",
      "INFO:absl:collect_time = 0.08750605583190918, train_time = 0.09880447387695312\n",
      "INFO:absl:step = 23350, loss = 1.559878\n",
      "INFO:absl:224.700 steps/sec\n",
      "INFO:absl:collect_time = 0.10384321212768555, train_time = 0.11867594718933105\n",
      "INFO:absl:step = 23400, loss = 3.560904\n",
      "INFO:absl:217.134 steps/sec\n",
      "INFO:absl:collect_time = 0.1114957332611084, train_time = 0.11877655982971191\n",
      "INFO:absl:step = 23450, loss = 1.200228\n",
      "INFO:absl:276.389 steps/sec\n",
      "INFO:absl:collect_time = 0.08735322952270508, train_time = 0.0935509204864502\n",
      "INFO:absl:step = 23500, loss = 0.327168\n",
      "INFO:absl:277.465 steps/sec\n",
      "INFO:absl:collect_time = 0.09077692031860352, train_time = 0.08942604064941406\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-23500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-23500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000023500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000023500/assets\n",
      "INFO:absl:step = 23550, loss = 0.494340\n",
      "INFO:absl:267.113 steps/sec\n",
      "INFO:absl:collect_time = 0.08048295974731445, train_time = 0.1067037582397461\n",
      "INFO:absl:step = 23600, loss = 0.643438\n",
      "INFO:absl:270.151 steps/sec\n",
      "INFO:absl:collect_time = 0.08191990852355957, train_time = 0.10316181182861328\n",
      "INFO:absl:step = 23650, loss = 0.518403\n",
      "INFO:absl:251.028 steps/sec\n",
      "INFO:absl:collect_time = 0.09195232391357422, train_time = 0.10722899436950684\n",
      "INFO:absl:step = 23700, loss = 0.887440\n",
      "INFO:absl:267.669 steps/sec\n",
      "INFO:absl:collect_time = 0.08516407012939453, train_time = 0.10163402557373047\n",
      "INFO:absl:step = 23750, loss = 0.566847\n",
      "INFO:absl:257.873 steps/sec\n",
      "INFO:absl:collect_time = 0.09540486335754395, train_time = 0.09848904609680176\n",
      "INFO:absl:step = 23800, loss = 4.435362\n",
      "INFO:absl:290.779 steps/sec\n",
      "INFO:absl:collect_time = 0.08134293556213379, train_time = 0.09060907363891602\n",
      "INFO:absl:step = 23850, loss = 2.354880\n",
      "INFO:absl:296.166 steps/sec\n",
      "INFO:absl:collect_time = 0.07646894454956055, train_time = 0.09235501289367676\n",
      "INFO:absl:step = 23900, loss = 2.943512\n",
      "INFO:absl:271.097 steps/sec\n",
      "INFO:absl:collect_time = 0.08515095710754395, train_time = 0.09928512573242188\n",
      "INFO:absl:step = 23950, loss = 0.629965\n",
      "INFO:absl:257.307 steps/sec\n",
      "INFO:absl:collect_time = 0.08558392524719238, train_time = 0.10873675346374512\n",
      "INFO:absl:step = 24000, loss = 6.909589\n",
      "INFO:absl:277.394 steps/sec\n",
      "INFO:absl:collect_time = 0.08051896095275879, train_time = 0.09973001480102539\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-24000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-24000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000024000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000024000/assets\n",
      "INFO:absl:step = 24050, loss = 0.813378\n",
      "INFO:absl:300.539 steps/sec\n",
      "INFO:absl:collect_time = 0.06981801986694336, train_time = 0.09654998779296875\n",
      "INFO:absl:step = 24100, loss = 1.106540\n",
      "INFO:absl:266.497 steps/sec\n",
      "INFO:absl:collect_time = 0.08289027214050293, train_time = 0.10472917556762695\n",
      "INFO:absl:step = 24150, loss = 1.893652\n",
      "INFO:absl:278.309 steps/sec\n",
      "INFO:absl:collect_time = 0.08099102973937988, train_time = 0.09866523742675781\n",
      "INFO:absl:step = 24200, loss = 0.534160\n",
      "INFO:absl:283.158 steps/sec\n",
      "INFO:absl:collect_time = 0.08340263366699219, train_time = 0.09317731857299805\n",
      "INFO:absl:step = 24250, loss = 0.937282\n",
      "INFO:absl:265.433 steps/sec\n",
      "INFO:absl:collect_time = 0.0916740894317627, train_time = 0.09669709205627441\n",
      "INFO:absl:step = 24300, loss = 0.445490\n",
      "INFO:absl:257.274 steps/sec\n",
      "INFO:absl:collect_time = 0.08299612998962402, train_time = 0.11134910583496094\n",
      "INFO:absl:step = 24350, loss = 2.331415\n",
      "INFO:absl:245.342 steps/sec\n",
      "INFO:absl:collect_time = 0.09810638427734375, train_time = 0.10569095611572266\n",
      "INFO:absl:step = 24400, loss = 1.398833\n",
      "INFO:absl:256.405 steps/sec\n",
      "INFO:absl:collect_time = 0.08621716499328613, train_time = 0.10878705978393555\n",
      "INFO:absl:step = 24450, loss = 2.329865\n",
      "INFO:absl:229.329 steps/sec\n",
      "INFO:absl:collect_time = 0.1060032844543457, train_time = 0.11202406883239746\n",
      "INFO:absl:step = 24500, loss = 0.595180\n",
      "INFO:absl:260.438 steps/sec\n",
      "INFO:absl:collect_time = 0.09216594696044922, train_time = 0.09981822967529297\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-24500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-24500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000024500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000024500/assets\n",
      "INFO:absl:step = 24550, loss = 1.594351\n",
      "INFO:absl:247.029 steps/sec\n",
      "INFO:absl:collect_time = 0.09108853340148926, train_time = 0.11131715774536133\n",
      "INFO:absl:step = 24600, loss = 0.730341\n",
      "INFO:absl:259.118 steps/sec\n",
      "INFO:absl:collect_time = 0.0891718864440918, train_time = 0.1037900447845459\n",
      "INFO:absl:step = 24650, loss = 1.830380\n",
      "INFO:absl:279.460 steps/sec\n",
      "INFO:absl:collect_time = 0.07945656776428223, train_time = 0.09945988655090332\n",
      "INFO:absl:step = 24700, loss = 0.486215\n",
      "INFO:absl:290.229 steps/sec\n",
      "INFO:absl:collect_time = 0.07272171974182129, train_time = 0.09955620765686035\n",
      "INFO:absl:step = 24750, loss = 1.060379\n",
      "INFO:absl:271.139 steps/sec\n",
      "INFO:absl:collect_time = 0.08797478675842285, train_time = 0.09643220901489258\n",
      "INFO:absl:step = 24800, loss = 0.531606\n",
      "INFO:absl:297.560 steps/sec\n",
      "INFO:absl:collect_time = 0.0778207778930664, train_time = 0.09021282196044922\n",
      "INFO:absl:step = 24850, loss = 1.035652\n",
      "INFO:absl:258.149 steps/sec\n",
      "INFO:absl:collect_time = 0.08713078498840332, train_time = 0.10655593872070312\n",
      "INFO:absl:step = 24900, loss = 0.898553\n",
      "INFO:absl:291.080 steps/sec\n",
      "INFO:absl:collect_time = 0.07897400856018066, train_time = 0.09279990196228027\n",
      "INFO:absl:step = 24950, loss = 0.690935\n",
      "INFO:absl:261.551 steps/sec\n",
      "INFO:absl:collect_time = 0.09083819389343262, train_time = 0.10032916069030762\n",
      "INFO:absl:step = 25000, loss = 1.029319\n",
      "INFO:absl:221.199 steps/sec\n",
      "INFO:absl:collect_time = 0.1116938591003418, train_time = 0.11434698104858398\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-25000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-25000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000025000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000025000/assets\n",
      "INFO:absl:step = 25050, loss = 0.835343\n",
      "INFO:absl:232.551 steps/sec\n",
      "INFO:absl:collect_time = 0.07848596572875977, train_time = 0.1365208625793457\n",
      "INFO:absl:step = 25100, loss = 0.413110\n",
      "INFO:absl:289.209 steps/sec\n",
      "INFO:absl:collect_time = 0.07625222206115723, train_time = 0.0966329574584961\n",
      "INFO:absl:step = 25150, loss = 0.489721\n",
      "INFO:absl:270.949 steps/sec\n",
      "INFO:absl:collect_time = 0.08155107498168945, train_time = 0.10298562049865723\n",
      "INFO:absl:step = 25200, loss = 1.572600\n",
      "INFO:absl:264.529 steps/sec\n",
      "INFO:absl:collect_time = 0.08698797225952148, train_time = 0.10202693939208984\n",
      "INFO:absl:step = 25250, loss = 0.211656\n",
      "INFO:absl:256.731 steps/sec\n",
      "INFO:absl:collect_time = 0.08633208274841309, train_time = 0.10842418670654297\n",
      "INFO:absl:step = 25300, loss = 0.747391\n",
      "INFO:absl:270.993 steps/sec\n",
      "INFO:absl:collect_time = 0.08886027336120605, train_time = 0.09564638137817383\n",
      "INFO:absl:step = 25350, loss = 0.858849\n",
      "INFO:absl:284.266 steps/sec\n",
      "INFO:absl:collect_time = 0.08061099052429199, train_time = 0.09528088569641113\n",
      "INFO:absl:step = 25400, loss = 2.555141\n",
      "INFO:absl:286.802 steps/sec\n",
      "INFO:absl:collect_time = 0.08111929893493652, train_time = 0.09321713447570801\n",
      "INFO:absl:step = 25450, loss = 0.663477\n",
      "INFO:absl:241.238 steps/sec\n",
      "INFO:absl:collect_time = 0.10354804992675781, train_time = 0.10371613502502441\n",
      "INFO:absl:step = 25500, loss = 0.710606\n",
      "INFO:absl:311.083 steps/sec\n",
      "INFO:absl:collect_time = 0.0674891471862793, train_time = 0.09323978424072266\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-25500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-25500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000025500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000025500/assets\n",
      "INFO:absl:step = 25550, loss = 0.536993\n",
      "INFO:absl:237.570 steps/sec\n",
      "INFO:absl:collect_time = 0.07028579711914062, train_time = 0.14017844200134277\n",
      "INFO:absl:step = 25600, loss = 2.447760\n",
      "INFO:absl:231.495 steps/sec\n",
      "INFO:absl:collect_time = 0.11080598831176758, train_time = 0.10518097877502441\n",
      "INFO:absl:step = 25650, loss = 1.264019\n",
      "INFO:absl:301.888 steps/sec\n",
      "INFO:absl:collect_time = 0.07447004318237305, train_time = 0.09115409851074219\n",
      "INFO:absl:step = 25700, loss = 0.877153\n",
      "INFO:absl:263.758 steps/sec\n",
      "INFO:absl:collect_time = 0.08013486862182617, train_time = 0.10943293571472168\n",
      "INFO:absl:step = 25750, loss = 0.449109\n",
      "INFO:absl:258.330 steps/sec\n",
      "INFO:absl:collect_time = 0.09589052200317383, train_time = 0.09766006469726562\n",
      "INFO:absl:step = 25800, loss = 0.795348\n",
      "INFO:absl:197.553 steps/sec\n",
      "INFO:absl:collect_time = 0.11270880699157715, train_time = 0.14038801193237305\n",
      "INFO:absl:step = 25850, loss = 3.191089\n",
      "INFO:absl:216.511 steps/sec\n",
      "INFO:absl:collect_time = 0.11730337142944336, train_time = 0.1136317253112793\n",
      "INFO:absl:step = 25900, loss = 1.905800\n",
      "INFO:absl:223.268 steps/sec\n",
      "INFO:absl:collect_time = 0.11454081535339355, train_time = 0.1094057559967041\n",
      "INFO:absl:step = 25950, loss = 1.241462\n",
      "INFO:absl:218.226 steps/sec\n",
      "INFO:absl:collect_time = 0.10322093963623047, train_time = 0.125899076461792\n",
      "INFO:absl:step = 26000, loss = 0.593841\n",
      "INFO:absl:268.175 steps/sec\n",
      "INFO:absl:collect_time = 0.08953547477722168, train_time = 0.09690999984741211\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-26000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-26000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000026000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000026000/assets\n",
      "INFO:absl:step = 26050, loss = 0.378757\n",
      "INFO:absl:310.428 steps/sec\n",
      "INFO:absl:collect_time = 0.07035160064697266, train_time = 0.09071612358093262\n",
      "INFO:absl:step = 26100, loss = 0.887760\n",
      "INFO:absl:291.774 steps/sec\n",
      "INFO:absl:collect_time = 0.07647895812988281, train_time = 0.09488677978515625\n",
      "INFO:absl:step = 26150, loss = 0.805764\n",
      "INFO:absl:284.074 steps/sec\n",
      "INFO:absl:collect_time = 0.08417701721191406, train_time = 0.09183335304260254\n",
      "INFO:absl:step = 26200, loss = 2.180315\n",
      "INFO:absl:268.206 steps/sec\n",
      "INFO:absl:collect_time = 0.09009599685668945, train_time = 0.0963280200958252\n",
      "INFO:absl:step = 26250, loss = 1.652327\n",
      "INFO:absl:283.271 steps/sec\n",
      "INFO:absl:collect_time = 0.07558393478393555, train_time = 0.10092568397521973\n",
      "INFO:absl:step = 26300, loss = 0.585726\n",
      "INFO:absl:157.663 steps/sec\n",
      "INFO:absl:collect_time = 0.13385915756225586, train_time = 0.183272123336792\n",
      "INFO:absl:step = 26350, loss = 1.280141\n",
      "INFO:absl:228.369 steps/sec\n",
      "INFO:absl:collect_time = 0.1173863410949707, train_time = 0.10155797004699707\n",
      "INFO:absl:step = 26400, loss = 0.590808\n",
      "INFO:absl:278.646 steps/sec\n",
      "INFO:absl:collect_time = 0.07621335983276367, train_time = 0.1032259464263916\n",
      "INFO:absl:step = 26450, loss = 1.178235\n",
      "INFO:absl:259.863 steps/sec\n",
      "INFO:absl:collect_time = 0.0898289680480957, train_time = 0.10258007049560547\n",
      "INFO:absl:step = 26500, loss = 1.201745\n",
      "INFO:absl:221.420 steps/sec\n",
      "INFO:absl:collect_time = 0.12018704414367676, train_time = 0.10562801361083984\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-26500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-26500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000026500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000026500/assets\n",
      "INFO:absl:step = 26550, loss = 1.965551\n",
      "INFO:absl:217.202 steps/sec\n",
      "INFO:absl:collect_time = 0.0870518684387207, train_time = 0.14314866065979004\n",
      "INFO:absl:step = 26600, loss = 0.445690\n",
      "INFO:absl:227.311 steps/sec\n",
      "INFO:absl:collect_time = 0.10922002792358398, train_time = 0.11074304580688477\n",
      "INFO:absl:step = 26650, loss = 1.004504\n",
      "INFO:absl:245.999 steps/sec\n",
      "INFO:absl:collect_time = 0.09008097648620605, train_time = 0.11317229270935059\n",
      "INFO:absl:step = 26700, loss = 4.466619\n",
      "INFO:absl:249.994 steps/sec\n",
      "INFO:absl:collect_time = 0.09631705284118652, train_time = 0.10368800163269043\n",
      "INFO:absl:step = 26750, loss = 1.704247\n",
      "INFO:absl:235.521 steps/sec\n",
      "INFO:absl:collect_time = 0.1139230728149414, train_time = 0.09837198257446289\n",
      "INFO:absl:step = 26800, loss = 2.746903\n",
      "INFO:absl:244.734 steps/sec\n",
      "INFO:absl:collect_time = 0.0909123420715332, train_time = 0.11339092254638672\n",
      "INFO:absl:step = 26850, loss = 3.308779\n",
      "INFO:absl:244.476 steps/sec\n",
      "INFO:absl:collect_time = 0.08712935447692871, train_time = 0.11738991737365723\n",
      "INFO:absl:step = 26900, loss = 2.236944\n",
      "INFO:absl:257.704 steps/sec\n",
      "INFO:absl:collect_time = 0.09471511840820312, train_time = 0.09930610656738281\n",
      "INFO:absl:step = 26950, loss = 2.260793\n",
      "INFO:absl:201.705 steps/sec\n",
      "INFO:absl:collect_time = 0.11393475532531738, train_time = 0.13395214080810547\n",
      "INFO:absl:step = 27000, loss = 1.403216\n",
      "INFO:absl:250.218 steps/sec\n",
      "INFO:absl:collect_time = 0.09462785720825195, train_time = 0.10519814491271973\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-27000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-27000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000027000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000027000/assets\n",
      "INFO:absl:step = 27050, loss = 0.408760\n",
      "INFO:absl:305.265 steps/sec\n",
      "INFO:absl:collect_time = 0.0717463493347168, train_time = 0.09204578399658203\n",
      "INFO:absl:step = 27100, loss = 0.879673\n",
      "INFO:absl:309.975 steps/sec\n",
      "INFO:absl:collect_time = 0.07365226745605469, train_time = 0.08765125274658203\n",
      "INFO:absl:step = 27150, loss = 1.021609\n",
      "INFO:absl:239.545 steps/sec\n",
      "INFO:absl:collect_time = 0.09834623336791992, train_time = 0.1103830337524414\n",
      "INFO:absl:step = 27200, loss = 1.297038\n",
      "INFO:absl:233.900 steps/sec\n",
      "INFO:absl:collect_time = 0.10482263565063477, train_time = 0.10894417762756348\n",
      "INFO:absl:step = 27250, loss = 0.479521\n",
      "INFO:absl:283.284 steps/sec\n",
      "INFO:absl:collect_time = 0.08217310905456543, train_time = 0.09432816505432129\n",
      "INFO:absl:step = 27300, loss = 0.403717\n",
      "INFO:absl:266.683 steps/sec\n",
      "INFO:absl:collect_time = 0.08611297607421875, train_time = 0.10137581825256348\n",
      "INFO:absl:step = 27350, loss = 0.264753\n",
      "INFO:absl:198.949 steps/sec\n",
      "INFO:absl:collect_time = 0.12528204917907715, train_time = 0.1260380744934082\n",
      "INFO:absl:step = 27400, loss = 2.412716\n",
      "INFO:absl:220.422 steps/sec\n",
      "INFO:absl:collect_time = 0.11712384223937988, train_time = 0.10971331596374512\n",
      "INFO:absl:step = 27450, loss = 0.500380\n",
      "INFO:absl:257.989 steps/sec\n",
      "INFO:absl:collect_time = 0.0887908935546875, train_time = 0.10501599311828613\n",
      "INFO:absl:step = 27500, loss = 0.655779\n",
      "INFO:absl:276.996 steps/sec\n",
      "INFO:absl:collect_time = 0.0837850570678711, train_time = 0.09672284126281738\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-27500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-27500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000027500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000027500/assets\n",
      "INFO:absl:step = 27550, loss = 7.513808\n",
      "INFO:absl:299.267 steps/sec\n",
      "INFO:absl:collect_time = 0.07366394996643066, train_time = 0.09341096878051758\n",
      "INFO:absl:step = 27600, loss = 0.894643\n",
      "INFO:absl:306.246 steps/sec\n",
      "INFO:absl:collect_time = 0.06992244720458984, train_time = 0.09334492683410645\n",
      "INFO:absl:step = 27650, loss = 1.725776\n",
      "INFO:absl:250.374 steps/sec\n",
      "INFO:absl:collect_time = 0.0899970531463623, train_time = 0.10970449447631836\n",
      "INFO:absl:step = 27700, loss = 4.268197\n",
      "INFO:absl:277.463 steps/sec\n",
      "INFO:absl:collect_time = 0.0820620059967041, train_time = 0.09814214706420898\n",
      "INFO:absl:step = 27750, loss = 0.324778\n",
      "INFO:absl:302.004 steps/sec\n",
      "INFO:absl:collect_time = 0.07788252830505371, train_time = 0.0876779556274414\n",
      "INFO:absl:step = 27800, loss = 0.614794\n",
      "INFO:absl:248.889 steps/sec\n",
      "INFO:absl:collect_time = 0.0702810287475586, train_time = 0.13061165809631348\n",
      "INFO:absl:step = 27850, loss = 0.364854\n",
      "INFO:absl:210.632 steps/sec\n",
      "INFO:absl:collect_time = 0.12268400192260742, train_time = 0.11469721794128418\n",
      "INFO:absl:step = 27900, loss = 1.340577\n",
      "INFO:absl:311.658 steps/sec\n",
      "INFO:absl:collect_time = 0.07238507270812988, train_time = 0.08804726600646973\n",
      "INFO:absl:step = 27950, loss = 6.326188\n",
      "INFO:absl:241.693 steps/sec\n",
      "INFO:absl:collect_time = 0.09303522109985352, train_time = 0.11383867263793945\n",
      "INFO:absl:step = 28000, loss = 0.613814\n",
      "INFO:absl:222.848 steps/sec\n",
      "INFO:absl:collect_time = 0.09617781639099121, train_time = 0.1281907558441162\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-28000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-28000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000028000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000028000/assets\n",
      "INFO:absl:step = 28050, loss = 0.378856\n",
      "INFO:absl:269.273 steps/sec\n",
      "INFO:absl:collect_time = 0.08524799346923828, train_time = 0.10043692588806152\n",
      "INFO:absl:step = 28100, loss = 0.428745\n",
      "INFO:absl:249.124 steps/sec\n",
      "INFO:absl:collect_time = 0.10127973556518555, train_time = 0.09942317008972168\n",
      "INFO:absl:step = 28150, loss = 2.905816\n",
      "INFO:absl:237.699 steps/sec\n",
      "INFO:absl:collect_time = 0.10096907615661621, train_time = 0.10938072204589844\n",
      "INFO:absl:step = 28200, loss = 0.569874\n",
      "INFO:absl:190.569 steps/sec\n",
      "INFO:absl:collect_time = 0.1138918399810791, train_time = 0.14848017692565918\n",
      "INFO:absl:step = 28250, loss = 0.570912\n",
      "INFO:absl:181.235 steps/sec\n",
      "INFO:absl:collect_time = 0.10558629035949707, train_time = 0.17029905319213867\n",
      "INFO:absl:step = 28300, loss = 2.516598\n",
      "INFO:absl:215.742 steps/sec\n",
      "INFO:absl:collect_time = 0.1137089729309082, train_time = 0.11804962158203125\n",
      "INFO:absl:step = 28350, loss = 1.630648\n",
      "INFO:absl:212.652 steps/sec\n",
      "INFO:absl:collect_time = 0.10048985481262207, train_time = 0.13463592529296875\n",
      "INFO:absl:step = 28400, loss = 0.443433\n",
      "INFO:absl:272.342 steps/sec\n",
      "INFO:absl:collect_time = 0.08656692504882812, train_time = 0.09702587127685547\n",
      "INFO:absl:step = 28450, loss = 0.455649\n",
      "INFO:absl:252.641 steps/sec\n",
      "INFO:absl:collect_time = 0.09129714965820312, train_time = 0.10661196708679199\n",
      "INFO:absl:step = 28500, loss = 0.699906\n",
      "INFO:absl:254.169 steps/sec\n",
      "INFO:absl:collect_time = 0.09248685836791992, train_time = 0.1042327880859375\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-28500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-28500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000028500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000028500/assets\n",
      "INFO:absl:step = 28550, loss = 0.579684\n",
      "INFO:absl:269.834 steps/sec\n",
      "INFO:absl:collect_time = 0.07964920997619629, train_time = 0.10565018653869629\n",
      "INFO:absl:step = 28600, loss = 1.870920\n",
      "INFO:absl:268.427 steps/sec\n",
      "INFO:absl:collect_time = 0.08520793914794922, train_time = 0.10106277465820312\n",
      "INFO:absl:step = 28650, loss = 0.648379\n",
      "INFO:absl:255.340 steps/sec\n",
      "INFO:absl:collect_time = 0.0903160572052002, train_time = 0.10550093650817871\n",
      "INFO:absl:step = 28700, loss = 1.386619\n",
      "INFO:absl:275.491 steps/sec\n",
      "INFO:absl:collect_time = 0.08320188522338867, train_time = 0.09829235076904297\n",
      "INFO:absl:step = 28750, loss = 0.498725\n",
      "INFO:absl:322.142 steps/sec\n",
      "INFO:absl:collect_time = 0.06831502914428711, train_time = 0.08689594268798828\n",
      "INFO:absl:step = 28800, loss = 6.724638\n",
      "INFO:absl:258.328 steps/sec\n",
      "INFO:absl:collect_time = 0.08902502059936523, train_time = 0.10452723503112793\n",
      "INFO:absl:step = 28850, loss = 1.048504\n",
      "INFO:absl:248.180 steps/sec\n",
      "INFO:absl:collect_time = 0.09383296966552734, train_time = 0.10763382911682129\n",
      "INFO:absl:step = 28900, loss = 0.893862\n",
      "INFO:absl:222.064 steps/sec\n",
      "INFO:absl:collect_time = 0.0979468822479248, train_time = 0.1272132396697998\n",
      "INFO:absl:step = 28950, loss = 0.304828\n",
      "INFO:absl:264.560 steps/sec\n",
      "INFO:absl:collect_time = 0.08551383018493652, train_time = 0.10347890853881836\n",
      "INFO:absl:step = 29000, loss = 0.620529\n",
      "INFO:absl:274.929 steps/sec\n",
      "INFO:absl:collect_time = 0.08468484878540039, train_time = 0.09718012809753418\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-29000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-29000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000029000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000029000/assets\n",
      "INFO:absl:step = 29050, loss = 0.933534\n",
      "INFO:absl:257.639 steps/sec\n",
      "INFO:absl:collect_time = 0.0955667495727539, train_time = 0.09850311279296875\n",
      "INFO:absl:step = 29100, loss = 4.761210\n",
      "INFO:absl:234.125 steps/sec\n",
      "INFO:absl:collect_time = 0.10189104080200195, train_time = 0.11166977882385254\n",
      "INFO:absl:step = 29150, loss = 2.838459\n",
      "INFO:absl:237.591 steps/sec\n",
      "INFO:absl:collect_time = 0.09544897079467773, train_time = 0.11499714851379395\n",
      "INFO:absl:step = 29200, loss = 0.653517\n",
      "INFO:absl:264.517 steps/sec\n",
      "INFO:absl:collect_time = 0.09827375411987305, train_time = 0.09075021743774414\n",
      "INFO:absl:step = 29250, loss = 1.460132\n",
      "INFO:absl:267.339 steps/sec\n",
      "INFO:absl:collect_time = 0.08472323417663574, train_time = 0.10230493545532227\n",
      "INFO:absl:step = 29300, loss = 12.987043\n",
      "INFO:absl:284.049 steps/sec\n",
      "INFO:absl:collect_time = 0.07246112823486328, train_time = 0.10356473922729492\n",
      "INFO:absl:step = 29350, loss = 3.565513\n",
      "INFO:absl:235.534 steps/sec\n",
      "INFO:absl:collect_time = 0.10045003890991211, train_time = 0.11183381080627441\n",
      "INFO:absl:step = 29400, loss = 0.609622\n",
      "INFO:absl:261.605 steps/sec\n",
      "INFO:absl:collect_time = 0.08814787864685059, train_time = 0.10297989845275879\n",
      "INFO:absl:step = 29450, loss = 1.754785\n",
      "INFO:absl:255.228 steps/sec\n",
      "INFO:absl:collect_time = 0.09092998504638672, train_time = 0.10497307777404785\n",
      "INFO:absl:step = 29500, loss = 1.685480\n",
      "INFO:absl:276.127 steps/sec\n",
      "INFO:absl:collect_time = 0.0813438892364502, train_time = 0.0997319221496582\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-29500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-29500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000029500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000029500/assets\n",
      "INFO:absl:step = 29550, loss = 2.732585\n",
      "INFO:absl:297.116 steps/sec\n",
      "INFO:absl:collect_time = 0.07446622848510742, train_time = 0.09381794929504395\n",
      "INFO:absl:step = 29600, loss = 0.682435\n",
      "INFO:absl:298.952 steps/sec\n",
      "INFO:absl:collect_time = 0.0706472396850586, train_time = 0.0966038703918457\n",
      "INFO:absl:step = 29650, loss = 5.801513\n",
      "INFO:absl:268.424 steps/sec\n",
      "INFO:absl:collect_time = 0.08833479881286621, train_time = 0.09793734550476074\n",
      "INFO:absl:step = 29700, loss = 0.581281\n",
      "INFO:absl:234.732 steps/sec\n",
      "INFO:absl:collect_time = 0.10187625885009766, train_time = 0.11113262176513672\n",
      "INFO:absl:step = 29750, loss = 2.728086\n",
      "INFO:absl:230.652 steps/sec\n",
      "INFO:absl:collect_time = 0.09859681129455566, train_time = 0.1181800365447998\n",
      "INFO:absl:step = 29800, loss = 0.905490\n",
      "INFO:absl:255.839 steps/sec\n",
      "INFO:absl:collect_time = 0.09436535835266113, train_time = 0.10106968879699707\n",
      "INFO:absl:step = 29850, loss = 1.238727\n",
      "INFO:absl:241.447 steps/sec\n",
      "INFO:absl:collect_time = 0.08983826637268066, train_time = 0.11724686622619629\n",
      "INFO:absl:step = 29900, loss = 0.899821\n",
      "INFO:absl:187.183 steps/sec\n",
      "INFO:absl:collect_time = 0.14213013648986816, train_time = 0.12498831748962402\n",
      "INFO:absl:step = 29950, loss = 1.121613\n",
      "INFO:absl:250.083 steps/sec\n",
      "INFO:absl:collect_time = 0.09221482276916504, train_time = 0.10771894454956055\n",
      "INFO:absl:step = 30000, loss = 1.683374\n",
      "INFO:absl:255.094 steps/sec\n",
      "INFO:absl:collect_time = 0.0952291488647461, train_time = 0.10077691078186035\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-30000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000030000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000030000/assets\n",
      "INFO:absl:step = 30050, loss = 1.188113\n",
      "INFO:absl:296.620 steps/sec\n",
      "INFO:absl:collect_time = 0.06789684295654297, train_time = 0.10066914558410645\n",
      "INFO:absl:step = 30100, loss = 0.694215\n",
      "INFO:absl:282.778 steps/sec\n",
      "INFO:absl:collect_time = 0.07943201065063477, train_time = 0.09738516807556152\n",
      "INFO:absl:step = 30150, loss = 0.466721\n",
      "INFO:absl:295.305 steps/sec\n",
      "INFO:absl:collect_time = 0.07459092140197754, train_time = 0.09472537040710449\n",
      "INFO:absl:step = 30200, loss = 4.888458\n",
      "INFO:absl:299.168 steps/sec\n",
      "INFO:absl:collect_time = 0.07754325866699219, train_time = 0.08958697319030762\n",
      "INFO:absl:step = 30250, loss = 0.648154\n",
      "INFO:absl:271.069 steps/sec\n",
      "INFO:absl:collect_time = 0.08657479286193848, train_time = 0.09787988662719727\n",
      "INFO:absl:step = 30300, loss = 0.762757\n",
      "INFO:absl:271.357 steps/sec\n",
      "INFO:absl:collect_time = 0.08637571334838867, train_time = 0.09788322448730469\n",
      "INFO:absl:step = 30350, loss = 1.761902\n",
      "INFO:absl:286.896 steps/sec\n",
      "INFO:absl:collect_time = 0.07849407196044922, train_time = 0.09578490257263184\n",
      "INFO:absl:step = 30400, loss = 5.533807\n",
      "INFO:absl:236.210 steps/sec\n",
      "INFO:absl:collect_time = 0.10047316551208496, train_time = 0.11120295524597168\n",
      "INFO:absl:step = 30450, loss = 0.860365\n",
      "INFO:absl:300.814 steps/sec\n",
      "INFO:absl:collect_time = 0.07766842842102051, train_time = 0.0885469913482666\n",
      "INFO:absl:step = 30500, loss = 0.739204\n",
      "INFO:absl:301.005 steps/sec\n",
      "INFO:absl:collect_time = 0.0770730972290039, train_time = 0.08903717994689941\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-30500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-30500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000030500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000030500/assets\n",
      "INFO:absl:step = 30550, loss = 0.605174\n",
      "INFO:absl:304.727 steps/sec\n",
      "INFO:absl:collect_time = 0.06640076637268066, train_time = 0.09768056869506836\n",
      "INFO:absl:step = 30600, loss = 0.917678\n",
      "INFO:absl:268.826 steps/sec\n",
      "INFO:absl:collect_time = 0.07989192008972168, train_time = 0.10610198974609375\n",
      "INFO:absl:step = 30650, loss = 0.475770\n",
      "INFO:absl:275.406 steps/sec\n",
      "INFO:absl:collect_time = 0.08759808540344238, train_time = 0.09395217895507812\n",
      "INFO:absl:step = 30700, loss = 1.059051\n",
      "INFO:absl:291.279 steps/sec\n",
      "INFO:absl:collect_time = 0.07495522499084473, train_time = 0.09670162200927734\n",
      "INFO:absl:step = 30750, loss = 0.369909\n",
      "INFO:absl:286.057 steps/sec\n",
      "INFO:absl:collect_time = 0.0824439525604248, train_time = 0.0923464298248291\n",
      "INFO:absl:step = 30800, loss = 1.482520\n",
      "INFO:absl:285.220 steps/sec\n",
      "INFO:absl:collect_time = 0.08186125755310059, train_time = 0.09344220161437988\n",
      "INFO:absl:step = 30850, loss = 1.205443\n",
      "INFO:absl:284.919 steps/sec\n",
      "INFO:absl:collect_time = 0.07892513275146484, train_time = 0.09656310081481934\n",
      "INFO:absl:step = 30900, loss = 0.436741\n",
      "INFO:absl:281.066 steps/sec\n",
      "INFO:absl:collect_time = 0.08274412155151367, train_time = 0.09514999389648438\n",
      "INFO:absl:step = 30950, loss = 1.139102\n",
      "INFO:absl:282.433 steps/sec\n",
      "INFO:absl:collect_time = 0.08491706848144531, train_time = 0.09211587905883789\n",
      "INFO:absl:step = 31000, loss = 0.738630\n",
      "INFO:absl:281.413 steps/sec\n",
      "INFO:absl:collect_time = 0.08012700080871582, train_time = 0.09754800796508789\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-31000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-31000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000031000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000031000/assets\n",
      "INFO:absl:step = 31050, loss = 0.310472\n",
      "INFO:absl:292.087 steps/sec\n",
      "INFO:absl:collect_time = 0.07698678970336914, train_time = 0.09419536590576172\n",
      "INFO:absl:step = 31100, loss = 2.376977\n",
      "INFO:absl:259.125 steps/sec\n",
      "INFO:absl:collect_time = 0.09050321578979492, train_time = 0.10245370864868164\n",
      "INFO:absl:step = 31150, loss = 1.674321\n",
      "INFO:absl:201.873 steps/sec\n",
      "INFO:absl:collect_time = 0.11825871467590332, train_time = 0.12942194938659668\n",
      "INFO:absl:step = 31200, loss = 0.674099\n",
      "INFO:absl:235.643 steps/sec\n",
      "INFO:absl:collect_time = 0.09374094009399414, train_time = 0.11844420433044434\n",
      "INFO:absl:step = 31250, loss = 1.272683\n",
      "INFO:absl:242.391 steps/sec\n",
      "INFO:absl:collect_time = 0.09772777557373047, train_time = 0.1085507869720459\n",
      "INFO:absl:step = 31300, loss = 0.458871\n",
      "INFO:absl:269.732 steps/sec\n",
      "INFO:absl:collect_time = 0.09366393089294434, train_time = 0.0917050838470459\n",
      "INFO:absl:step = 31350, loss = 0.441069\n",
      "INFO:absl:290.687 steps/sec\n",
      "INFO:absl:collect_time = 0.07741689682006836, train_time = 0.0945892333984375\n",
      "INFO:absl:step = 31400, loss = 0.467266\n",
      "INFO:absl:247.637 steps/sec\n",
      "INFO:absl:collect_time = 0.09627342224121094, train_time = 0.10563492774963379\n",
      "INFO:absl:step = 31450, loss = 6.287967\n",
      "INFO:absl:216.552 steps/sec\n",
      "INFO:absl:collect_time = 0.10825705528259277, train_time = 0.1226339340209961\n",
      "INFO:absl:step = 31500, loss = 2.811139\n",
      "INFO:absl:286.039 steps/sec\n",
      "INFO:absl:collect_time = 0.07932806015014648, train_time = 0.09547305107116699\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-31500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-31500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000031500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000031500/assets\n",
      "INFO:absl:step = 31550, loss = 1.567216\n",
      "INFO:absl:210.018 steps/sec\n",
      "INFO:absl:collect_time = 0.1082615852355957, train_time = 0.12981343269348145\n",
      "INFO:absl:step = 31600, loss = 2.030240\n",
      "INFO:absl:253.644 steps/sec\n",
      "INFO:absl:collect_time = 0.09418988227844238, train_time = 0.10293698310852051\n",
      "INFO:absl:step = 31650, loss = 3.007765\n",
      "INFO:absl:210.151 steps/sec\n",
      "INFO:absl:collect_time = 0.11694836616516113, train_time = 0.12097597122192383\n",
      "INFO:absl:step = 31700, loss = 1.400626\n",
      "INFO:absl:239.973 steps/sec\n",
      "INFO:absl:collect_time = 0.09968113899230957, train_time = 0.10867595672607422\n",
      "INFO:absl:step = 31750, loss = 0.403495\n",
      "INFO:absl:248.698 steps/sec\n",
      "INFO:absl:collect_time = 0.09313082695007324, train_time = 0.10791611671447754\n",
      "INFO:absl:step = 31800, loss = 1.299856\n",
      "INFO:absl:234.657 steps/sec\n",
      "INFO:absl:collect_time = 0.09699630737304688, train_time = 0.11608028411865234\n",
      "INFO:absl:step = 31850, loss = 0.736062\n",
      "INFO:absl:261.200 steps/sec\n",
      "INFO:absl:collect_time = 0.08271408081054688, train_time = 0.10870981216430664\n",
      "INFO:absl:step = 31900, loss = 1.242303\n",
      "INFO:absl:211.100 steps/sec\n",
      "INFO:absl:collect_time = 0.11577010154724121, train_time = 0.12108397483825684\n",
      "INFO:absl:step = 31950, loss = 6.074572\n",
      "INFO:absl:222.472 steps/sec\n",
      "INFO:absl:collect_time = 0.10462212562561035, train_time = 0.12012505531311035\n",
      "INFO:absl:step = 32000, loss = 1.185958\n",
      "INFO:absl:234.602 steps/sec\n",
      "INFO:absl:collect_time = 0.08782792091369629, train_time = 0.12529921531677246\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-32000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-32000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000032000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000032000/assets\n",
      "INFO:absl:step = 32050, loss = 1.407326\n",
      "INFO:absl:250.287 steps/sec\n",
      "INFO:absl:collect_time = 0.0860891342163086, train_time = 0.11368179321289062\n",
      "INFO:absl:step = 32100, loss = 1.851470\n",
      "INFO:absl:251.407 steps/sec\n",
      "INFO:absl:collect_time = 0.09052681922912598, train_time = 0.10835409164428711\n",
      "INFO:absl:step = 32150, loss = 0.733193\n",
      "INFO:absl:264.318 steps/sec\n",
      "INFO:absl:collect_time = 0.08456587791442871, train_time = 0.10460019111633301\n",
      "INFO:absl:step = 32200, loss = 0.596464\n",
      "INFO:absl:274.234 steps/sec\n",
      "INFO:absl:collect_time = 0.08276510238647461, train_time = 0.09956073760986328\n",
      "INFO:absl:step = 32250, loss = 7.080750\n",
      "INFO:absl:245.436 steps/sec\n",
      "INFO:absl:collect_time = 0.09919500350952148, train_time = 0.10452389717102051\n",
      "INFO:absl:step = 32300, loss = 2.630346\n",
      "INFO:absl:239.397 steps/sec\n",
      "INFO:absl:collect_time = 0.10487890243530273, train_time = 0.10397911071777344\n",
      "INFO:absl:step = 32350, loss = 0.794914\n",
      "INFO:absl:258.156 steps/sec\n",
      "INFO:absl:collect_time = 0.0881950855255127, train_time = 0.10548591613769531\n",
      "INFO:absl:step = 32400, loss = 1.141199\n",
      "INFO:absl:222.798 steps/sec\n",
      "INFO:absl:collect_time = 0.10992121696472168, train_time = 0.11449718475341797\n",
      "INFO:absl:step = 32450, loss = 2.492366\n",
      "INFO:absl:253.474 steps/sec\n",
      "INFO:absl:collect_time = 0.09351420402526855, train_time = 0.1037449836730957\n",
      "INFO:absl:step = 32500, loss = 1.447400\n",
      "INFO:absl:240.943 steps/sec\n",
      "INFO:absl:collect_time = 0.09323596954345703, train_time = 0.11428189277648926\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-32500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-32500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000032500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000032500/assets\n",
      "INFO:absl:step = 32550, loss = 2.126656\n",
      "INFO:absl:215.895 steps/sec\n",
      "INFO:absl:collect_time = 0.11461400985717773, train_time = 0.11697983741760254\n",
      "INFO:absl:step = 32600, loss = 1.533375\n",
      "INFO:absl:258.650 steps/sec\n",
      "INFO:absl:collect_time = 0.08762717247009277, train_time = 0.10568428039550781\n",
      "INFO:absl:step = 32650, loss = 1.598842\n",
      "INFO:absl:234.538 steps/sec\n",
      "INFO:absl:collect_time = 0.09958124160766602, train_time = 0.11360406875610352\n",
      "INFO:absl:step = 32700, loss = 0.861880\n",
      "INFO:absl:278.932 steps/sec\n",
      "INFO:absl:collect_time = 0.08414626121520996, train_time = 0.0951089859008789\n",
      "INFO:absl:step = 32750, loss = 0.824923\n",
      "INFO:absl:283.766 steps/sec\n",
      "INFO:absl:collect_time = 0.0794367790222168, train_time = 0.09676504135131836\n",
      "INFO:absl:step = 32800, loss = 1.907054\n",
      "INFO:absl:238.394 steps/sec\n",
      "INFO:absl:collect_time = 0.1097710132598877, train_time = 0.09996604919433594\n",
      "INFO:absl:step = 32850, loss = 0.334898\n",
      "INFO:absl:254.737 steps/sec\n",
      "INFO:absl:collect_time = 0.09239077568054199, train_time = 0.10388994216918945\n",
      "INFO:absl:step = 32900, loss = 1.297564\n",
      "INFO:absl:226.224 steps/sec\n",
      "INFO:absl:collect_time = 0.10385918617248535, train_time = 0.11716079711914062\n",
      "INFO:absl:step = 32950, loss = 1.322850\n",
      "INFO:absl:270.800 steps/sec\n",
      "INFO:absl:collect_time = 0.0858910083770752, train_time = 0.09874701499938965\n",
      "INFO:absl:step = 33000, loss = 0.947765\n",
      "INFO:absl:270.330 steps/sec\n",
      "INFO:absl:collect_time = 0.08615732192993164, train_time = 0.09880185127258301\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-33000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-33000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000033000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000033000/assets\n",
      "INFO:absl:step = 33050, loss = 2.834840\n",
      "INFO:absl:289.363 steps/sec\n",
      "INFO:absl:collect_time = 0.07982492446899414, train_time = 0.09296822547912598\n",
      "INFO:absl:step = 33100, loss = 3.549296\n",
      "INFO:absl:312.276 steps/sec\n",
      "INFO:absl:collect_time = 0.07255315780639648, train_time = 0.08756184577941895\n",
      "INFO:absl:step = 33150, loss = 0.677678\n",
      "INFO:absl:280.998 steps/sec\n",
      "INFO:absl:collect_time = 0.07775092124938965, train_time = 0.10018610954284668\n",
      "INFO:absl:step = 33200, loss = 0.345876\n",
      "INFO:absl:252.103 steps/sec\n",
      "INFO:absl:collect_time = 0.08165740966796875, train_time = 0.11667394638061523\n",
      "INFO:absl:step = 33250, loss = 1.029427\n",
      "INFO:absl:287.137 steps/sec\n",
      "INFO:absl:collect_time = 0.0792238712310791, train_time = 0.0949091911315918\n",
      "INFO:absl:step = 33300, loss = 3.493516\n",
      "INFO:absl:263.310 steps/sec\n",
      "INFO:absl:collect_time = 0.08498024940490723, train_time = 0.10490965843200684\n",
      "INFO:absl:step = 33350, loss = 0.733952\n",
      "INFO:absl:286.367 steps/sec\n",
      "INFO:absl:collect_time = 0.0775601863861084, train_time = 0.09704089164733887\n",
      "INFO:absl:step = 33400, loss = 1.465574\n",
      "INFO:absl:203.542 steps/sec\n",
      "INFO:absl:collect_time = 0.12619471549987793, train_time = 0.11945486068725586\n",
      "INFO:absl:step = 33450, loss = 2.567534\n",
      "INFO:absl:243.154 steps/sec\n",
      "INFO:absl:collect_time = 0.10383415222167969, train_time = 0.10179686546325684\n",
      "INFO:absl:step = 33500, loss = 2.387717\n",
      "INFO:absl:263.804 steps/sec\n",
      "INFO:absl:collect_time = 0.08503389358520508, train_time = 0.10450077056884766\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-33500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-33500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000033500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000033500/assets\n",
      "INFO:absl:step = 33550, loss = 2.110599\n",
      "INFO:absl:247.182 steps/sec\n",
      "INFO:absl:collect_time = 0.09521794319152832, train_time = 0.10706186294555664\n",
      "INFO:absl:step = 33600, loss = 1.145651\n",
      "INFO:absl:267.334 steps/sec\n",
      "INFO:absl:collect_time = 0.0854949951171875, train_time = 0.10153698921203613\n",
      "INFO:absl:step = 33650, loss = 0.392991\n",
      "INFO:absl:270.298 steps/sec\n",
      "INFO:absl:collect_time = 0.08736610412597656, train_time = 0.09761476516723633\n",
      "INFO:absl:step = 33700, loss = 1.169528\n",
      "INFO:absl:263.608 steps/sec\n",
      "INFO:absl:collect_time = 0.09301972389221191, train_time = 0.09665584564208984\n",
      "INFO:absl:step = 33750, loss = 1.095726\n",
      "INFO:absl:240.736 steps/sec\n",
      "INFO:absl:collect_time = 0.08820676803588867, train_time = 0.11948990821838379\n",
      "INFO:absl:step = 33800, loss = 1.731503\n",
      "INFO:absl:240.693 steps/sec\n",
      "INFO:absl:collect_time = 0.0881502628326416, train_time = 0.1195828914642334\n",
      "INFO:absl:step = 33850, loss = 1.013780\n",
      "INFO:absl:227.400 steps/sec\n",
      "INFO:absl:collect_time = 0.09682607650756836, train_time = 0.12305068969726562\n",
      "INFO:absl:step = 33900, loss = 5.655685\n",
      "INFO:absl:197.672 steps/sec\n",
      "INFO:absl:collect_time = 0.11541104316711426, train_time = 0.13753271102905273\n",
      "INFO:absl:step = 33950, loss = 1.286764\n",
      "INFO:absl:209.939 steps/sec\n",
      "INFO:absl:collect_time = 0.1268770694732666, train_time = 0.11128687858581543\n",
      "INFO:absl:step = 34000, loss = 4.394370\n",
      "INFO:absl:276.892 steps/sec\n",
      "INFO:absl:collect_time = 0.07679510116577148, train_time = 0.10378098487854004\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-34000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-34000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000034000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000034000/assets\n",
      "INFO:absl:step = 34050, loss = 0.396428\n",
      "INFO:absl:286.894 steps/sec\n",
      "INFO:absl:collect_time = 0.07799839973449707, train_time = 0.09628176689147949\n",
      "INFO:absl:step = 34100, loss = 0.199051\n",
      "INFO:absl:264.624 steps/sec\n",
      "INFO:absl:collect_time = 0.07528114318847656, train_time = 0.11366605758666992\n",
      "INFO:absl:step = 34150, loss = 1.924595\n",
      "INFO:absl:235.741 steps/sec\n",
      "INFO:absl:collect_time = 0.0992729663848877, train_time = 0.1128244400024414\n",
      "INFO:absl:step = 34200, loss = 4.167245\n",
      "INFO:absl:206.468 steps/sec\n",
      "INFO:absl:collect_time = 0.09980583190917969, train_time = 0.14236211776733398\n",
      "INFO:absl:step = 34250, loss = 2.801863\n",
      "INFO:absl:232.020 steps/sec\n",
      "INFO:absl:collect_time = 0.10662221908569336, train_time = 0.10887670516967773\n",
      "INFO:absl:step = 34300, loss = 0.731667\n",
      "INFO:absl:235.782 steps/sec\n",
      "INFO:absl:collect_time = 0.10233330726623535, train_time = 0.1097266674041748\n",
      "INFO:absl:step = 34350, loss = 3.191456\n",
      "INFO:absl:261.820 steps/sec\n",
      "INFO:absl:collect_time = 0.09452986717224121, train_time = 0.09644126892089844\n",
      "INFO:absl:step = 34400, loss = 0.817007\n",
      "INFO:absl:257.962 steps/sec\n",
      "INFO:absl:collect_time = 0.08940267562866211, train_time = 0.10442423820495605\n",
      "INFO:absl:step = 34450, loss = 0.523140\n",
      "INFO:absl:233.134 steps/sec\n",
      "INFO:absl:collect_time = 0.09555196762084961, train_time = 0.11891722679138184\n",
      "INFO:absl:step = 34500, loss = 1.069447\n",
      "INFO:absl:201.701 steps/sec\n",
      "INFO:absl:collect_time = 0.13388991355895996, train_time = 0.11400222778320312\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-34500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-34500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000034500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000034500/assets\n",
      "INFO:absl:step = 34550, loss = 1.171617\n",
      "INFO:absl:221.814 steps/sec\n",
      "INFO:absl:collect_time = 0.0966801643371582, train_time = 0.12873363494873047\n",
      "INFO:absl:step = 34600, loss = 2.108478\n",
      "INFO:absl:244.299 steps/sec\n",
      "INFO:absl:collect_time = 0.1005702018737793, train_time = 0.10409688949584961\n",
      "INFO:absl:step = 34650, loss = 0.966168\n",
      "INFO:absl:290.604 steps/sec\n",
      "INFO:absl:collect_time = 0.07935500144958496, train_time = 0.09270071983337402\n",
      "INFO:absl:step = 34700, loss = 3.244466\n",
      "INFO:absl:252.825 steps/sec\n",
      "INFO:absl:collect_time = 0.09168386459350586, train_time = 0.10608124732971191\n",
      "INFO:absl:step = 34750, loss = 0.495699\n",
      "INFO:absl:225.362 steps/sec\n",
      "INFO:absl:collect_time = 0.10927677154541016, train_time = 0.11258888244628906\n",
      "INFO:absl:step = 34800, loss = 0.346429\n",
      "INFO:absl:246.652 steps/sec\n",
      "INFO:absl:collect_time = 0.09988212585449219, train_time = 0.10283303260803223\n",
      "INFO:absl:step = 34850, loss = 3.678516\n",
      "INFO:absl:234.201 steps/sec\n",
      "INFO:absl:collect_time = 0.09568452835083008, train_time = 0.11780714988708496\n",
      "INFO:absl:step = 34900, loss = 4.463328\n",
      "INFO:absl:184.179 steps/sec\n",
      "INFO:absl:collect_time = 0.13573646545410156, train_time = 0.13573813438415527\n",
      "INFO:absl:step = 34950, loss = 1.141935\n",
      "INFO:absl:238.685 steps/sec\n",
      "INFO:absl:collect_time = 0.1088860034942627, train_time = 0.10059499740600586\n",
      "INFO:absl:step = 35000, loss = 0.716866\n",
      "INFO:absl:253.310 steps/sec\n",
      "INFO:absl:collect_time = 0.0922551155090332, train_time = 0.10513114929199219\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-35000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-35000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000035000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000035000/assets\n",
      "INFO:absl:step = 35050, loss = 1.490644\n",
      "INFO:absl:242.735 steps/sec\n",
      "INFO:absl:collect_time = 0.08630013465881348, train_time = 0.11968612670898438\n",
      "INFO:absl:step = 35100, loss = 0.466728\n",
      "INFO:absl:240.682 steps/sec\n",
      "INFO:absl:collect_time = 0.09090805053710938, train_time = 0.11683487892150879\n",
      "INFO:absl:step = 35150, loss = 2.058692\n",
      "INFO:absl:260.737 steps/sec\n",
      "INFO:absl:collect_time = 0.08952045440673828, train_time = 0.10224390029907227\n",
      "INFO:absl:step = 35200, loss = 1.181963\n",
      "INFO:absl:262.889 steps/sec\n",
      "INFO:absl:collect_time = 0.0864405632019043, train_time = 0.10375404357910156\n",
      "INFO:absl:step = 35250, loss = 0.543122\n",
      "INFO:absl:256.623 steps/sec\n",
      "INFO:absl:collect_time = 0.09139299392700195, train_time = 0.10344529151916504\n",
      "INFO:absl:step = 35300, loss = 0.130337\n",
      "INFO:absl:282.628 steps/sec\n",
      "INFO:absl:collect_time = 0.08133101463317871, train_time = 0.09557986259460449\n",
      "INFO:absl:step = 35350, loss = 0.746095\n",
      "INFO:absl:272.773 steps/sec\n",
      "INFO:absl:collect_time = 0.08950114250183105, train_time = 0.09380173683166504\n",
      "INFO:absl:step = 35400, loss = 1.939538\n",
      "INFO:absl:264.352 steps/sec\n",
      "INFO:absl:collect_time = 0.0857398509979248, train_time = 0.10340213775634766\n",
      "INFO:absl:step = 35450, loss = 2.189709\n",
      "INFO:absl:277.155 steps/sec\n",
      "INFO:absl:collect_time = 0.08313822746276855, train_time = 0.09726595878601074\n",
      "INFO:absl:step = 35500, loss = 1.589354\n",
      "INFO:absl:251.380 steps/sec\n",
      "INFO:absl:collect_time = 0.09581708908081055, train_time = 0.10308504104614258\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-35500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-35500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000035500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000035500/assets\n",
      "INFO:absl:step = 35550, loss = 1.368705\n",
      "INFO:absl:258.773 steps/sec\n",
      "INFO:absl:collect_time = 0.08989930152893066, train_time = 0.10332012176513672\n",
      "INFO:absl:step = 35600, loss = 6.075073\n",
      "INFO:absl:234.287 steps/sec\n",
      "INFO:absl:collect_time = 0.09320330619812012, train_time = 0.12021017074584961\n",
      "INFO:absl:step = 35650, loss = 7.673312\n",
      "INFO:absl:213.058 steps/sec\n",
      "INFO:absl:collect_time = 0.10325336456298828, train_time = 0.1314249038696289\n",
      "INFO:absl:step = 35700, loss = 1.707029\n",
      "INFO:absl:212.561 steps/sec\n",
      "INFO:absl:collect_time = 0.1124422550201416, train_time = 0.12278461456298828\n",
      "INFO:absl:step = 35750, loss = 1.259003\n",
      "INFO:absl:219.275 steps/sec\n",
      "INFO:absl:collect_time = 0.09997844696044922, train_time = 0.12804603576660156\n",
      "INFO:absl:step = 35800, loss = 0.996759\n",
      "INFO:absl:273.873 steps/sec\n",
      "INFO:absl:collect_time = 0.0878748893737793, train_time = 0.09469175338745117\n",
      "INFO:absl:step = 35850, loss = 1.551109\n",
      "INFO:absl:279.526 steps/sec\n",
      "INFO:absl:collect_time = 0.08119535446166992, train_time = 0.09767866134643555\n",
      "INFO:absl:step = 35900, loss = 0.567818\n",
      "INFO:absl:248.705 steps/sec\n",
      "INFO:absl:collect_time = 0.09684491157531738, train_time = 0.10419678688049316\n",
      "INFO:absl:step = 35950, loss = 1.160244\n",
      "INFO:absl:248.756 steps/sec\n",
      "INFO:absl:collect_time = 0.09278512001037598, train_time = 0.1082150936126709\n",
      "INFO:absl:step = 36000, loss = 2.829767\n",
      "INFO:absl:261.408 steps/sec\n",
      "INFO:absl:collect_time = 0.08987212181091309, train_time = 0.10139989852905273\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-36000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-36000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000036000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000036000/assets\n",
      "INFO:absl:step = 36050, loss = 1.850601\n",
      "INFO:absl:251.011 steps/sec\n",
      "INFO:absl:collect_time = 0.08333182334899902, train_time = 0.11586284637451172\n",
      "INFO:absl:step = 36100, loss = 0.407940\n",
      "INFO:absl:174.885 steps/sec\n",
      "INFO:absl:collect_time = 0.13950800895690918, train_time = 0.1463940143585205\n",
      "INFO:absl:step = 36150, loss = 4.397059\n",
      "INFO:absl:229.775 steps/sec\n",
      "INFO:absl:collect_time = 0.10614824295043945, train_time = 0.11145591735839844\n",
      "INFO:absl:step = 36200, loss = 1.414541\n",
      "INFO:absl:252.686 steps/sec\n",
      "INFO:absl:collect_time = 0.0915679931640625, train_time = 0.10630607604980469\n",
      "INFO:absl:step = 36250, loss = 16.056690\n",
      "INFO:absl:231.357 steps/sec\n",
      "INFO:absl:collect_time = 0.09676814079284668, train_time = 0.11934804916381836\n",
      "INFO:absl:step = 36300, loss = 0.743653\n",
      "INFO:absl:258.411 steps/sec\n",
      "INFO:absl:collect_time = 0.08725500106811523, train_time = 0.10623502731323242\n",
      "INFO:absl:step = 36350, loss = 2.154166\n",
      "INFO:absl:269.076 steps/sec\n",
      "INFO:absl:collect_time = 0.08451604843139648, train_time = 0.10130524635314941\n",
      "INFO:absl:step = 36400, loss = 0.956194\n",
      "INFO:absl:253.147 steps/sec\n",
      "INFO:absl:collect_time = 0.09762287139892578, train_time = 0.09989094734191895\n",
      "INFO:absl:step = 36450, loss = 2.065875\n",
      "INFO:absl:234.993 steps/sec\n",
      "INFO:absl:collect_time = 0.10399413108825684, train_time = 0.10877799987792969\n",
      "INFO:absl:step = 36500, loss = 0.532679\n",
      "INFO:absl:250.214 steps/sec\n",
      "INFO:absl:collect_time = 0.0879366397857666, train_time = 0.1118922233581543\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-36500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-36500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000036500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000036500/assets\n",
      "INFO:absl:step = 36550, loss = 4.648633\n",
      "INFO:absl:284.842 steps/sec\n",
      "INFO:absl:collect_time = 0.07350683212280273, train_time = 0.10202884674072266\n",
      "INFO:absl:step = 36600, loss = 2.351145\n",
      "INFO:absl:266.894 steps/sec\n",
      "INFO:absl:collect_time = 0.08963823318481445, train_time = 0.0977020263671875\n",
      "INFO:absl:step = 36650, loss = 2.190078\n",
      "INFO:absl:263.816 steps/sec\n",
      "INFO:absl:collect_time = 0.09280109405517578, train_time = 0.0967249870300293\n",
      "INFO:absl:step = 36700, loss = 1.442540\n",
      "INFO:absl:249.475 steps/sec\n",
      "INFO:absl:collect_time = 0.09654974937438965, train_time = 0.10387110710144043\n",
      "INFO:absl:step = 36750, loss = 0.965823\n",
      "INFO:absl:288.947 steps/sec\n",
      "INFO:absl:collect_time = 0.07859992980957031, train_time = 0.09444189071655273\n",
      "INFO:absl:step = 36800, loss = 2.155527\n",
      "INFO:absl:251.694 steps/sec\n",
      "INFO:absl:collect_time = 0.0913538932800293, train_time = 0.1073000431060791\n",
      "INFO:absl:step = 36850, loss = 0.701557\n",
      "INFO:absl:268.995 steps/sec\n",
      "INFO:absl:collect_time = 0.07482266426086426, train_time = 0.1110541820526123\n",
      "INFO:absl:step = 36900, loss = 2.308671\n",
      "INFO:absl:249.979 steps/sec\n",
      "INFO:absl:collect_time = 0.09170651435852051, train_time = 0.10830998420715332\n",
      "INFO:absl:step = 36950, loss = 5.990013\n",
      "INFO:absl:254.314 steps/sec\n",
      "INFO:absl:collect_time = 0.09575319290161133, train_time = 0.10085391998291016\n",
      "INFO:absl:step = 37000, loss = 0.629138\n",
      "INFO:absl:278.578 steps/sec\n",
      "INFO:absl:collect_time = 0.07656407356262207, train_time = 0.10291910171508789\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-37000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-37000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000037000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000037000/assets\n",
      "INFO:absl:step = 37050, loss = 1.071191\n",
      "INFO:absl:243.078 steps/sec\n",
      "INFO:absl:collect_time = 0.08958578109741211, train_time = 0.11610960960388184\n",
      "INFO:absl:step = 37100, loss = 1.173108\n",
      "INFO:absl:173.064 steps/sec\n",
      "INFO:absl:collect_time = 0.1251671314239502, train_time = 0.1637427806854248\n",
      "INFO:absl:step = 37150, loss = 0.654155\n",
      "INFO:absl:231.289 steps/sec\n",
      "INFO:absl:collect_time = 0.09881782531738281, train_time = 0.11736226081848145\n",
      "INFO:absl:step = 37200, loss = 0.735436\n",
      "INFO:absl:224.398 steps/sec\n",
      "INFO:absl:collect_time = 0.10135507583618164, train_time = 0.12146377563476562\n",
      "INFO:absl:step = 37250, loss = 0.513879\n",
      "INFO:absl:276.960 steps/sec\n",
      "INFO:absl:collect_time = 0.07997441291809082, train_time = 0.10055685043334961\n",
      "INFO:absl:step = 37300, loss = 0.782167\n",
      "INFO:absl:206.111 steps/sec\n",
      "INFO:absl:collect_time = 0.1162269115447998, train_time = 0.12636113166809082\n",
      "INFO:absl:step = 37350, loss = 3.216467\n",
      "INFO:absl:231.986 steps/sec\n",
      "INFO:absl:collect_time = 0.09364914894104004, train_time = 0.12188100814819336\n",
      "INFO:absl:step = 37400, loss = 2.031735\n",
      "INFO:absl:257.868 steps/sec\n",
      "INFO:absl:collect_time = 0.09484386444091797, train_time = 0.09905385971069336\n",
      "INFO:absl:step = 37450, loss = 0.988378\n",
      "INFO:absl:270.522 steps/sec\n",
      "INFO:absl:collect_time = 0.08394908905029297, train_time = 0.10087871551513672\n",
      "INFO:absl:step = 37500, loss = 6.611319\n",
      "INFO:absl:289.209 steps/sec\n",
      "INFO:absl:collect_time = 0.07756423950195312, train_time = 0.0953209400177002\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-37500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-37500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000037500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000037500/assets\n",
      "INFO:absl:step = 37550, loss = 1.675645\n",
      "INFO:absl:216.198 steps/sec\n",
      "INFO:absl:collect_time = 0.10341572761535645, train_time = 0.1278536319732666\n",
      "INFO:absl:step = 37600, loss = 1.898650\n",
      "INFO:absl:236.362 steps/sec\n",
      "INFO:absl:collect_time = 0.09566712379455566, train_time = 0.11587309837341309\n",
      "INFO:absl:step = 37650, loss = 1.311205\n",
      "INFO:absl:291.209 steps/sec\n",
      "INFO:absl:collect_time = 0.08080482482910156, train_time = 0.09089303016662598\n",
      "INFO:absl:step = 37700, loss = 0.832676\n",
      "INFO:absl:251.806 steps/sec\n",
      "INFO:absl:collect_time = 0.09399247169494629, train_time = 0.10457301139831543\n",
      "INFO:absl:step = 37750, loss = 1.387591\n",
      "INFO:absl:227.194 steps/sec\n",
      "INFO:absl:collect_time = 0.09772014617919922, train_time = 0.12235593795776367\n",
      "INFO:absl:step = 37800, loss = 2.446346\n",
      "INFO:absl:272.191 steps/sec\n",
      "INFO:absl:collect_time = 0.08569884300231934, train_time = 0.09799599647521973\n",
      "INFO:absl:step = 37850, loss = 1.925425\n",
      "INFO:absl:219.509 steps/sec\n",
      "INFO:absl:collect_time = 0.09863114356994629, train_time = 0.1291499137878418\n",
      "INFO:absl:step = 37900, loss = 0.454854\n",
      "INFO:absl:179.909 steps/sec\n",
      "INFO:absl:collect_time = 0.1578223705291748, train_time = 0.12009572982788086\n",
      "INFO:absl:step = 37950, loss = 0.759494\n",
      "INFO:absl:285.610 steps/sec\n",
      "INFO:absl:collect_time = 0.08254265785217285, train_time = 0.09252095222473145\n",
      "INFO:absl:step = 38000, loss = 0.415628\n",
      "INFO:absl:264.832 steps/sec\n",
      "INFO:absl:collect_time = 0.09203004837036133, train_time = 0.09676885604858398\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-38000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-38000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000038000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000038000/assets\n",
      "INFO:absl:step = 38050, loss = 0.933312\n",
      "INFO:absl:278.232 steps/sec\n",
      "INFO:absl:collect_time = 0.07887959480285645, train_time = 0.10082626342773438\n",
      "INFO:absl:step = 38100, loss = 0.847768\n",
      "INFO:absl:239.412 steps/sec\n",
      "INFO:absl:collect_time = 0.10166501998901367, train_time = 0.10717964172363281\n",
      "INFO:absl:step = 38150, loss = 1.064269\n",
      "INFO:absl:250.083 steps/sec\n",
      "INFO:absl:collect_time = 0.09068894386291504, train_time = 0.10924434661865234\n",
      "INFO:absl:step = 38200, loss = 2.797059\n",
      "INFO:absl:217.960 steps/sec\n",
      "INFO:absl:collect_time = 0.09288573265075684, train_time = 0.13651418685913086\n",
      "INFO:absl:step = 38250, loss = 1.040124\n",
      "INFO:absl:294.341 steps/sec\n",
      "INFO:absl:collect_time = 0.0772249698638916, train_time = 0.09264612197875977\n",
      "INFO:absl:step = 38300, loss = 5.056213\n",
      "INFO:absl:245.249 steps/sec\n",
      "INFO:absl:collect_time = 0.09043455123901367, train_time = 0.11343979835510254\n",
      "INFO:absl:step = 38350, loss = 0.835830\n",
      "INFO:absl:291.562 steps/sec\n",
      "INFO:absl:collect_time = 0.07673382759094238, train_time = 0.0947561264038086\n",
      "INFO:absl:step = 38400, loss = 2.128470\n",
      "INFO:absl:201.097 steps/sec\n",
      "INFO:absl:collect_time = 0.11165785789489746, train_time = 0.1369783878326416\n",
      "INFO:absl:step = 38450, loss = 2.403973\n",
      "INFO:absl:249.785 steps/sec\n",
      "INFO:absl:collect_time = 0.09551692008972168, train_time = 0.10465526580810547\n",
      "INFO:absl:step = 38500, loss = 1.343858\n",
      "INFO:absl:245.372 steps/sec\n",
      "INFO:absl:collect_time = 0.1047813892364502, train_time = 0.09899091720581055\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-38500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-38500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000038500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000038500/assets\n",
      "INFO:absl:step = 38550, loss = 1.430433\n",
      "INFO:absl:283.586 steps/sec\n",
      "INFO:absl:collect_time = 0.07352805137634277, train_time = 0.10278511047363281\n",
      "INFO:absl:step = 38600, loss = 2.853502\n",
      "INFO:absl:240.032 steps/sec\n",
      "INFO:absl:collect_time = 0.08947372436523438, train_time = 0.11883163452148438\n",
      "INFO:absl:step = 38650, loss = 0.384708\n",
      "INFO:absl:161.051 steps/sec\n",
      "INFO:absl:collect_time = 0.13736510276794434, train_time = 0.1730959415435791\n",
      "INFO:absl:step = 38700, loss = 10.464804\n",
      "INFO:absl:127.145 steps/sec\n",
      "INFO:absl:collect_time = 0.2258462905883789, train_time = 0.1674048900604248\n",
      "INFO:absl:step = 38750, loss = 0.934846\n",
      "INFO:absl:244.920 steps/sec\n",
      "INFO:absl:collect_time = 0.10315322875976562, train_time = 0.10099530220031738\n",
      "INFO:absl:step = 38800, loss = 0.691305\n",
      "INFO:absl:227.056 steps/sec\n",
      "INFO:absl:collect_time = 0.09345793724060059, train_time = 0.12675189971923828\n",
      "INFO:absl:step = 38850, loss = 3.831112\n",
      "INFO:absl:238.826 steps/sec\n",
      "INFO:absl:collect_time = 0.10396122932434082, train_time = 0.10539603233337402\n",
      "INFO:absl:step = 38900, loss = 1.415520\n",
      "INFO:absl:232.493 steps/sec\n",
      "INFO:absl:collect_time = 0.10938596725463867, train_time = 0.10567402839660645\n",
      "INFO:absl:step = 38950, loss = 1.245686\n",
      "INFO:absl:309.362 steps/sec\n",
      "INFO:absl:collect_time = 0.07499575614929199, train_time = 0.08662724494934082\n",
      "INFO:absl:step = 39000, loss = 1.410477\n",
      "INFO:absl:240.497 steps/sec\n",
      "INFO:absl:collect_time = 0.08853816986083984, train_time = 0.11936497688293457\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-39000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-39000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000039000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000039000/assets\n",
      "INFO:absl:step = 39050, loss = 1.004665\n",
      "INFO:absl:238.489 steps/sec\n",
      "INFO:absl:collect_time = 0.10400724411010742, train_time = 0.10564589500427246\n",
      "INFO:absl:step = 39100, loss = 4.797210\n",
      "INFO:absl:265.040 steps/sec\n",
      "INFO:absl:collect_time = 0.08745479583740234, train_time = 0.1011960506439209\n",
      "INFO:absl:step = 39150, loss = 2.797630\n",
      "INFO:absl:271.602 steps/sec\n",
      "INFO:absl:collect_time = 0.08649873733520508, train_time = 0.09759402275085449\n",
      "INFO:absl:step = 39200, loss = 1.394187\n",
      "INFO:absl:261.184 steps/sec\n",
      "INFO:absl:collect_time = 0.0935208797454834, train_time = 0.0979151725769043\n",
      "INFO:absl:step = 39250, loss = 1.452845\n",
      "INFO:absl:245.471 steps/sec\n",
      "INFO:absl:collect_time = 0.10929083824157715, train_time = 0.09439897537231445\n",
      "INFO:absl:step = 39300, loss = 6.774278\n",
      "INFO:absl:276.290 steps/sec\n",
      "INFO:absl:collect_time = 0.08175015449523926, train_time = 0.09921884536743164\n",
      "INFO:absl:step = 39350, loss = 3.560363\n",
      "INFO:absl:258.748 steps/sec\n",
      "INFO:absl:collect_time = 0.09094929695129395, train_time = 0.10228896141052246\n",
      "INFO:absl:step = 39400, loss = 1.336229\n",
      "INFO:absl:262.656 steps/sec\n",
      "INFO:absl:collect_time = 0.08986186981201172, train_time = 0.10050153732299805\n",
      "INFO:absl:step = 39450, loss = 1.541018\n",
      "INFO:absl:235.084 steps/sec\n",
      "INFO:absl:collect_time = 0.10505318641662598, train_time = 0.10763669013977051\n",
      "INFO:absl:step = 39500, loss = 1.395596\n",
      "INFO:absl:241.364 steps/sec\n",
      "INFO:absl:collect_time = 0.09540271759033203, train_time = 0.11175298690795898\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-39500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-39500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000039500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000039500/assets\n",
      "INFO:absl:step = 39550, loss = 1.095227\n",
      "INFO:absl:239.970 steps/sec\n",
      "INFO:absl:collect_time = 0.09378194808959961, train_time = 0.1145777702331543\n",
      "INFO:absl:step = 39600, loss = 3.105994\n",
      "INFO:absl:255.002 steps/sec\n",
      "INFO:absl:collect_time = 0.09366917610168457, train_time = 0.10240793228149414\n",
      "INFO:absl:step = 39650, loss = 0.778284\n",
      "INFO:absl:266.780 steps/sec\n",
      "INFO:absl:collect_time = 0.09293794631958008, train_time = 0.094482421875\n",
      "INFO:absl:step = 39700, loss = 0.678014\n",
      "INFO:absl:277.750 steps/sec\n",
      "INFO:absl:collect_time = 0.09238100051879883, train_time = 0.08763694763183594\n",
      "INFO:absl:step = 39750, loss = 1.073202\n",
      "INFO:absl:230.785 steps/sec\n",
      "INFO:absl:collect_time = 0.10317516326904297, train_time = 0.11347699165344238\n",
      "INFO:absl:step = 39800, loss = 0.313932\n",
      "INFO:absl:330.223 steps/sec\n",
      "INFO:absl:collect_time = 0.06897091865539551, train_time = 0.08244204521179199\n",
      "INFO:absl:step = 39850, loss = 2.611412\n",
      "INFO:absl:263.147 steps/sec\n",
      "INFO:absl:collect_time = 0.09215211868286133, train_time = 0.09785604476928711\n",
      "INFO:absl:step = 39900, loss = 1.948837\n",
      "INFO:absl:271.005 steps/sec\n",
      "INFO:absl:collect_time = 0.08722448348999023, train_time = 0.0972740650177002\n",
      "INFO:absl:step = 39950, loss = 3.633167\n",
      "INFO:absl:255.760 steps/sec\n",
      "INFO:absl:collect_time = 0.092559814453125, train_time = 0.1029360294342041\n",
      "INFO:absl:step = 40000, loss = 0.927671\n",
      "INFO:absl:258.578 steps/sec\n",
      "INFO:absl:collect_time = 0.08924174308776855, train_time = 0.10412383079528809\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-40000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-40000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000040000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000040000/assets\n",
      "INFO:absl:step = 40050, loss = 0.880053\n",
      "INFO:absl:245.394 steps/sec\n",
      "INFO:absl:collect_time = 0.09202384948730469, train_time = 0.11173009872436523\n",
      "INFO:absl:step = 40100, loss = 0.336147\n",
      "INFO:absl:286.262 steps/sec\n",
      "INFO:absl:collect_time = 0.0765533447265625, train_time = 0.09811186790466309\n",
      "INFO:absl:step = 40150, loss = 2.165032\n",
      "INFO:absl:214.952 steps/sec\n",
      "INFO:absl:collect_time = 0.10695576667785645, train_time = 0.12565398216247559\n",
      "INFO:absl:step = 40200, loss = 4.183830\n",
      "INFO:absl:265.417 steps/sec\n",
      "INFO:absl:collect_time = 0.08863997459411621, train_time = 0.09974288940429688\n",
      "INFO:absl:step = 40250, loss = 1.691617\n",
      "INFO:absl:224.220 steps/sec\n",
      "INFO:absl:collect_time = 0.1043088436126709, train_time = 0.11868596076965332\n",
      "INFO:absl:step = 40300, loss = 1.368943\n",
      "INFO:absl:214.041 steps/sec\n",
      "INFO:absl:collect_time = 0.08572983741760254, train_time = 0.14787006378173828\n",
      "INFO:absl:step = 40350, loss = 0.824251\n",
      "INFO:absl:236.695 steps/sec\n",
      "INFO:absl:collect_time = 0.09886884689331055, train_time = 0.11237311363220215\n",
      "INFO:absl:step = 40400, loss = 0.437736\n",
      "INFO:absl:295.356 steps/sec\n",
      "INFO:absl:collect_time = 0.07314610481262207, train_time = 0.09614086151123047\n",
      "INFO:absl:step = 40450, loss = 1.254504\n",
      "INFO:absl:241.607 steps/sec\n",
      "INFO:absl:collect_time = 0.09483003616333008, train_time = 0.11211729049682617\n",
      "INFO:absl:step = 40500, loss = 3.379341\n",
      "INFO:absl:272.413 steps/sec\n",
      "INFO:absl:collect_time = 0.08662891387939453, train_time = 0.09691596031188965\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-40500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-40500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000040500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000040500/assets\n",
      "INFO:absl:step = 40550, loss = 1.954580\n",
      "INFO:absl:239.920 steps/sec\n",
      "INFO:absl:collect_time = 0.09152436256408691, train_time = 0.11687874794006348\n",
      "INFO:absl:step = 40600, loss = 4.067834\n",
      "INFO:absl:254.165 steps/sec\n",
      "INFO:absl:collect_time = 0.09283828735351562, train_time = 0.10388398170471191\n",
      "INFO:absl:step = 40650, loss = 11.431011\n",
      "INFO:absl:235.388 steps/sec\n",
      "INFO:absl:collect_time = 0.10564327239990234, train_time = 0.10677242279052734\n",
      "INFO:absl:step = 40700, loss = 0.621280\n",
      "INFO:absl:243.189 steps/sec\n",
      "INFO:absl:collect_time = 0.0987858772277832, train_time = 0.10681533813476562\n",
      "INFO:absl:step = 40750, loss = 2.799237\n",
      "INFO:absl:250.028 steps/sec\n",
      "INFO:absl:collect_time = 0.08781909942626953, train_time = 0.11215877532958984\n",
      "INFO:absl:step = 40800, loss = 1.605796\n",
      "INFO:absl:285.683 steps/sec\n",
      "INFO:absl:collect_time = 0.07778167724609375, train_time = 0.09723734855651855\n",
      "INFO:absl:step = 40850, loss = 1.113110\n",
      "INFO:absl:227.342 steps/sec\n",
      "INFO:absl:collect_time = 0.10650420188903809, train_time = 0.11342883110046387\n",
      "INFO:absl:step = 40900, loss = 0.812173\n",
      "INFO:absl:247.173 steps/sec\n",
      "INFO:absl:collect_time = 0.10258722305297852, train_time = 0.0996999740600586\n",
      "INFO:absl:step = 40950, loss = 2.519263\n",
      "INFO:absl:268.791 steps/sec\n",
      "INFO:absl:collect_time = 0.08711504936218262, train_time = 0.09890341758728027\n",
      "INFO:absl:step = 41000, loss = 1.109085\n",
      "INFO:absl:253.546 steps/sec\n",
      "INFO:absl:collect_time = 0.09594488143920898, train_time = 0.1012580394744873\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-41000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-41000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000041000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000041000/assets\n",
      "INFO:absl:step = 41050, loss = 3.579572\n",
      "INFO:absl:257.538 steps/sec\n",
      "INFO:absl:collect_time = 0.08667302131652832, train_time = 0.10747313499450684\n",
      "INFO:absl:step = 41100, loss = 1.309279\n",
      "INFO:absl:256.198 steps/sec\n",
      "INFO:absl:collect_time = 0.09236621856689453, train_time = 0.10279512405395508\n",
      "INFO:absl:step = 41150, loss = 3.685194\n",
      "INFO:absl:226.725 steps/sec\n",
      "INFO:absl:collect_time = 0.10482597351074219, train_time = 0.11570596694946289\n",
      "INFO:absl:step = 41200, loss = 0.685019\n",
      "INFO:absl:223.036 steps/sec\n",
      "INFO:absl:collect_time = 0.11249208450317383, train_time = 0.11168694496154785\n",
      "INFO:absl:step = 41250, loss = 0.543510\n",
      "INFO:absl:228.626 steps/sec\n",
      "INFO:absl:collect_time = 0.10290884971618652, train_time = 0.11578917503356934\n",
      "INFO:absl:step = 41300, loss = 2.433960\n",
      "INFO:absl:248.452 steps/sec\n",
      "INFO:absl:collect_time = 0.09869027137756348, train_time = 0.10255599021911621\n",
      "INFO:absl:step = 41350, loss = 5.535176\n",
      "INFO:absl:215.673 steps/sec\n",
      "INFO:absl:collect_time = 0.1147148609161377, train_time = 0.11711788177490234\n",
      "INFO:absl:step = 41400, loss = 3.292445\n",
      "INFO:absl:194.730 steps/sec\n",
      "INFO:absl:collect_time = 0.09888887405395508, train_time = 0.15787672996520996\n",
      "INFO:absl:step = 41450, loss = 8.304709\n",
      "INFO:absl:240.728 steps/sec\n",
      "INFO:absl:collect_time = 0.0993490219116211, train_time = 0.10835409164428711\n",
      "INFO:absl:step = 41500, loss = 3.896521\n",
      "INFO:absl:209.838 steps/sec\n",
      "INFO:absl:collect_time = 0.11042499542236328, train_time = 0.127854585647583\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-41500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-41500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000041500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000041500/assets\n",
      "INFO:absl:step = 41550, loss = 0.530079\n",
      "INFO:absl:240.818 steps/sec\n",
      "INFO:absl:collect_time = 0.10121273994445801, train_time = 0.10641336441040039\n",
      "INFO:absl:step = 41600, loss = 0.762750\n",
      "INFO:absl:285.936 steps/sec\n",
      "INFO:absl:collect_time = 0.077545166015625, train_time = 0.09731888771057129\n",
      "INFO:absl:step = 41650, loss = 1.616031\n",
      "INFO:absl:249.992 steps/sec\n",
      "INFO:absl:collect_time = 0.09372782707214355, train_time = 0.10627865791320801\n",
      "INFO:absl:step = 41700, loss = 0.627024\n",
      "INFO:absl:235.955 steps/sec\n",
      "INFO:absl:collect_time = 0.10397791862487793, train_time = 0.10792708396911621\n",
      "INFO:absl:step = 41750, loss = 0.745157\n",
      "INFO:absl:198.608 steps/sec\n",
      "INFO:absl:collect_time = 0.13353180885314941, train_time = 0.11822080612182617\n",
      "INFO:absl:step = 41800, loss = 2.072354\n",
      "INFO:absl:213.636 steps/sec\n",
      "INFO:absl:collect_time = 0.11831927299499512, train_time = 0.11572384834289551\n",
      "INFO:absl:step = 41850, loss = 2.892146\n",
      "INFO:absl:247.218 steps/sec\n",
      "INFO:absl:collect_time = 0.09983468055725098, train_time = 0.10241556167602539\n",
      "INFO:absl:step = 41900, loss = 5.808561\n",
      "INFO:absl:223.784 steps/sec\n",
      "INFO:absl:collect_time = 0.11145281791687012, train_time = 0.11197710037231445\n",
      "INFO:absl:step = 41950, loss = 2.974343\n",
      "INFO:absl:222.331 steps/sec\n",
      "INFO:absl:collect_time = 0.11787295341491699, train_time = 0.10701704025268555\n",
      "INFO:absl:step = 42000, loss = 0.714763\n",
      "INFO:absl:224.816 steps/sec\n",
      "INFO:absl:collect_time = 0.10319685935974121, train_time = 0.11920714378356934\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-42000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-42000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000042000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000042000/assets\n",
      "INFO:absl:step = 42050, loss = 1.835827\n",
      "INFO:absl:175.419 steps/sec\n",
      "INFO:absl:collect_time = 0.11735105514526367, train_time = 0.16768097877502441\n",
      "INFO:absl:step = 42100, loss = 1.360408\n",
      "INFO:absl:262.288 steps/sec\n",
      "INFO:absl:collect_time = 0.07732415199279785, train_time = 0.11330604553222656\n",
      "INFO:absl:step = 42150, loss = 0.555300\n",
      "INFO:absl:225.274 steps/sec\n",
      "INFO:absl:collect_time = 0.11328291893005371, train_time = 0.10866904258728027\n",
      "INFO:absl:step = 42200, loss = 0.906540\n",
      "INFO:absl:244.035 steps/sec\n",
      "INFO:absl:collect_time = 0.09851884841918945, train_time = 0.1063694953918457\n",
      "INFO:absl:step = 42250, loss = 2.048461\n",
      "INFO:absl:172.924 steps/sec\n",
      "INFO:absl:collect_time = 0.12950682640075684, train_time = 0.1596376895904541\n",
      "INFO:absl:step = 42300, loss = 1.710151\n",
      "INFO:absl:238.213 steps/sec\n",
      "INFO:absl:collect_time = 0.08544325828552246, train_time = 0.12445306777954102\n",
      "INFO:absl:step = 42350, loss = 0.909479\n",
      "INFO:absl:260.379 steps/sec\n",
      "INFO:absl:collect_time = 0.08466196060180664, train_time = 0.10736608505249023\n",
      "INFO:absl:step = 42400, loss = 0.668000\n",
      "INFO:absl:205.404 steps/sec\n",
      "INFO:absl:collect_time = 0.1481943130493164, train_time = 0.09522795677185059\n",
      "INFO:absl:step = 42450, loss = 1.668454\n",
      "INFO:absl:247.052 steps/sec\n",
      "INFO:absl:collect_time = 0.09388923645019531, train_time = 0.10849714279174805\n",
      "INFO:absl:step = 42500, loss = 0.458191\n",
      "INFO:absl:238.990 steps/sec\n",
      "INFO:absl:collect_time = 0.08785891532897949, train_time = 0.12135529518127441\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-42500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-42500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000042500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000042500/assets\n",
      "INFO:absl:step = 42550, loss = 0.571647\n",
      "INFO:absl:222.468 steps/sec\n",
      "INFO:absl:collect_time = 0.10216689109802246, train_time = 0.12258481979370117\n",
      "INFO:absl:step = 42600, loss = 1.472187\n",
      "INFO:absl:216.412 steps/sec\n",
      "INFO:absl:collect_time = 0.1147451400756836, train_time = 0.11629533767700195\n",
      "INFO:absl:step = 42650, loss = 2.424568\n",
      "INFO:absl:273.562 steps/sec\n",
      "INFO:absl:collect_time = 0.08893680572509766, train_time = 0.09383726119995117\n",
      "INFO:absl:step = 42700, loss = 0.608042\n",
      "INFO:absl:174.086 steps/sec\n",
      "INFO:absl:collect_time = 0.13883495330810547, train_time = 0.14837908744812012\n",
      "INFO:absl:step = 42750, loss = 0.884667\n",
      "INFO:absl:235.498 steps/sec\n",
      "INFO:absl:collect_time = 0.1034700870513916, train_time = 0.10884618759155273\n",
      "INFO:absl:step = 42800, loss = 1.375546\n",
      "INFO:absl:257.394 steps/sec\n",
      "INFO:absl:collect_time = 0.09474515914916992, train_time = 0.09950947761535645\n",
      "INFO:absl:step = 42850, loss = 6.579996\n",
      "INFO:absl:212.181 steps/sec\n",
      "INFO:absl:collect_time = 0.10813760757446289, train_time = 0.12750983238220215\n",
      "INFO:absl:step = 42900, loss = 2.932414\n",
      "INFO:absl:239.757 steps/sec\n",
      "INFO:absl:collect_time = 0.09253573417663574, train_time = 0.11600899696350098\n",
      "INFO:absl:step = 42950, loss = 1.227472\n",
      "INFO:absl:154.026 steps/sec\n",
      "INFO:absl:collect_time = 0.15155887603759766, train_time = 0.17306113243103027\n",
      "INFO:absl:step = 43000, loss = 2.593775\n",
      "INFO:absl:221.349 steps/sec\n",
      "INFO:absl:collect_time = 0.10398101806640625, train_time = 0.12190699577331543\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-43000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-43000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000043000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000043000/assets\n",
      "INFO:absl:step = 43050, loss = 0.700653\n",
      "INFO:absl:239.806 steps/sec\n",
      "INFO:absl:collect_time = 0.10036492347717285, train_time = 0.10813713073730469\n",
      "INFO:absl:step = 43100, loss = 3.010526\n",
      "INFO:absl:240.381 steps/sec\n",
      "INFO:absl:collect_time = 0.09621858596801758, train_time = 0.1117849349975586\n",
      "INFO:absl:step = 43150, loss = 2.117424\n",
      "INFO:absl:248.150 steps/sec\n",
      "INFO:absl:collect_time = 0.09457898139953613, train_time = 0.10691213607788086\n",
      "INFO:absl:step = 43200, loss = 0.244867\n",
      "INFO:absl:267.382 steps/sec\n",
      "INFO:absl:collect_time = 0.09091019630432129, train_time = 0.09608793258666992\n",
      "INFO:absl:step = 43250, loss = 1.153368\n",
      "INFO:absl:161.525 steps/sec\n",
      "INFO:absl:collect_time = 0.10365939140319824, train_time = 0.20589089393615723\n",
      "INFO:absl:step = 43300, loss = 0.845266\n",
      "INFO:absl:187.129 steps/sec\n",
      "INFO:absl:collect_time = 0.13612985610961914, train_time = 0.13106513023376465\n",
      "INFO:absl:step = 43350, loss = 5.372899\n",
      "INFO:absl:163.746 steps/sec\n",
      "INFO:absl:collect_time = 0.17025399208068848, train_time = 0.13509607315063477\n",
      "INFO:absl:step = 43400, loss = 4.563944\n",
      "INFO:absl:181.196 steps/sec\n",
      "INFO:absl:collect_time = 0.13282465934753418, train_time = 0.14312005043029785\n",
      "INFO:absl:step = 43450, loss = 2.531979\n",
      "INFO:absl:265.298 steps/sec\n",
      "INFO:absl:collect_time = 0.0852198600769043, train_time = 0.10324716567993164\n",
      "INFO:absl:step = 43500, loss = 3.651859\n",
      "INFO:absl:198.614 steps/sec\n",
      "INFO:absl:collect_time = 0.10196518898010254, train_time = 0.1497795581817627\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-43500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-43500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000043500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000043500/assets\n",
      "INFO:absl:step = 43550, loss = 1.061434\n",
      "INFO:absl:210.129 steps/sec\n",
      "INFO:absl:collect_time = 0.13091111183166504, train_time = 0.10703802108764648\n",
      "INFO:absl:step = 43600, loss = 1.062253\n",
      "INFO:absl:244.808 steps/sec\n",
      "INFO:absl:collect_time = 0.09111142158508301, train_time = 0.11313056945800781\n",
      "INFO:absl:step = 43650, loss = 0.767741\n",
      "INFO:absl:255.438 steps/sec\n",
      "INFO:absl:collect_time = 0.08447599411010742, train_time = 0.11126589775085449\n",
      "INFO:absl:step = 43700, loss = 1.802525\n",
      "INFO:absl:182.641 steps/sec\n",
      "INFO:absl:collect_time = 0.13793492317199707, train_time = 0.13582611083984375\n",
      "INFO:absl:step = 43750, loss = 0.968453\n",
      "INFO:absl:254.867 steps/sec\n",
      "INFO:absl:collect_time = 0.08516693115234375, train_time = 0.11101412773132324\n",
      "INFO:absl:step = 43800, loss = 0.555552\n",
      "INFO:absl:169.448 steps/sec\n",
      "INFO:absl:collect_time = 0.13654422760009766, train_time = 0.15853118896484375\n",
      "INFO:absl:step = 43850, loss = 1.889230\n",
      "INFO:absl:195.010 steps/sec\n",
      "INFO:absl:collect_time = 0.12144780158996582, train_time = 0.1349499225616455\n",
      "INFO:absl:step = 43900, loss = 3.895947\n",
      "INFO:absl:207.604 steps/sec\n",
      "INFO:absl:collect_time = 0.12298035621643066, train_time = 0.11786293983459473\n",
      "INFO:absl:step = 43950, loss = 2.654141\n",
      "INFO:absl:239.614 steps/sec\n",
      "INFO:absl:collect_time = 0.09675002098083496, train_time = 0.11191916465759277\n",
      "INFO:absl:step = 44000, loss = 3.168338\n",
      "INFO:absl:213.057 steps/sec\n",
      "INFO:absl:collect_time = 0.09665989875793457, train_time = 0.13801884651184082\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-44000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-44000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000044000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000044000/assets\n",
      "INFO:absl:step = 44050, loss = 3.197127\n",
      "INFO:absl:218.587 steps/sec\n",
      "INFO:absl:collect_time = 0.10610127449035645, train_time = 0.12264108657836914\n",
      "INFO:absl:step = 44100, loss = 20.193684\n",
      "INFO:absl:192.651 steps/sec\n",
      "INFO:absl:collect_time = 0.130202054977417, train_time = 0.1293351650238037\n",
      "INFO:absl:step = 44150, loss = 2.693974\n",
      "INFO:absl:214.470 steps/sec\n",
      "INFO:absl:collect_time = 0.10340404510498047, train_time = 0.1297292709350586\n",
      "INFO:absl:step = 44200, loss = 1.913730\n",
      "INFO:absl:262.099 steps/sec\n",
      "INFO:absl:collect_time = 0.08699512481689453, train_time = 0.10377216339111328\n",
      "INFO:absl:step = 44250, loss = 0.936060\n",
      "INFO:absl:230.454 steps/sec\n",
      "INFO:absl:collect_time = 0.09778618812561035, train_time = 0.11917686462402344\n",
      "INFO:absl:step = 44300, loss = 0.498136\n",
      "INFO:absl:201.155 steps/sec\n",
      "INFO:absl:collect_time = 0.12550711631774902, train_time = 0.12305784225463867\n",
      "INFO:absl:step = 44350, loss = 2.040754\n",
      "INFO:absl:243.876 steps/sec\n",
      "INFO:absl:collect_time = 0.09154725074768066, train_time = 0.11347508430480957\n",
      "INFO:absl:step = 44400, loss = 1.473467\n",
      "INFO:absl:227.838 steps/sec\n",
      "INFO:absl:collect_time = 0.10085391998291016, train_time = 0.11859989166259766\n",
      "INFO:absl:step = 44450, loss = 3.006436\n",
      "INFO:absl:228.764 steps/sec\n",
      "INFO:absl:collect_time = 0.08849191665649414, train_time = 0.13007378578186035\n",
      "INFO:absl:step = 44500, loss = 13.611113\n",
      "INFO:absl:179.544 steps/sec\n",
      "INFO:absl:collect_time = 0.14351224899291992, train_time = 0.13497090339660645\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-44500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-44500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000044500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000044500/assets\n",
      "INFO:absl:step = 44550, loss = 0.607143\n",
      "INFO:absl:259.189 steps/sec\n",
      "INFO:absl:collect_time = 0.08687710762023926, train_time = 0.1060326099395752\n",
      "INFO:absl:step = 44600, loss = 0.797925\n",
      "INFO:absl:263.007 steps/sec\n",
      "INFO:absl:collect_time = 0.08870577812194824, train_time = 0.10140323638916016\n",
      "INFO:absl:step = 44650, loss = 1.971471\n",
      "INFO:absl:247.724 steps/sec\n",
      "INFO:absl:collect_time = 0.10388350486755371, train_time = 0.09795403480529785\n",
      "INFO:absl:step = 44700, loss = 1.786437\n",
      "INFO:absl:251.284 steps/sec\n",
      "INFO:absl:collect_time = 0.08588480949401855, train_time = 0.11309361457824707\n",
      "INFO:absl:step = 44750, loss = 4.331830\n",
      "INFO:absl:227.698 steps/sec\n",
      "INFO:absl:collect_time = 0.10663414001464844, train_time = 0.11295485496520996\n",
      "INFO:absl:step = 44800, loss = 0.330798\n",
      "INFO:absl:280.870 steps/sec\n",
      "INFO:absl:collect_time = 0.08270716667175293, train_time = 0.09531140327453613\n",
      "INFO:absl:step = 44850, loss = 1.929358\n",
      "INFO:absl:263.833 steps/sec\n",
      "INFO:absl:collect_time = 0.08457016944885254, train_time = 0.10494375228881836\n",
      "INFO:absl:step = 44900, loss = 0.607313\n",
      "INFO:absl:251.567 steps/sec\n",
      "INFO:absl:collect_time = 0.09430575370788574, train_time = 0.10444855690002441\n",
      "INFO:absl:step = 44950, loss = 0.577432\n",
      "INFO:absl:215.353 steps/sec\n",
      "INFO:absl:collect_time = 0.1047670841217041, train_time = 0.1274099349975586\n",
      "INFO:absl:step = 45000, loss = 1.713496\n",
      "INFO:absl:251.987 steps/sec\n",
      "INFO:absl:collect_time = 0.08740973472595215, train_time = 0.11101317405700684\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-45000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-45000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000045000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000045000/assets\n",
      "INFO:absl:step = 45050, loss = 1.389466\n",
      "INFO:absl:261.270 steps/sec\n",
      "INFO:absl:collect_time = 0.08147192001342773, train_time = 0.10990118980407715\n",
      "INFO:absl:step = 45100, loss = 3.292096\n",
      "INFO:absl:257.247 steps/sec\n",
      "INFO:absl:collect_time = 0.0961906909942627, train_time = 0.0981748104095459\n",
      "INFO:absl:step = 45150, loss = 2.558369\n",
      "INFO:absl:247.973 steps/sec\n",
      "INFO:absl:collect_time = 0.09328675270080566, train_time = 0.10834789276123047\n",
      "INFO:absl:step = 45200, loss = 0.748684\n",
      "INFO:absl:259.615 steps/sec\n",
      "INFO:absl:collect_time = 0.09045600891113281, train_time = 0.10213708877563477\n",
      "INFO:absl:step = 45250, loss = 0.988218\n",
      "INFO:absl:291.949 steps/sec\n",
      "INFO:absl:collect_time = 0.07491087913513184, train_time = 0.09635186195373535\n",
      "INFO:absl:step = 45300, loss = 1.406425\n",
      "INFO:absl:286.020 steps/sec\n",
      "INFO:absl:collect_time = 0.08020305633544922, train_time = 0.09460997581481934\n",
      "INFO:absl:step = 45350, loss = 0.544190\n",
      "INFO:absl:267.045 steps/sec\n",
      "INFO:absl:collect_time = 0.0842745304107666, train_time = 0.10296010971069336\n",
      "INFO:absl:step = 45400, loss = 1.194568\n",
      "INFO:absl:270.576 steps/sec\n",
      "INFO:absl:collect_time = 0.0850520133972168, train_time = 0.09973907470703125\n",
      "INFO:absl:step = 45450, loss = 2.062320\n",
      "INFO:absl:248.751 steps/sec\n",
      "INFO:absl:collect_time = 0.09580421447753906, train_time = 0.10520029067993164\n",
      "INFO:absl:step = 45500, loss = 4.870022\n",
      "INFO:absl:239.677 steps/sec\n",
      "INFO:absl:collect_time = 0.08726620674133301, train_time = 0.12134814262390137\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-45500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-45500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000045500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000045500/assets\n",
      "INFO:absl:step = 45550, loss = 1.444727\n",
      "INFO:absl:255.948 steps/sec\n",
      "INFO:absl:collect_time = 0.0850670337677002, train_time = 0.11028504371643066\n",
      "INFO:absl:step = 45600, loss = 0.700916\n",
      "INFO:absl:264.064 steps/sec\n",
      "INFO:absl:collect_time = 0.08444523811340332, train_time = 0.10490298271179199\n",
      "INFO:absl:step = 45650, loss = 1.423931\n",
      "INFO:absl:278.470 steps/sec\n",
      "INFO:absl:collect_time = 0.0780029296875, train_time = 0.10154938697814941\n",
      "INFO:absl:step = 45700, loss = 7.915609\n",
      "INFO:absl:219.789 steps/sec\n",
      "INFO:absl:collect_time = 0.11099815368652344, train_time = 0.11649298667907715\n",
      "INFO:absl:step = 45750, loss = 0.786308\n",
      "INFO:absl:235.306 steps/sec\n",
      "INFO:absl:collect_time = 0.09957218170166016, train_time = 0.11291694641113281\n",
      "INFO:absl:step = 45800, loss = 0.897320\n",
      "INFO:absl:269.892 steps/sec\n",
      "INFO:absl:collect_time = 0.07762980461120605, train_time = 0.10762977600097656\n",
      "INFO:absl:step = 45850, loss = 0.322435\n",
      "INFO:absl:251.892 steps/sec\n",
      "INFO:absl:collect_time = 0.08804726600646973, train_time = 0.11045074462890625\n",
      "INFO:absl:step = 45900, loss = 0.533098\n",
      "INFO:absl:255.753 steps/sec\n",
      "INFO:absl:collect_time = 0.08828902244567871, train_time = 0.10721182823181152\n",
      "INFO:absl:step = 45950, loss = 0.840646\n",
      "INFO:absl:221.578 steps/sec\n",
      "INFO:absl:collect_time = 0.11304354667663574, train_time = 0.11261105537414551\n",
      "INFO:absl:step = 46000, loss = 9.892083\n",
      "INFO:absl:256.268 steps/sec\n",
      "INFO:absl:collect_time = 0.09164690971374512, train_time = 0.10346102714538574\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-46000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-46000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000046000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000046000/assets\n",
      "INFO:absl:step = 46050, loss = 0.525152\n",
      "INFO:absl:276.270 steps/sec\n",
      "INFO:absl:collect_time = 0.07808423042297363, train_time = 0.10289812088012695\n",
      "INFO:absl:step = 46100, loss = 4.254232\n",
      "INFO:absl:250.952 steps/sec\n",
      "INFO:absl:collect_time = 0.08958816528320312, train_time = 0.10965347290039062\n",
      "INFO:absl:step = 46150, loss = 1.282307\n",
      "INFO:absl:269.443 steps/sec\n",
      "INFO:absl:collect_time = 0.0860600471496582, train_time = 0.09950804710388184\n",
      "INFO:absl:step = 46200, loss = 1.508260\n",
      "INFO:absl:249.901 steps/sec\n",
      "INFO:absl:collect_time = 0.0966951847076416, train_time = 0.10338401794433594\n",
      "INFO:absl:step = 46250, loss = 4.496926\n",
      "INFO:absl:224.989 steps/sec\n",
      "INFO:absl:collect_time = 0.10585427284240723, train_time = 0.1163790225982666\n",
      "INFO:absl:step = 46300, loss = 5.545374\n",
      "INFO:absl:272.816 steps/sec\n",
      "INFO:absl:collect_time = 0.07936358451843262, train_time = 0.10390996932983398\n",
      "INFO:absl:step = 46350, loss = 0.482153\n",
      "INFO:absl:262.314 steps/sec\n",
      "INFO:absl:collect_time = 0.0847618579864502, train_time = 0.1058497428894043\n",
      "INFO:absl:step = 46400, loss = 4.399897\n",
      "INFO:absl:238.855 steps/sec\n",
      "INFO:absl:collect_time = 0.10171079635620117, train_time = 0.1076211929321289\n",
      "INFO:absl:step = 46450, loss = 1.801357\n",
      "INFO:absl:229.821 steps/sec\n",
      "INFO:absl:collect_time = 0.10838103294372559, train_time = 0.10917925834655762\n",
      "INFO:absl:step = 46500, loss = 0.939704\n",
      "INFO:absl:268.901 steps/sec\n",
      "INFO:absl:collect_time = 0.08783888816833496, train_time = 0.09810328483581543\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-46500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-46500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000046500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000046500/assets\n",
      "INFO:absl:step = 46550, loss = 3.163092\n",
      "INFO:absl:258.024 steps/sec\n",
      "INFO:absl:collect_time = 0.08653688430786133, train_time = 0.10724329948425293\n",
      "INFO:absl:step = 46600, loss = 0.705267\n",
      "INFO:absl:268.251 steps/sec\n",
      "INFO:absl:collect_time = 0.08765316009521484, train_time = 0.0987393856048584\n",
      "INFO:absl:step = 46650, loss = 1.108124\n",
      "INFO:absl:246.474 steps/sec\n",
      "INFO:absl:collect_time = 0.09312605857849121, train_time = 0.10973501205444336\n",
      "INFO:absl:step = 46700, loss = 1.101244\n",
      "INFO:absl:244.839 steps/sec\n",
      "INFO:absl:collect_time = 0.09989619255065918, train_time = 0.10432004928588867\n",
      "INFO:absl:step = 46750, loss = 1.060301\n",
      "INFO:absl:259.309 steps/sec\n",
      "INFO:absl:collect_time = 0.0917959213256836, train_time = 0.10102415084838867\n",
      "INFO:absl:step = 46800, loss = 4.080630\n",
      "INFO:absl:238.713 steps/sec\n",
      "INFO:absl:collect_time = 0.1002199649810791, train_time = 0.10923624038696289\n",
      "INFO:absl:step = 46850, loss = 0.498924\n",
      "INFO:absl:228.587 steps/sec\n",
      "INFO:absl:collect_time = 0.0987391471862793, train_time = 0.1199960708618164\n",
      "INFO:absl:step = 46900, loss = 1.851463\n",
      "INFO:absl:230.867 steps/sec\n",
      "INFO:absl:collect_time = 0.10836172103881836, train_time = 0.10821318626403809\n",
      "INFO:absl:step = 46950, loss = 1.077127\n",
      "INFO:absl:234.835 steps/sec\n",
      "INFO:absl:collect_time = 0.104827880859375, train_time = 0.10808801651000977\n",
      "INFO:absl:step = 47000, loss = 2.730235\n",
      "INFO:absl:267.512 steps/sec\n",
      "INFO:absl:collect_time = 0.0870051383972168, train_time = 0.09990215301513672\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-47000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-47000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000047000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000047000/assets\n",
      "INFO:absl:step = 47050, loss = 1.776473\n",
      "INFO:absl:260.162 steps/sec\n",
      "INFO:absl:collect_time = 0.08893322944641113, train_time = 0.10325503349304199\n",
      "INFO:absl:step = 47100, loss = 0.792905\n",
      "INFO:absl:217.376 steps/sec\n",
      "INFO:absl:collect_time = 0.10541296005249023, train_time = 0.1246027946472168\n",
      "INFO:absl:step = 47150, loss = 2.242041\n",
      "INFO:absl:257.303 steps/sec\n",
      "INFO:absl:collect_time = 0.09684491157531738, train_time = 0.09747886657714844\n",
      "INFO:absl:step = 47200, loss = 4.923855\n",
      "INFO:absl:249.709 steps/sec\n",
      "INFO:absl:collect_time = 0.0924062728881836, train_time = 0.10782694816589355\n",
      "INFO:absl:step = 47250, loss = 2.357864\n",
      "INFO:absl:244.009 steps/sec\n",
      "INFO:absl:collect_time = 0.10050415992736816, train_time = 0.10440611839294434\n",
      "INFO:absl:step = 47300, loss = 1.834432\n",
      "INFO:absl:245.375 steps/sec\n",
      "INFO:absl:collect_time = 0.09780383110046387, train_time = 0.10596609115600586\n",
      "INFO:absl:step = 47350, loss = 4.493051\n",
      "INFO:absl:231.209 steps/sec\n",
      "INFO:absl:collect_time = 0.10245370864868164, train_time = 0.1138007640838623\n",
      "INFO:absl:step = 47400, loss = 2.070976\n",
      "INFO:absl:236.252 steps/sec\n",
      "INFO:absl:collect_time = 0.10530996322631836, train_time = 0.10632872581481934\n",
      "INFO:absl:step = 47450, loss = 2.251427\n",
      "INFO:absl:239.373 steps/sec\n",
      "INFO:absl:collect_time = 0.10232186317443848, train_time = 0.10655713081359863\n",
      "INFO:absl:step = 47500, loss = 2.124663\n",
      "INFO:absl:284.634 steps/sec\n",
      "INFO:absl:collect_time = 0.07981300354003906, train_time = 0.09585142135620117\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-47500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-47500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000047500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000047500/assets\n",
      "INFO:absl:step = 47550, loss = 0.967490\n",
      "INFO:absl:262.084 steps/sec\n",
      "INFO:absl:collect_time = 0.08632898330688477, train_time = 0.10444974899291992\n",
      "INFO:absl:step = 47600, loss = 6.600316\n",
      "INFO:absl:215.356 steps/sec\n",
      "INFO:absl:collect_time = 0.12694001197814941, train_time = 0.10523390769958496\n",
      "INFO:absl:step = 47650, loss = 1.209136\n",
      "INFO:absl:226.798 steps/sec\n",
      "INFO:absl:collect_time = 0.10865330696105957, train_time = 0.11180710792541504\n",
      "INFO:absl:step = 47700, loss = 4.462541\n",
      "INFO:absl:249.642 steps/sec\n",
      "INFO:absl:collect_time = 0.09984087944030762, train_time = 0.10044622421264648\n",
      "INFO:absl:step = 47750, loss = 1.096350\n",
      "INFO:absl:268.572 steps/sec\n",
      "INFO:absl:collect_time = 0.08692193031311035, train_time = 0.09924769401550293\n",
      "INFO:absl:step = 47800, loss = 1.037406\n",
      "INFO:absl:207.639 steps/sec\n",
      "INFO:absl:collect_time = 0.11765408515930176, train_time = 0.12314891815185547\n",
      "INFO:absl:step = 47850, loss = 1.545659\n",
      "INFO:absl:239.965 steps/sec\n",
      "INFO:absl:collect_time = 0.09323883056640625, train_time = 0.11512517929077148\n",
      "INFO:absl:step = 47900, loss = 1.340546\n",
      "INFO:absl:256.352 steps/sec\n",
      "INFO:absl:collect_time = 0.09678196907043457, train_time = 0.09826231002807617\n",
      "INFO:absl:step = 47950, loss = 6.995123\n",
      "INFO:absl:167.381 steps/sec\n",
      "INFO:absl:collect_time = 0.11003875732421875, train_time = 0.18868136405944824\n",
      "INFO:absl:step = 48000, loss = 1.244751\n",
      "INFO:absl:235.691 steps/sec\n",
      "INFO:absl:collect_time = 0.10199475288391113, train_time = 0.11014699935913086\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-48000\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-48000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000048000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000048000/assets\n",
      "INFO:absl:step = 48050, loss = 1.281160\n",
      "INFO:absl:257.386 steps/sec\n",
      "INFO:absl:collect_time = 0.09092068672180176, train_time = 0.10334014892578125\n",
      "INFO:absl:step = 48100, loss = 0.592749\n",
      "INFO:absl:256.048 steps/sec\n",
      "INFO:absl:collect_time = 0.08860135078430176, train_time = 0.1066746711730957\n",
      "INFO:absl:step = 48150, loss = 0.762767\n",
      "INFO:absl:243.615 steps/sec\n",
      "INFO:absl:collect_time = 0.09011578559875488, train_time = 0.11512613296508789\n",
      "INFO:absl:step = 48200, loss = 6.125124\n",
      "INFO:absl:242.147 steps/sec\n",
      "INFO:absl:collect_time = 0.10020756721496582, train_time = 0.1062781810760498\n",
      "INFO:absl:step = 48250, loss = 1.878250\n",
      "INFO:absl:255.054 steps/sec\n",
      "INFO:absl:collect_time = 0.09403872489929199, train_time = 0.10199785232543945\n",
      "INFO:absl:step = 48300, loss = 1.391526\n",
      "INFO:absl:265.453 steps/sec\n",
      "INFO:absl:collect_time = 0.0825951099395752, train_time = 0.10576200485229492\n",
      "INFO:absl:step = 48350, loss = 1.127414\n",
      "INFO:absl:270.350 steps/sec\n",
      "INFO:absl:collect_time = 0.08513212203979492, train_time = 0.09981298446655273\n",
      "INFO:absl:step = 48400, loss = 2.018726\n",
      "INFO:absl:237.722 steps/sec\n",
      "INFO:absl:collect_time = 0.10124897956848145, train_time = 0.10908102989196777\n",
      "INFO:absl:step = 48450, loss = 0.745538\n",
      "INFO:absl:217.916 steps/sec\n",
      "INFO:absl:collect_time = 0.11377358436584473, train_time = 0.11567306518554688\n",
      "INFO:absl:step = 48500, loss = 0.919356\n",
      "INFO:absl:236.887 steps/sec\n",
      "INFO:absl:collect_time = 0.09819817543029785, train_time = 0.11287307739257812\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/ckpt-48500\n",
      "INFO:absl:Saved checkpoint: /Users/richard/Documents/Research/FLRL/dump/train/policy/ckpt-48500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000048500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/richard/Documents/Research/FLRL/dump/policy_saved_model/policy_000048500/assets\n",
      "INFO:absl:step = 48550, loss = 1.129066\n",
      "INFO:absl:240.681 steps/sec\n",
      "INFO:absl:collect_time = 0.10470914840698242, train_time = 0.10303497314453125\n",
      "INFO:absl:step = 48600, loss = 14.142413\n",
      "INFO:absl:241.037 steps/sec\n",
      "INFO:absl:collect_time = 0.09703803062438965, train_time = 0.11039900779724121\n",
      "INFO:absl:step = 48650, loss = 1.087065\n",
      "INFO:absl:239.407 steps/sec\n",
      "INFO:absl:collect_time = 0.09114694595336914, train_time = 0.11770200729370117\n",
      "INFO:absl:step = 48700, loss = 3.698543\n",
      "INFO:absl:221.039 steps/sec\n",
      "INFO:absl:collect_time = 0.11099624633789062, train_time = 0.11520791053771973\n",
      "INFO:absl:step = 48750, loss = 2.650952\n",
      "INFO:absl:232.311 steps/sec\n",
      "INFO:absl:collect_time = 0.10853195190429688, train_time = 0.10669708251953125\n",
      "INFO:absl:step = 48800, loss = 0.968679\n",
      "INFO:absl:273.325 steps/sec\n",
      "INFO:absl:collect_time = 0.08434486389160156, train_time = 0.0985872745513916\n",
      "INFO:absl:step = 48850, loss = 1.595748\n",
      "INFO:absl:224.499 steps/sec\n",
      "INFO:absl:collect_time = 0.10418391227722168, train_time = 0.11853432655334473\n",
      "INFO:absl:step = 48900, loss = 1.025084\n",
      "INFO:absl:239.395 steps/sec\n",
      "INFO:absl:collect_time = 0.09578728675842285, train_time = 0.11307239532470703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXITED\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2018 The TF-Agents Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "r\"\"\"Train and Eval PPO.\n",
    "To run:\n",
    "```bash\n",
    "tensorboard --logdir $HOME/tmp/ppo/gym/HalfCheetah-v2/ --port 2223 &\n",
    "python tf_agents/agents/ppo/examples/v2/train_eval.py \\\n",
    "  --root_dir=$HOME/tmp/ppo/gym/HalfCheetah-v2/ \\\n",
    "  --logtostderr\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from absl import logging\n",
    "\n",
    "import gin\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.ppo import ppo_agent\n",
    "from tf_agents.drivers import dynamic_episode_driver\n",
    "from tf_agents.environments import parallel_py_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.networks import actor_distribution_rnn_network\n",
    "from tf_agents.networks import value_network\n",
    "from tf_agents.networks import value_rnn_network\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.utils import common\n",
    "\n",
    "\n",
    "def train_eval(\n",
    "    root_dir,\n",
    "    env_name='HalfCheetah-v2',\n",
    "    env_load_fn=BoostedEnvironment,\n",
    "    random_seed=0,\n",
    "    # TODO(b/127576522): rename to policy_fc_layers.\n",
    "    actor_fc_layers=(200, 100),\n",
    "    value_fc_layers=(200, 100),\n",
    "    use_rnns=False,\n",
    "    # Params for collect\n",
    "    num_environment_steps=10000000,\n",
    "    collect_episodes_per_iteration=30,\n",
    "    num_parallel_environments=30,\n",
    "    replay_buffer_capacity=1001,  # Per-environment\n",
    "    # Params for train\n",
    "    num_epochs=25,\n",
    "    learning_rate=1e-5,\n",
    "    # Params for eval\n",
    "    num_eval_episodes=30,\n",
    "    eval_interval=500,\n",
    "    # Params for summaries and logging\n",
    "    train_checkpoint_interval=500,\n",
    "    policy_checkpoint_interval=500,\n",
    "    log_interval=50,\n",
    "    summary_interval=50,\n",
    "    summaries_flush_secs=1,\n",
    "    use_tf_functions=True,\n",
    "    debug_summaries=True,\n",
    "    summarize_grads_and_vars=False):\n",
    "  \"\"\"A simple train and eval for PPO.\"\"\"\n",
    "  if root_dir is None:\n",
    "    raise AttributeError('train_eval requires a root_dir.')\n",
    "\n",
    "  root_dir = os.path.expanduser(root_dir)\n",
    "  train_dir = os.path.join(root_dir, 'train')\n",
    "  eval_dir = os.path.join(root_dir, 'eval')\n",
    "  saved_model_dir = os.path.join(root_dir, 'policy_saved_model')\n",
    "\n",
    "  train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "      train_dir, flush_millis=summaries_flush_secs * 1000)\n",
    "  train_summary_writer.set_as_default()\n",
    "\n",
    "  eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "      eval_dir, flush_millis=summaries_flush_secs * 1000)\n",
    "  eval_metrics = [\n",
    "      tf_metrics.AverageReturnMetric(buffer_size=num_eval_episodes),\n",
    "      tf_metrics.AverageEpisodeLengthMetric(buffer_size=num_eval_episodes)\n",
    "  ]\n",
    "\n",
    "  global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "  with tf.compat.v2.summary.record_if(\n",
    "      lambda: tf.math.equal(global_step % summary_interval, 0)):\n",
    "    tf.compat.v1.set_random_seed(random_seed)\n",
    "    eval_tf_env = tf_py_environment.TFPyEnvironment(env_load_fn())\n",
    "    tf_env = tf_py_environment.TFPyEnvironment(\n",
    "        parallel_py_environment.ParallelPyEnvironment(\n",
    "            [lambda: env_load_fn()] * num_parallel_environments))\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "    if use_rnns:\n",
    "      actor_net = actor_distribution_rnn_network.ActorDistributionRnnNetwork(\n",
    "          tf_env.observation_spec(),\n",
    "          tf_env.action_spec(),\n",
    "          input_fc_layer_params=actor_fc_layers,\n",
    "          output_fc_layer_params=None)\n",
    "      value_net = value_rnn_network.ValueRnnNetwork(\n",
    "          tf_env.observation_spec(),\n",
    "          input_fc_layer_params=value_fc_layers,\n",
    "          output_fc_layer_params=None)\n",
    "    else:\n",
    "      actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "          tf_env.observation_spec(),\n",
    "          tf_env.action_spec(),\n",
    "          fc_layer_params=actor_fc_layers)\n",
    "      value_net = value_network.ValueNetwork(\n",
    "          tf_env.observation_spec(), fc_layer_params=value_fc_layers)\n",
    "\n",
    "    tf_agent = ppo_agent.PPOAgent(\n",
    "        tf_env.time_step_spec(),\n",
    "        tf_env.action_spec(),\n",
    "        optimizer,\n",
    "        actor_net=actor_net,\n",
    "        value_net=value_net,\n",
    "        num_epochs=num_epochs,\n",
    "        debug_summaries=debug_summaries,\n",
    "        summarize_grads_and_vars=summarize_grads_and_vars,\n",
    "        train_step_counter=global_step)\n",
    "    tf_agent.initialize()\n",
    "\n",
    "    environment_steps_metric = tf_metrics.EnvironmentSteps()\n",
    "    step_metrics = [\n",
    "        tf_metrics.NumberOfEpisodes(),\n",
    "        environment_steps_metric,\n",
    "    ]\n",
    "\n",
    "    train_metrics = step_metrics + [\n",
    "        tf_metrics.AverageReturnMetric(\n",
    "            batch_size=num_parallel_environments),\n",
    "        tf_metrics.AverageEpisodeLengthMetric(\n",
    "            batch_size=num_parallel_environments),\n",
    "    ]\n",
    "\n",
    "    eval_policy = tf_agent.policy\n",
    "    collect_policy = tf_agent.collect_policy\n",
    "\n",
    "    replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "        tf_agent.collect_data_spec,\n",
    "        batch_size=num_parallel_environments,\n",
    "        max_length=replay_buffer_capacity)\n",
    "\n",
    "    train_checkpointer = common.Checkpointer(\n",
    "        ckpt_dir=train_dir,\n",
    "        agent=tf_agent,\n",
    "        global_step=global_step,\n",
    "        metrics=metric_utils.MetricsGroup(train_metrics, 'train_metrics'))\n",
    "    policy_checkpointer = common.Checkpointer(\n",
    "        ckpt_dir=os.path.join(train_dir, 'policy'),\n",
    "        policy=eval_policy,\n",
    "        global_step=global_step)\n",
    "    saved_model = policy_saver.PolicySaver(\n",
    "        eval_policy, train_step=global_step)\n",
    "\n",
    "    train_checkpointer.initialize_or_restore()\n",
    "\n",
    "    collect_driver = dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "        tf_env,\n",
    "        collect_policy,\n",
    "        observers=[replay_buffer.add_batch] + train_metrics,\n",
    "        num_episodes=collect_episodes_per_iteration)\n",
    "\n",
    "    def train_step():\n",
    "      trajectories = replay_buffer.gather_all()\n",
    "      return tf_agent.train(experience=trajectories)\n",
    "\n",
    "    if use_tf_functions:\n",
    "      # TODO(b/123828980): Enable once the cause for slowdown was identified.\n",
    "      collect_driver.run = common.function(collect_driver.run, autograph=False)\n",
    "      tf_agent.train = common.function(tf_agent.train, autograph=False)\n",
    "      train_step = common.function(train_step)\n",
    "\n",
    "    collect_time = 0\n",
    "    train_time = 0\n",
    "    timed_at_step = global_step.numpy()\n",
    "\n",
    "    while environment_steps_metric.result() < num_environment_steps:\n",
    "      global_step_val = global_step.numpy()\n",
    "      if global_step_val % eval_interval == 0:\n",
    "        metric_utils.eager_compute(\n",
    "            eval_metrics,\n",
    "            eval_tf_env,\n",
    "            eval_policy,\n",
    "            num_episodes=num_eval_episodes,\n",
    "            train_step=global_step,\n",
    "            summary_writer=eval_summary_writer,\n",
    "            summary_prefix='Metrics',\n",
    "        )\n",
    "\n",
    "      start_time = time.time()\n",
    "      collect_driver.run()\n",
    "      collect_time += time.time() - start_time\n",
    "\n",
    "      start_time = time.time()\n",
    "      total_loss, _ = train_step()\n",
    "      replay_buffer.clear()\n",
    "      train_time += time.time() - start_time\n",
    "\n",
    "      for train_metric in train_metrics:\n",
    "        train_metric.tf_summaries(\n",
    "            train_step=global_step, step_metrics=step_metrics)\n",
    "\n",
    "      if global_step_val % log_interval == 0:\n",
    "        logging.info('step = %d, loss = %f', global_step_val, total_loss)\n",
    "        steps_per_sec = (\n",
    "            (global_step_val - timed_at_step) / (collect_time + train_time))\n",
    "        logging.info('%.3f steps/sec', steps_per_sec)\n",
    "        logging.info('collect_time = {}, train_time = {}'.format(\n",
    "            collect_time, train_time))\n",
    "        with tf.compat.v2.summary.record_if(True):\n",
    "          tf.compat.v2.summary.scalar(\n",
    "              name='global_steps_per_sec', data=steps_per_sec, step=global_step)\n",
    "\n",
    "        if global_step_val % train_checkpoint_interval == 0:\n",
    "          train_checkpointer.save(global_step=global_step_val)\n",
    "\n",
    "        if global_step_val % policy_checkpoint_interval == 0:\n",
    "          policy_checkpointer.save(global_step=global_step_val)\n",
    "          saved_model_path = os.path.join(\n",
    "              saved_model_dir, 'policy_' + ('%d' % global_step_val).zfill(9))\n",
    "          saved_model.save(saved_model_path)\n",
    "\n",
    "        timed_at_step = global_step_val\n",
    "        collect_time = 0\n",
    "        train_time = 0\n",
    "\n",
    "    # One final eval before exiting.\n",
    "    metric_utils.eager_compute(\n",
    "        eval_metrics,\n",
    "        eval_tf_env,\n",
    "        eval_policy,\n",
    "        num_episodes=num_eval_episodes,\n",
    "        train_step=global_step,\n",
    "        summary_writer=eval_summary_writer,\n",
    "        summary_prefix='Metrics',\n",
    "    )\n",
    "    print(\"EXITED\")\n",
    "    \n",
    "    return tf_agent\n",
    "\n",
    "logging.set_verbosity(logging.INFO)\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "agent = train_eval(\n",
    "      '/Users/richard/Documents/Research/FLRL/dump',\n",
    "      env_name='BoostedEnvironment',\n",
    "      use_rnns=False,\n",
    "      num_environment_steps=100000,\n",
    "      collect_episodes_per_iteration=30,\n",
    "      num_parallel_environments=4,\n",
    "      replay_buffer_capacity=1000,\n",
    "      num_epochs=25,\n",
    "      num_eval_episodes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted action tf.Tensor([[[0.32016593 0.52141124]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.00235294]\n",
      "predicted action tf.Tensor([[[0.35313064 0.5240068 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.00235294]\n",
      "predicted action tf.Tensor([[[0.47748858 0.4257298 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.02941176]\n",
      "predicted action tf.Tensor([[[0.54622453 0.4379269 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.01882353]\n",
      "predicted action tf.Tensor([[[0.47748858 0.4257298 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 3 Reward: [0.0482353]\n",
      "predicted action tf.Tensor([[[0.5850633 0.5429086]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 1 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.39333037 0.4595622 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.00235294]\n",
      "predicted action tf.Tensor([[[0.44661033 0.4924605 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.00235294]\n",
      "predicted action tf.Tensor([[[0.45497605 0.45990297]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.00823529]\n",
      "predicted action tf.Tensor([[[0.46967703 0.47262034]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.00823529]\n",
      "predicted action tf.Tensor([[[0.68936765 0.46289316]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.06117647]\n",
      "predicted action tf.Tensor([[[0.65380347 0.47966844]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.06117647]\n",
      "predicted action tf.Tensor([[[0.5672813  0.49334446]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 1 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.50469667 0.5421612 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 1 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.43513238 0.53437483]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.03647059]\n",
      "predicted action tf.Tensor([[[0.4614342 0.5222356]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.03647059]\n",
      "predicted action tf.Tensor([[[0.5396533 0.3693898]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.01176471]\n",
      "predicted action tf.Tensor([[[0.5446063  0.35623214]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.01176471]\n",
      "predicted action tf.Tensor([[[0.47849122 0.42929953]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.03647059]\n",
      "predicted action tf.Tensor([[[0.5140755  0.44140977]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.05882353]\n",
      "predicted action tf.Tensor([[[0.47849122 0.42929953]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 3 Reward: [0.09529412]\n",
      "predicted action tf.Tensor([[[0.54557276 0.45516372]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.5306484  0.49533135]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.5227565  0.58878404]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.06823529]\n",
      "predicted action tf.Tensor([[[0.49332547 0.5540747 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.02]\n",
      "predicted action tf.Tensor([[[0.511545   0.58667415]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 3 Reward: [0.0882353]\n",
      "predicted action tf.Tensor([[[0.5540199 0.4654552]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.06235294]\n",
      "predicted action tf.Tensor([[[0.5894287  0.45543098]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.06235294]\n",
      "predicted action tf.Tensor([[[0.38207656 0.4564721 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.44196564 0.41686872]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.02470588]\n",
      "predicted action tf.Tensor([[[0.43730587 0.40719646]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 3 Reward: [0.02470588]\n",
      "predicted action tf.Tensor([[[0.55529815 0.560385  ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.02235294]\n",
      "predicted action tf.Tensor([[[0.5215201 0.5535342]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.02235294]\n",
      "predicted action tf.Tensor([[[0.4842403  0.55113316]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.03411765]\n",
      "predicted action tf.Tensor([[[0.49220255 0.5176336 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.03411765]\n",
      "predicted action tf.Tensor([[[0.50007254 0.49785173]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.03411765]\n",
      "predicted action tf.Tensor([[[0.49672914 0.52416444]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 4 Reward: [0.10235294]\n",
      "predicted action tf.Tensor([[[0.4752004  0.52180016]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.48360685 0.5311077 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.47375762 0.4471121 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.4865336 0.4339642]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.55068636 0.47939527]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.50660217 0.53983253]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.4801026 0.5259589]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.03294118]\n",
      "predicted action tf.Tensor([[[0.5267066  0.54563963]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 4 Reward: [0.03294118]\n",
      "predicted action tf.Tensor([[[0.57492924 0.5162883 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.01647059]\n",
      "predicted action tf.Tensor([[[0.59025    0.48048055]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.0317647]\n",
      "predicted action tf.Tensor([[[0.57998794 0.47372976]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 3 Reward: [0.04823529]\n",
      "predicted action tf.Tensor([[[0.40718693 0.538946  ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.01176471]\n",
      "predicted action tf.Tensor([[[0.39928433 0.51060283]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.01176471]\n",
      "predicted action tf.Tensor([[[0.42201674 0.41794086]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.06235294]\n",
      "predicted action tf.Tensor([[[0.46670777 0.41034222]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.06235294]\n",
      "predicted action tf.Tensor([[[0.3656389 0.4554571]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.3786146  0.42436332]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.58087075 0.48365384]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.57762355 0.4476351 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.55509835 0.4480796 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 3 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.39783016 0.6386797 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 1 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.43885058 0.476438  ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.4443074  0.48872024]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.5390661  0.46090287]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.5047267  0.49589238]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.43958148 0.5602988 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.0282353]\n",
      "predicted action tf.Tensor([[[0.47994688 0.56257504]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.0282353]\n",
      "predicted action tf.Tensor([[[0.6158629  0.42525232]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.00117647]\n",
      "predicted action tf.Tensor([[[0.6003744  0.41183022]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.00117647]\n",
      "predicted action tf.Tensor([[[0.41295326 0.49666524]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.00235294]\n",
      "predicted action tf.Tensor([[[0.42632943 0.5051232 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.47446635 0.4631219 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 3 Reward: [0.00235294]\n",
      "predicted action tf.Tensor([[[0.49518597 0.5018666 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 1 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.44111234 0.48125285]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.00941177]\n",
      "predicted action tf.Tensor([[[0.4773324  0.47044155]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.00941177]\n",
      "predicted action tf.Tensor([[[0.6230596  0.44191977]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.02352941]\n",
      "predicted action tf.Tensor([[[0.6370295 0.4411767]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.02352941]\n",
      "predicted action tf.Tensor([[[0.48480597 0.41808838]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 1 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.5127813 0.5815209]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.51738304 0.5525759 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.56405425 0.4277358 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.00823529]\n",
      "predicted action tf.Tensor([[[0.5540106  0.42656624]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.00823529]\n",
      "predicted action tf.Tensor([[[0.43246192 0.45199835]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 1 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.5025643 0.4634159]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.06235294]\n",
      "predicted action tf.Tensor([[[0.46744794 0.48566186]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.06235294]\n",
      "predicted action tf.Tensor([[[0.5203138 0.4900906]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 3 Reward: [0.12470589]\n",
      "predicted action tf.Tensor([[[0.5181822 0.5153269]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 1 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.47138432 0.4571437 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 1 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.6411974 0.4116183]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 1 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.62145936 0.5094544 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.04]\n",
      "predicted action tf.Tensor([[[0.5984693  0.50174516]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.04]\n",
      "predicted action tf.Tensor([[[0.4229482 0.5953689]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [-0.]\n",
      "predicted action tf.Tensor([[[0.45426026 0.5818317 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.]\n",
      "predicted action tf.Tensor([[[0.39127767 0.50750375]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.04235294]\n",
      "predicted action tf.Tensor([[[0.41252297 0.5224677 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.04235294]\n",
      "predicted action tf.Tensor([[[0.65670663 0.49030533]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.01529412]\n",
      "predicted action tf.Tensor([[[0.6870581  0.49787262]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.01529412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted action tf.Tensor([[[0.45336407 0.47315836]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.02705882]\n",
      "predicted action tf.Tensor([[[0.48258638 0.47715747]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.02705882]\n",
      "predicted action tf.Tensor([[[0.608012   0.54048145]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.01294118]\n",
      "predicted action tf.Tensor([[[0.57309616 0.52038664]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.01294118]\n",
      "predicted action tf.Tensor([[[0.3862327  0.44728348]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.00823529]\n",
      "predicted action tf.Tensor([[[0.43184984 0.4117758 ]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.00823529]\n",
      "predicted action tf.Tensor([[[0.4680928  0.46774697]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.02235294]\n",
      "predicted action tf.Tensor([[[0.4990568  0.49323973]]], shape=(1, 1, 2), dtype=float32)\n",
      "Reward [0.]\n",
      "Steps: 2 Reward: [0.02235294]\n"
     ]
    }
   ],
   "source": [
    "be = BoostedEnvironment()\n",
    "validate_py_environment(be, episodes=1)\n",
    "tf_env = tf_py_environment.TFPyEnvironment(be)\n",
    "\n",
    "# see how agent performs \n",
    "time_step = tf_env.reset()\n",
    "for _ in range(50):\n",
    "    tf_env.reset()\n",
    "    episode_reward = 0\n",
    "    episode_steps = 0\n",
    "    while not tf_env.current_time_step().is_last():\n",
    "        action = agent.policy.action(tf_env.current_time_step()).action\n",
    "        print('predicted action', action)\n",
    "        next_time_step = tf_env.step(action)\n",
    "        episode_steps += 1\n",
    "        print(\"Reward\", next_time_step.reward.numpy())\n",
    "        episode_reward += next_time_step.reward.numpy()\n",
    "    print(\"Steps:\", episode_steps, \"Reward:\", episode_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
